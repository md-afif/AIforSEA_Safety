{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second_mean</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>second_spread</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>num_non_speed_outlier</th>\n",
       "      <th>second_std</th>\n",
       "      <th>second_median</th>\n",
       "      <th>speed_spread</th>\n",
       "      <th>num_non_gyro_outlier</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>903.526892</td>\n",
       "      <td>8.994822</td>\n",
       "      <td>8.503366</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>0.624159</td>\n",
       "      <td>243</td>\n",
       "      <td>533.745097</td>\n",
       "      <td>1087.5</td>\n",
       "      <td>23.946083</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>581.175088</td>\n",
       "      <td>7.881588</td>\n",
       "      <td>6.904588</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>0.519956</td>\n",
       "      <td>189</td>\n",
       "      <td>289.339367</td>\n",
       "      <td>607.0</td>\n",
       "      <td>22.882141</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>339.441026</td>\n",
       "      <td>3.157213</td>\n",
       "      <td>2.998761</td>\n",
       "      <td>825.0</td>\n",
       "      <td>0.515173</td>\n",
       "      <td>47</td>\n",
       "      <td>356.319445</td>\n",
       "      <td>97.0</td>\n",
       "      <td>9.360483</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>547.495430</td>\n",
       "      <td>6.150996</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.620066</td>\n",
       "      <td>260</td>\n",
       "      <td>315.962793</td>\n",
       "      <td>547.5</td>\n",
       "      <td>19.780001</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>4.628921</td>\n",
       "      <td>1.936962</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.585346</td>\n",
       "      <td>263</td>\n",
       "      <td>316.243577</td>\n",
       "      <td>547.0</td>\n",
       "      <td>16.394695</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>480.947313</td>\n",
       "      <td>12.176386</td>\n",
       "      <td>13.017325</td>\n",
       "      <td>959.0</td>\n",
       "      <td>0.916836</td>\n",
       "      <td>221</td>\n",
       "      <td>276.761488</td>\n",
       "      <td>481.0</td>\n",
       "      <td>25.230654</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>256.847545</td>\n",
       "      <td>5.351266</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.728514</td>\n",
       "      <td>92</td>\n",
       "      <td>130.713942</td>\n",
       "      <td>268.0</td>\n",
       "      <td>19.270000</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>8.702027</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.833292</td>\n",
       "      <td>89</td>\n",
       "      <td>108.397417</td>\n",
       "      <td>187.0</td>\n",
       "      <td>20.050000</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>6.659024</td>\n",
       "      <td>5.192059</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.750480</td>\n",
       "      <td>46</td>\n",
       "      <td>93.043769</td>\n",
       "      <td>112.0</td>\n",
       "      <td>17.876741</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>299.500000</td>\n",
       "      <td>4.725448</td>\n",
       "      <td>3.173314</td>\n",
       "      <td>599.0</td>\n",
       "      <td>0.447980</td>\n",
       "      <td>140</td>\n",
       "      <td>173.349358</td>\n",
       "      <td>299.5</td>\n",
       "      <td>21.780035</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   second_mean  speed_mean  speed_median  second_spread  acceleration_std  \\\n",
       "0   903.526892    8.994822      8.503366         1589.0          0.624159   \n",
       "1   581.175088    7.881588      6.904588         1034.0          0.519956   \n",
       "2   339.441026    3.157213      2.998761          825.0          0.515173   \n",
       "3   547.495430    6.150996      3.310000         1094.0          0.620066   \n",
       "4   547.000000    4.628921      1.936962         1094.0          0.585346   \n",
       "5   480.947313   12.176386     13.017325          959.0          0.916836   \n",
       "6   256.847545    5.351266      3.500000          462.0          0.728514   \n",
       "7   187.000000    8.702027      9.580000          374.0          0.833292   \n",
       "8   132.000000    6.659024      5.192059          299.0          0.750480   \n",
       "9   299.500000    4.725448      3.173314          599.0          0.447980   \n",
       "\n",
       "   num_non_speed_outlier  second_std  second_median  speed_spread  \\\n",
       "0                    243  533.745097         1087.5     23.946083   \n",
       "1                    189  289.339367          607.0     22.882141   \n",
       "2                     47  356.319445           97.0      9.360483   \n",
       "3                    260  315.962793          547.5     19.780001   \n",
       "4                    263  316.243577          547.0     16.394695   \n",
       "5                    221  276.761488          481.0     25.230654   \n",
       "6                     92  130.713942          268.0     19.270000   \n",
       "7                     89  108.397417          187.0     20.050000   \n",
       "8                     46   93.043769          112.0     17.876741   \n",
       "9                    140  173.349358          299.5     21.780035   \n",
       "\n",
       "   num_non_gyro_outlier  label  \n",
       "0                   239      0  \n",
       "1                   199      1  \n",
       "2                    41      1  \n",
       "3                   245      1  \n",
       "4                   253      0  \n",
       "5                   235      0  \n",
       "6                    88      0  \n",
       "7                    82      0  \n",
       "8                    43      0  \n",
       "9                   140      0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), '../data/safety/kfengtee.csv')\n",
    "\n",
    "adaboost_cols = ['second_mean', 'speed_mean', 'speed_median', 'second_spread',\n",
    "       'acceleration_std', 'num_non_speed_outlier', 'second_std',\n",
    "       'second_median', 'speed_spread', 'num_non_gyro_outlier', 'label']\n",
    "\n",
    "agg_diff_df = pd.read_csv(DATA_DIR)\n",
    "agg_diff_df = agg_diff_df.drop('bookingid', axis='columns')\n",
    "agg_diff_df = agg_diff_df[adaboost_cols]\n",
    "agg_diff_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downsampling training set to get equal class distribution\n",
    "# seed = 199\n",
    "\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# count_0 = agg_diff_df['label'].value_counts()[0]\n",
    "# count_1 = agg_diff_df['label'].value_counts()[1]\n",
    "\n",
    "# idx0 = agg_diff_df[agg_diff_df['label'] == 0].index.values\n",
    "# sample_0_idx = np.random.choice(idx0, size=count_1, replace=False)\n",
    "\n",
    "# df_0 = agg_diff_df.iloc[sample_0_idx, :]\n",
    "# downsample_df = pd.concat([df_0, agg_diff_df[agg_diff_df['label'] == 1]]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# X = downsample_df.drop('label', axis=1)\n",
    "# y = downsample_df['label']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reforming test set to have class distribution of 75% class 0 : 25% class 1\n",
    "# prop = count_1 / (count_0 + count_1)\n",
    "# sample_0_idx2 = [idx for idx in idx0 if idx not in sample_0_idx]\n",
    "\n",
    "# count_1_new = y_test2.value_counts()[1]\n",
    "# count_0_new = y_test2.value_counts()[0]\n",
    "# size_total = np.int((count_1_new / 20) * 80)\n",
    "# size_rem = size_total - count_0_new\n",
    "\n",
    "# sample_0_idx2 = np.random.choice(sample_0_idx2, size=size_rem, replace=False)\n",
    "\n",
    "# new_df0 = agg_diff_df.iloc[sample_0_idx2, :]\n",
    "\n",
    "# X_test = pd.concat([X_test, new_df0.drop('label', axis=1)]).sample(frac=1)\n",
    "# y_test = pd.concat([y_test, new_df0['label']]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11967\n",
      "1     4018\n",
      "Name: label, dtype: int64\n",
      "0    3032\n",
      "1     965\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "seed = 102\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "X = agg_diff_df.drop('label', axis=1)\n",
    "y = agg_diff_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=seed, shuffle=True)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second_mean</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>second_spread</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>num_non_speed_outlier</th>\n",
       "      <th>second_std</th>\n",
       "      <th>second_median</th>\n",
       "      <th>speed_spread</th>\n",
       "      <th>num_non_gyro_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.598500e+04</td>\n",
       "      <td>1.598500e+04</td>\n",
       "      <td>1.598500e+04</td>\n",
       "      <td>1.598500e+04</td>\n",
       "      <td>1.598500e+04</td>\n",
       "      <td>1.598500e+04</td>\n",
       "      <td>1.598500e+04</td>\n",
       "      <td>1.598500e+04</td>\n",
       "      <td>1.598500e+04</td>\n",
       "      <td>1.598500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.459978e-17</td>\n",
       "      <td>-4.543198e-16</td>\n",
       "      <td>8.059448e-17</td>\n",
       "      <td>1.783276e-17</td>\n",
       "      <td>4.212388e-17</td>\n",
       "      <td>1.121475e-16</td>\n",
       "      <td>-7.290212e-17</td>\n",
       "      <td>8.946376e-17</td>\n",
       "      <td>-1.661063e-16</td>\n",
       "      <td>7.039168e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000031e+00</td>\n",
       "      <td>1.000031e+00</td>\n",
       "      <td>1.000031e+00</td>\n",
       "      <td>1.000031e+00</td>\n",
       "      <td>1.000031e+00</td>\n",
       "      <td>1.000031e+00</td>\n",
       "      <td>1.000031e+00</td>\n",
       "      <td>1.000031e+00</td>\n",
       "      <td>1.000031e+00</td>\n",
       "      <td>1.000031e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.137380e-02</td>\n",
       "      <td>-2.194757e+00</td>\n",
       "      <td>-1.562373e+00</td>\n",
       "      <td>-1.446772e-02</td>\n",
       "      <td>-1.632869e+00</td>\n",
       "      <td>-1.823856e+00</td>\n",
       "      <td>-1.393694e-02</td>\n",
       "      <td>-1.518703e+00</td>\n",
       "      <td>-3.847519e+00</td>\n",
       "      <td>-1.754359e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-1.086632e-02</td>\n",
       "      <td>-7.411859e-01</td>\n",
       "      <td>-7.681883e-01</td>\n",
       "      <td>-1.443784e-02</td>\n",
       "      <td>-4.432735e-01</td>\n",
       "      <td>-7.619954e-01</td>\n",
       "      <td>-1.386320e-02</td>\n",
       "      <td>-7.267819e-01</td>\n",
       "      <td>-6.905334e-01</td>\n",
       "      <td>-7.715878e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-1.050896e-02</td>\n",
       "      <td>-2.206701e-01</td>\n",
       "      <td>-2.369787e-01</td>\n",
       "      <td>-1.441723e-02</td>\n",
       "      <td>-1.615945e-01</td>\n",
       "      <td>-1.552177e-01</td>\n",
       "      <td>-1.381280e-02</td>\n",
       "      <td>-1.425201e-01</td>\n",
       "      <td>1.335398e-02</td>\n",
       "      <td>-1.585719e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>-1.006794e-02</td>\n",
       "      <td>5.816500e-01</td>\n",
       "      <td>5.940225e-01</td>\n",
       "      <td>-1.439147e-02</td>\n",
       "      <td>1.869026e-01</td>\n",
       "      <td>6.234804e-01</td>\n",
       "      <td>-1.375334e-02</td>\n",
       "      <td>5.666894e-01</td>\n",
       "      <td>7.432251e-01</td>\n",
       "      <td>6.393218e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.219359e+02</td>\n",
       "      <td>4.919532e+00</td>\n",
       "      <td>3.954529e+00</td>\n",
       "      <td>1.027395e+02</td>\n",
       "      <td>2.019433e+01</td>\n",
       "      <td>1.673343e+01</td>\n",
       "      <td>1.024543e+02</td>\n",
       "      <td>2.391253e+01</td>\n",
       "      <td>2.322740e+01</td>\n",
       "      <td>1.223797e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        second_mean    speed_mean  speed_median  second_spread  \\\n",
       "count  1.598500e+04  1.598500e+04  1.598500e+04   1.598500e+04   \n",
       "mean   1.459978e-17 -4.543198e-16  8.059448e-17   1.783276e-17   \n",
       "std    1.000031e+00  1.000031e+00  1.000031e+00   1.000031e+00   \n",
       "min   -1.137380e-02 -2.194757e+00 -1.562373e+00  -1.446772e-02   \n",
       "25%   -1.086632e-02 -7.411859e-01 -7.681883e-01  -1.443784e-02   \n",
       "50%   -1.050896e-02 -2.206701e-01 -2.369787e-01  -1.441723e-02   \n",
       "75%   -1.006794e-02  5.816500e-01  5.940225e-01  -1.439147e-02   \n",
       "max    1.219359e+02  4.919532e+00  3.954529e+00   1.027395e+02   \n",
       "\n",
       "       acceleration_std  num_non_speed_outlier    second_std  second_median  \\\n",
       "count      1.598500e+04           1.598500e+04  1.598500e+04   1.598500e+04   \n",
       "mean       4.212388e-17           1.121475e-16 -7.290212e-17   8.946376e-17   \n",
       "std        1.000031e+00           1.000031e+00  1.000031e+00   1.000031e+00   \n",
       "min       -1.632869e+00          -1.823856e+00 -1.393694e-02  -1.518703e+00   \n",
       "25%       -4.432735e-01          -7.619954e-01 -1.386320e-02  -7.267819e-01   \n",
       "50%       -1.615945e-01          -1.552177e-01 -1.381280e-02  -1.425201e-01   \n",
       "75%        1.869026e-01           6.234804e-01 -1.375334e-02   5.666894e-01   \n",
       "max        2.019433e+01           1.673343e+01  1.024543e+02   2.391253e+01   \n",
       "\n",
       "       speed_spread  num_non_gyro_outlier  \n",
       "count  1.598500e+04          1.598500e+04  \n",
       "mean  -1.661063e-16          7.039168e-17  \n",
       "std    1.000031e+00          1.000031e+00  \n",
       "min   -3.847519e+00         -1.754359e+00  \n",
       "25%   -6.905334e-01         -7.715878e-01  \n",
       "50%    1.335398e-02         -1.585719e-01  \n",
       "75%    7.432251e-01          6.393218e-01  \n",
       "max    2.322740e+01          1.223797e+01  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second_mean</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>second_spread</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>num_non_speed_outlier</th>\n",
       "      <th>second_std</th>\n",
       "      <th>second_median</th>\n",
       "      <th>speed_spread</th>\n",
       "      <th>num_non_gyro_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3.997000e+03</td>\n",
       "      <td>3.997000e+03</td>\n",
       "      <td>3.997000e+03</td>\n",
       "      <td>3.997000e+03</td>\n",
       "      <td>3.997000e+03</td>\n",
       "      <td>3.997000e+03</td>\n",
       "      <td>3.997000e+03</td>\n",
       "      <td>3.997000e+03</td>\n",
       "      <td>3.997000e+03</td>\n",
       "      <td>3.997000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-4.116984e-18</td>\n",
       "      <td>-4.527277e-16</td>\n",
       "      <td>6.751750e-17</td>\n",
       "      <td>1.969695e-17</td>\n",
       "      <td>-1.249938e-16</td>\n",
       "      <td>-9.396759e-17</td>\n",
       "      <td>-7.129857e-18</td>\n",
       "      <td>7.021876e-17</td>\n",
       "      <td>1.037171e-16</td>\n",
       "      <td>1.213829e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000125e+00</td>\n",
       "      <td>1.000125e+00</td>\n",
       "      <td>1.000125e+00</td>\n",
       "      <td>1.000125e+00</td>\n",
       "      <td>1.000125e+00</td>\n",
       "      <td>1.000125e+00</td>\n",
       "      <td>1.000125e+00</td>\n",
       "      <td>1.000125e+00</td>\n",
       "      <td>1.000125e+00</td>\n",
       "      <td>1.000125e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.343577e-02</td>\n",
       "      <td>-2.200054e+00</td>\n",
       "      <td>-1.555848e+00</td>\n",
       "      <td>-1.589975e-02</td>\n",
       "      <td>-1.527091e+00</td>\n",
       "      <td>-1.847147e+00</td>\n",
       "      <td>-1.612719e-02</td>\n",
       "      <td>-1.587899e+00</td>\n",
       "      <td>-3.999681e+00</td>\n",
       "      <td>-1.762144e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-1.930302e-02</td>\n",
       "      <td>-7.323201e-01</td>\n",
       "      <td>-7.607036e-01</td>\n",
       "      <td>-1.585534e-02</td>\n",
       "      <td>-4.337218e-01</td>\n",
       "      <td>-7.478590e-01</td>\n",
       "      <td>-1.595486e-02</td>\n",
       "      <td>-7.468301e-01</td>\n",
       "      <td>-7.102989e-01</td>\n",
       "      <td>-7.739631e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-1.658790e-02</td>\n",
       "      <td>-2.311273e-01</td>\n",
       "      <td>-2.468733e-01</td>\n",
       "      <td>-1.582624e-02</td>\n",
       "      <td>-1.591734e-01</td>\n",
       "      <td>-1.359911e-01</td>\n",
       "      <td>-1.584314e-02</td>\n",
       "      <td>-1.498213e-01</td>\n",
       "      <td>-1.215461e-03</td>\n",
       "      <td>-1.612908e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>-1.294342e-02</td>\n",
       "      <td>5.862923e-01</td>\n",
       "      <td>5.954278e-01</td>\n",
       "      <td>-1.578948e-02</td>\n",
       "      <td>1.739295e-01</td>\n",
       "      <td>6.106952e-01</td>\n",
       "      <td>-1.570425e-02</td>\n",
       "      <td>6.067654e-01</td>\n",
       "      <td>7.405672e-01</td>\n",
       "      <td>6.292540e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>6.321323e+01</td>\n",
       "      <td>4.014485e+00</td>\n",
       "      <td>3.664321e+00</td>\n",
       "      <td>6.321392e+01</td>\n",
       "      <td>1.615867e+01</td>\n",
       "      <td>7.818292e+00</td>\n",
       "      <td>6.321392e+01</td>\n",
       "      <td>6.636930e+00</td>\n",
       "      <td>4.243975e+00</td>\n",
       "      <td>8.386476e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        second_mean    speed_mean  speed_median  second_spread  \\\n",
       "count  3.997000e+03  3.997000e+03  3.997000e+03   3.997000e+03   \n",
       "mean  -4.116984e-18 -4.527277e-16  6.751750e-17   1.969695e-17   \n",
       "std    1.000125e+00  1.000125e+00  1.000125e+00   1.000125e+00   \n",
       "min   -2.343577e-02 -2.200054e+00 -1.555848e+00  -1.589975e-02   \n",
       "25%   -1.930302e-02 -7.323201e-01 -7.607036e-01  -1.585534e-02   \n",
       "50%   -1.658790e-02 -2.311273e-01 -2.468733e-01  -1.582624e-02   \n",
       "75%   -1.294342e-02  5.862923e-01  5.954278e-01  -1.578948e-02   \n",
       "max    6.321323e+01  4.014485e+00  3.664321e+00   6.321392e+01   \n",
       "\n",
       "       acceleration_std  num_non_speed_outlier    second_std  second_median  \\\n",
       "count      3.997000e+03           3.997000e+03  3.997000e+03   3.997000e+03   \n",
       "mean      -1.249938e-16          -9.396759e-17 -7.129857e-18   7.021876e-17   \n",
       "std        1.000125e+00           1.000125e+00  1.000125e+00   1.000125e+00   \n",
       "min       -1.527091e+00          -1.847147e+00 -1.612719e-02  -1.587899e+00   \n",
       "25%       -4.337218e-01          -7.478590e-01 -1.595486e-02  -7.468301e-01   \n",
       "50%       -1.591734e-01          -1.359911e-01 -1.584314e-02  -1.498213e-01   \n",
       "75%        1.739295e-01           6.106952e-01 -1.570425e-02   6.067654e-01   \n",
       "max        1.615867e+01           7.818292e+00  6.321392e+01   6.636930e+00   \n",
       "\n",
       "       speed_spread  num_non_gyro_outlier  \n",
       "count  3.997000e+03          3.997000e+03  \n",
       "mean   1.037171e-16          1.213829e-16  \n",
       "std    1.000125e+00          1.000125e+00  \n",
       "min   -3.999681e+00         -1.762144e+00  \n",
       "25%   -7.102989e-01         -7.739631e-01  \n",
       "50%   -1.215461e-03         -1.612908e-01  \n",
       "75%    7.405672e-01          6.292540e-01  \n",
       "max    4.243975e+00          8.386476e+00  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = pd.DataFrame(scaler.fit_transform(X_test), columns = X_test.columns)\n",
    "X_test_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_layers=1, num_nodes=32, lr=0.001, dropout=False, opt=\"SGD\", input_shape=(10,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_nodes, activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    if dropout:\n",
    "        model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    if num_layers > 1:\n",
    "        for i in range(num_layers - 1):\n",
    "            model.add(Dense(num_nodes, activation='relu'))\n",
    "            if dropout:\n",
    "                model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if opt == \"SGD\":\n",
    "        optimiser = optimizers.SGD(lr=lr)\n",
    "    elif opt == \"RMSprop\":\n",
    "        optimiser = optimizers.RMSprop(lr=lr)\n",
    "    elif opt == \"Adam\":\n",
    "        optimiser = optimizers.Adam(lr=lr)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", \n",
    "               optimizer=optimiser,\n",
    "               metrics=[\"accuracy\"])\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1 of 5\n",
      "Total time taken: 121 seconds\n",
      "Processing fold 2 of 5\n",
      "Total time taken: 245 seconds\n",
      "Processing fold 3 of 5\n",
      "Total time taken: 376 seconds\n",
      "Processing fold 4 of 5\n",
      "Total time taken: 506 seconds\n",
      "Processing fold 5 of 5\n",
      "Total time taken: 635 seconds\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "k = 5\n",
    "num_val_samples = X_train_scaled.shape[0] // k\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "all_val_loss = []\n",
    "all_train_loss = []\n",
    "all_val_acc = []\n",
    "all_train_acc = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('Processing fold {} of {}'.format(i + 1, k))\n",
    "\n",
    "    val_data = X_train_scaled[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    partial_train_data = np.concatenate([X_train_scaled[:i * num_val_samples], \n",
    "                                         X_train_scaled[(i + 1) * num_val_samples:]], axis=0)\n",
    "    partial_train_targets = np.concatenate([y_train[:i * num_val_samples], \n",
    "                                            y_train[(i + 1) * num_val_samples:]], axis=0)\n",
    "    \n",
    "    model = build_model(num_layers=2, num_nodes=256, lr=0.001, opt=\"Adam\", dropout=True)\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, verbose=0,\n",
    "                        validation_data=((val_data, val_targets)), batch_size=batch_size)\n",
    "\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "    all_val_loss.append(val_loss)\n",
    "    all_train_loss.append(loss)\n",
    "    all_val_acc.append(val_acc)\n",
    "    all_train_acc.append(acc)\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"Total time taken: {} seconds\".format((end_time - start_time).seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4908082390142896, train acc: 0.7760400176048279\n",
      "Val loss: 0.48992861790287145, val acc: 0.7764153838157654\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_val_loss = [np.mean([x[i] for x in all_val_loss]) for i in range(num_epochs)]\n",
    "average_train_loss = [np.mean([x[i] for x in all_train_loss]) for i in range(num_epochs)]\n",
    "\n",
    "average_val_acc = [np.mean([x[i] for x in all_val_acc]) for i in range(num_epochs)]\n",
    "average_train_acc = [np.mean([x[i] for x in all_train_acc]) for i in range(num_epochs)]\n",
    "\n",
    "print(\"Train loss: {}, train acc: {}\".format(average_train_loss[-1], average_train_acc[-1]))\n",
    "print(\"Val loss: {}, val acc: {}\".format(average_val_loss[-1], average_val_acc[-1]))\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(range(1, len(average_train_loss) + 1), average_train_loss, color=\"r\", label=\"Training loss\")\n",
    "plt.plot(range(1, len(average_val_loss) + 1), average_val_loss, color=\"b\", label=\"Validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15985/15985 [==============================] - 8s 487us/step - loss: 0.5196 - accuracy: 0.7633\n",
      "Epoch 2/20\n",
      "15985/15985 [==============================] - 7s 430us/step - loss: 0.5014 - accuracy: 0.7732\n",
      "Epoch 3/20\n",
      "15985/15985 [==============================] - 7s 448us/step - loss: 0.5005 - accuracy: 0.7736\n",
      "Epoch 4/20\n",
      "15985/15985 [==============================] - 7s 457us/step - loss: 0.4963 - accuracy: 0.7742\n",
      "Epoch 5/20\n",
      "15985/15985 [==============================] - 7s 465us/step - loss: 0.4959 - accuracy: 0.7756\n",
      "Epoch 6/20\n",
      "15985/15985 [==============================] - 8s 476us/step - loss: 0.4956 - accuracy: 0.7742\n",
      "Epoch 7/20\n",
      "15985/15985 [==============================] - 8s 476us/step - loss: 0.4950 - accuracy: 0.7740\n",
      "Epoch 8/20\n",
      "15985/15985 [==============================] - 8s 482us/step - loss: 0.4943 - accuracy: 0.7748\n",
      "Epoch 9/20\n",
      "15985/15985 [==============================] - 8s 488us/step - loss: 0.4928 - accuracy: 0.7762\n",
      "Epoch 10/20\n",
      "15985/15985 [==============================] - 8s 489us/step - loss: 0.4924 - accuracy: 0.7754\n",
      "Epoch 11/20\n",
      "15985/15985 [==============================] - 8s 487us/step - loss: 0.4918 - accuracy: 0.7739\n",
      "Epoch 12/20\n",
      "15985/15985 [==============================] - 8s 508us/step - loss: 0.4944 - accuracy: 0.7755\n",
      "Epoch 13/20\n",
      "15985/15985 [==============================] - 8s 494us/step - loss: 0.4929 - accuracy: 0.7765\n",
      "Epoch 14/20\n",
      "15985/15985 [==============================] - 8s 497us/step - loss: 0.4920 - accuracy: 0.7759\n",
      "Epoch 15/20\n",
      "15985/15985 [==============================] - 8s 498us/step - loss: 0.4896 - accuracy: 0.7753\n",
      "Epoch 16/20\n",
      "15985/15985 [==============================] - 8s 497us/step - loss: 0.4917 - accuracy: 0.7765\n",
      "Epoch 17/20\n",
      "15985/15985 [==============================] - 8s 491us/step - loss: 0.4901 - accuracy: 0.7759\n",
      "Epoch 18/20\n",
      "15985/15985 [==============================] - 8s 500us/step - loss: 0.4934 - accuracy: 0.7778\n",
      "Epoch 19/20\n",
      "15985/15985 [==============================] - 8s 502us/step - loss: 0.4914 - accuracy: 0.7762\n",
      "Epoch 20/20\n",
      "15985/15985 [==============================] - 8s 496us/step - loss: 0.4902 - accuracy: 0.7777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5985096791392674"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(num_layers=2, num_nodes=256, lr=0.001, opt=\"Adam\", dropout=True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20, batch_size=16, verbose=1)\n",
    "\n",
    "res = model.predict(X_test_scaled)\n",
    "res = [round(num[0]) for num in res]\n",
    "\n",
    "roc_auc_score(y_test, res)\n",
    "\n",
    "# 1 layer, Dense(256), Dropout=False, 20 epochs, batch_size=16, Adam(0.001) : 0.61965\n",
    "# 2 layer, Dense(256) * 2, Dropout=False, 20 epochs, batch_size=16, Adam(0.001) : 0.62931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7972/7972 [==============================] - 2s 206us/step - loss: 22.9504 - accuracy: 0.5314\n",
      "Epoch 2/50\n",
      "7972/7972 [==============================] - 1s 129us/step - loss: 0.7837 - accuracy: 0.5645\n",
      "Epoch 3/50\n",
      "7972/7972 [==============================] - 1s 132us/step - loss: 0.7313 - accuracy: 0.5871\n",
      "Epoch 4/50\n",
      "7972/7972 [==============================] - 1s 138us/step - loss: 0.7288 - accuracy: 0.5960\n",
      "Epoch 5/50\n",
      "7972/7972 [==============================] - 1s 143us/step - loss: 0.6928 - accuracy: 0.6080\n",
      "Epoch 6/50\n",
      "7972/7972 [==============================] - 1s 137us/step - loss: 3022.0657 - accuracy: 0.6076\n",
      "Epoch 7/50\n",
      "7972/7972 [==============================] - 1s 139us/step - loss: 0.6866 - accuracy: 0.6041\n",
      "Epoch 8/50\n",
      "7972/7972 [==============================] - 1s 144us/step - loss: 0.6828 - accuracy: 0.6136\n",
      "Epoch 9/50\n",
      "7972/7972 [==============================] - 1s 143us/step - loss: 0.6861 - accuracy: 0.6174\n",
      "Epoch 10/50\n",
      "7972/7972 [==============================] - 1s 143us/step - loss: 0.6781 - accuracy: 0.6157\n",
      "Epoch 11/50\n",
      "7972/7972 [==============================] - 1s 144us/step - loss: 0.6894 - accuracy: 0.6185\n",
      "Epoch 12/50\n",
      "7972/7972 [==============================] - 1s 143us/step - loss: 0.6822 - accuracy: 0.6150\n",
      "Epoch 13/50\n",
      "7972/7972 [==============================] - 1s 142us/step - loss: 0.6790 - accuracy: 0.6204\n",
      "Epoch 14/50\n",
      "7972/7972 [==============================] - 1s 137us/step - loss: 0.6801 - accuracy: 0.6200\n",
      "Epoch 15/50\n",
      "7972/7972 [==============================] - 1s 137us/step - loss: 1635.5178 - accuracy: 0.6104\n",
      "Epoch 16/50\n",
      "7972/7972 [==============================] - 1s 138us/step - loss: 0.6836 - accuracy: 0.6118\n",
      "Epoch 17/50\n",
      "7972/7972 [==============================] - 1s 137us/step - loss: 0.6840 - accuracy: 0.6172\n",
      "Epoch 18/50\n",
      "7972/7972 [==============================] - 1s 138us/step - loss: 0.6851 - accuracy: 0.6193\n",
      "Epoch 19/50\n",
      "7972/7972 [==============================] - 1s 138us/step - loss: 923.3607 - accuracy: 0.6093\n",
      "Epoch 20/50\n",
      "7972/7972 [==============================] - 1s 138us/step - loss: 0.6919 - accuracy: 0.6134\n",
      "Epoch 21/50\n",
      "7972/7972 [==============================] - 1s 139us/step - loss: 0.6740 - accuracy: 0.6282\n",
      "Epoch 22/50\n",
      "7972/7972 [==============================] - 1s 138us/step - loss: 0.6661 - accuracy: 0.6114\n",
      "Epoch 23/50\n",
      "7972/7972 [==============================] - 1s 137us/step - loss: 0.6770 - accuracy: 0.6175\n",
      "Epoch 24/50\n",
      "7972/7972 [==============================] - 1s 137us/step - loss: 0.6863 - accuracy: 0.6168\n",
      "Epoch 25/50\n",
      "7972/7972 [==============================] - 1s 137us/step - loss: 0.6831 - accuracy: 0.6199\n",
      "Epoch 26/50\n",
      "7972/7972 [==============================] - 1s 137us/step - loss: 0.6680 - accuracy: 0.6189\n",
      "Epoch 27/50\n",
      "7972/7972 [==============================] - 1s 142us/step - loss: 296.4107 - accuracy: 0.6232\n",
      "Epoch 28/50\n",
      "7972/7972 [==============================] - 1s 142us/step - loss: 625.2251 - accuracy: 0.6209\n",
      "Epoch 29/50\n",
      "7972/7972 [==============================] - 1s 142us/step - loss: 367.0657 - accuracy: 0.6229\n",
      "Epoch 30/50\n",
      "7972/7972 [==============================] - 1s 143us/step - loss: 0.6840 - accuracy: 0.6223\n",
      "Epoch 31/50\n",
      "7972/7972 [==============================] - 1s 149us/step - loss: 437.4323 - accuracy: 0.6228\n",
      "Epoch 32/50\n",
      "7972/7972 [==============================] - 1s 151us/step - loss: 0.6705 - accuracy: 0.6116\n",
      "Epoch 33/50\n",
      "7972/7972 [==============================] - 1s 151us/step - loss: 2717.2102 - accuracy: 0.6121\n",
      "Epoch 34/50\n",
      "7972/7972 [==============================] - 1s 148us/step - loss: 0.6573 - accuracy: 0.6247\n",
      "Epoch 35/50\n",
      "7972/7972 [==============================] - 1s 153us/step - loss: 386.4151 - accuracy: 0.6150\n",
      "Epoch 36/50\n",
      "7972/7972 [==============================] - 1s 151us/step - loss: 0.7024 - accuracy: 0.6160\n",
      "Epoch 37/50\n",
      "7972/7972 [==============================] - 1s 149us/step - loss: 0.6738 - accuracy: 0.6187\n",
      "Epoch 38/50\n",
      "7972/7972 [==============================] - 1s 149us/step - loss: 0.6709 - accuracy: 0.6292\n",
      "Epoch 39/50\n",
      "7972/7972 [==============================] - 1s 145us/step - loss: 0.6879 - accuracy: 0.6212\n",
      "Epoch 40/50\n",
      "7972/7972 [==============================] - 1s 144us/step - loss: 0.6775 - accuracy: 0.6295\n",
      "Epoch 41/50\n",
      "7972/7972 [==============================] - 1s 143us/step - loss: 766.9627 - accuracy: 0.6233\n",
      "Epoch 42/50\n",
      "7972/7972 [==============================] - 1s 144us/step - loss: 0.6849 - accuracy: 0.6119\n",
      "Epoch 43/50\n",
      "7972/7972 [==============================] - 1s 143us/step - loss: 0.6794 - accuracy: 0.6222\n",
      "Epoch 44/50\n",
      "7972/7972 [==============================] - 1s 144us/step - loss: 0.6678 - accuracy: 0.6254\n",
      "Epoch 45/50\n",
      "7972/7972 [==============================] - 1s 145us/step - loss: 822.5585 - accuracy: 0.6216\n",
      "Epoch 46/50\n",
      "7972/7972 [==============================] - 1s 143us/step - loss: 0.6777 - accuracy: 0.6169\n",
      "Epoch 47/50\n",
      "7972/7972 [==============================] - 1s 141us/step - loss: 1814.8814 - accuracy: 0.6284\n",
      "Epoch 48/50\n",
      "7972/7972 [==============================] - 1s 137us/step - loss: 0.6669 - accuracy: 0.6253\n",
      "Epoch 49/50\n",
      "7972/7972 [==============================] - 1s 139us/step - loss: 0.6707 - accuracy: 0.6323\n",
      "Epoch 50/50\n",
      "7972/7972 [==============================] - 1s 144us/step - loss: 893.0998 - accuracy: 0.6360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x1a43d70090>,\n",
       "                   iid='warn', n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'dropout': [True, False],\n",
       "                                        'lr': [0.0001, 0.001, 0.01, 0.1],\n",
       "                                        'num_layers': [1, 2],\n",
       "                                        'num_nodes': [32, 64, 128, 256],\n",
       "                                        'opt': ['SGD', 'RMSprop', 'Adam']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=299, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params)\n",
    "\n",
    "params = {'num_nodes' : [32, 64, 128, 256],\n",
    "         'num_layers' : [1, 2], \n",
    "         'lr' : [0.0001, 0.001, 0.01, 0.1],\n",
    "         'dropout' : [True, False],\n",
    "         'opt' : ['SGD', \"RMSprop\", \"Adam\"]}\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=50, batch_size=16)\n",
    "# grid = GridSearchCV(model, param_grid=params, n_jobs=4, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "seed = 299\n",
    "num_iter = 5\n",
    "\n",
    "random_grid = RandomizedSearchCV(estimator=model, \n",
    "                                 param_distributions=params, \n",
    "                                 scoring='roc_auc', n_iter=num_iter, cv=5, n_jobs=-1,\n",
    "                                 random_state=seed)\n",
    "random_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([323.6830193 , 218.12241797, 162.63273921, 224.07102652,\n",
       "        235.32160497]),\n",
       " 'std_fit_time': array([ 1.99630942,  7.8220918 , 14.16352113, 12.44804933, 42.12429535]),\n",
       " 'mean_score_time': array([1.01736503, 1.27732596, 1.807862  , 2.59811206, 0.64059763]),\n",
       " 'std_score_time': array([0.32341652, 0.24254038, 0.44929909, 0.83589727, 0.47590574]),\n",
       " 'param_opt': masked_array(data=['Adam', 'RMSprop', 'RMSprop', 'Adam', 'Adam'],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_num_nodes': masked_array(data=[256, 256, 64, 64, 128],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_num_layers': masked_array(data=[2, 1, 1, 2, 2],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_lr': masked_array(data=[0.1, 0.001, 0.001, 0.01, 0.001],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_dropout': masked_array(data=[False, True, True, True, True],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'opt': 'Adam',\n",
       "   'num_nodes': 256,\n",
       "   'num_layers': 2,\n",
       "   'lr': 0.1,\n",
       "   'dropout': False},\n",
       "  {'opt': 'RMSprop',\n",
       "   'num_nodes': 256,\n",
       "   'num_layers': 1,\n",
       "   'lr': 0.001,\n",
       "   'dropout': True},\n",
       "  {'opt': 'RMSprop',\n",
       "   'num_nodes': 64,\n",
       "   'num_layers': 1,\n",
       "   'lr': 0.001,\n",
       "   'dropout': True},\n",
       "  {'opt': 'Adam',\n",
       "   'num_nodes': 64,\n",
       "   'num_layers': 2,\n",
       "   'lr': 0.01,\n",
       "   'dropout': True},\n",
       "  {'opt': 'Adam',\n",
       "   'num_nodes': 128,\n",
       "   'num_layers': 2,\n",
       "   'lr': 0.001,\n",
       "   'dropout': True}],\n",
       " 'split0_test_score': array([0.50124844, 0.70639503, 0.73722708, 0.49937578, 0.71636446]),\n",
       " 'split1_test_score': array([0.49941328, 0.70148914, 0.72317746, 0.49879981, 0.72515628]),\n",
       " 'split2_test_score': array([0.5       , 0.68784329, 0.69272802, 0.5       , 0.70509968]),\n",
       " 'split3_test_score': array([0.50123762, 0.70295849, 0.72317537, 0.49998189, 0.63934526]),\n",
       " 'split4_test_score': array([0.5006471 , 0.71782821, 0.72872651, 0.5       , 0.73309166]),\n",
       " 'mean_test_score': array([0.50050924, 0.70330299, 0.7210092 , 0.49963136, 0.70381572]),\n",
       " 'std_test_score': array([0.00071511, 0.00962129, 0.01504446, 0.00047993, 0.03354708]),\n",
       " 'rank_test_score': array([4, 3, 1, 5, 2], dtype=int32)}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
