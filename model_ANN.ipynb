{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should (intuitively) be some correlation between the 'over' columns and the 'outlier' columns \\\n",
    "After some rounds of validation, the 'outlier' columns prove to be trash \n",
    "\n",
    "Furthermore, running tree-based models showed that even the 'over' columns are not that useful, so we first try eliminating the 'outlier' columns (proven improvement in ROC) and then eliminating 'over' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_mean</th>\n",
       "      <th>acceleration_median</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>acceleration_spread</th>\n",
       "      <th>gyro_pc_mean</th>\n",
       "      <th>gyro_pc_median</th>\n",
       "      <th>gyro_pc_std</th>\n",
       "      <th>gyro_pc_spread</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>...</th>\n",
       "      <th>second_median</th>\n",
       "      <th>second_std</th>\n",
       "      <th>second_spread</th>\n",
       "      <th>num_non_speed_outlier</th>\n",
       "      <th>num_speed_outlier</th>\n",
       "      <th>num_non_accel_outlier</th>\n",
       "      <th>num_accel_outlier</th>\n",
       "      <th>num_non_gyro_outlier</th>\n",
       "      <th>num_gyro_outlier</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.883337</td>\n",
       "      <td>9.852269</td>\n",
       "      <td>0.619492</td>\n",
       "      <td>6.530989</td>\n",
       "      <td>-0.006583</td>\n",
       "      <td>-0.002863</td>\n",
       "      <td>0.099002</td>\n",
       "      <td>1.101352</td>\n",
       "      <td>9.003204</td>\n",
       "      <td>8.503366</td>\n",
       "      <td>...</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>534.113894</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>243</td>\n",
       "      <td>6</td>\n",
       "      <td>235</td>\n",
       "      <td>14</td>\n",
       "      <td>237</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.865608</td>\n",
       "      <td>9.847932</td>\n",
       "      <td>0.522142</td>\n",
       "      <td>5.819621</td>\n",
       "      <td>-0.006855</td>\n",
       "      <td>-0.003612</td>\n",
       "      <td>0.090770</td>\n",
       "      <td>1.123587</td>\n",
       "      <td>8.019369</td>\n",
       "      <td>7.206634</td>\n",
       "      <td>...</td>\n",
       "      <td>607.5</td>\n",
       "      <td>289.129088</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>192</td>\n",
       "      <td>16</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.929590</td>\n",
       "      <td>9.877755</td>\n",
       "      <td>0.515173</td>\n",
       "      <td>5.168422</td>\n",
       "      <td>-0.012751</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.117109</td>\n",
       "      <td>0.896289</td>\n",
       "      <td>3.157213</td>\n",
       "      <td>2.998761</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>356.319445</td>\n",
       "      <td>825.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.813434</td>\n",
       "      <td>9.791035</td>\n",
       "      <td>0.620066</td>\n",
       "      <td>13.349284</td>\n",
       "      <td>0.022429</td>\n",
       "      <td>0.024239</td>\n",
       "      <td>0.112628</td>\n",
       "      <td>1.166471</td>\n",
       "      <td>6.150996</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>...</td>\n",
       "      <td>547.5</td>\n",
       "      <td>315.962793</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>259</td>\n",
       "      <td>13</td>\n",
       "      <td>262</td>\n",
       "      <td>10</td>\n",
       "      <td>247</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.918090</td>\n",
       "      <td>9.904142</td>\n",
       "      <td>0.585346</td>\n",
       "      <td>7.280114</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.106469</td>\n",
       "      <td>1.161481</td>\n",
       "      <td>4.628921</td>\n",
       "      <td>1.936962</td>\n",
       "      <td>...</td>\n",
       "      <td>547.0</td>\n",
       "      <td>316.243577</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>259</td>\n",
       "      <td>13</td>\n",
       "      <td>262</td>\n",
       "      <td>10</td>\n",
       "      <td>248</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9.826470</td>\n",
       "      <td>9.789800</td>\n",
       "      <td>0.916836</td>\n",
       "      <td>8.572037</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>-0.002687</td>\n",
       "      <td>0.072664</td>\n",
       "      <td>0.903745</td>\n",
       "      <td>12.176386</td>\n",
       "      <td>13.017325</td>\n",
       "      <td>...</td>\n",
       "      <td>481.0</td>\n",
       "      <td>276.761488</td>\n",
       "      <td>959.0</td>\n",
       "      <td>205</td>\n",
       "      <td>30</td>\n",
       "      <td>192</td>\n",
       "      <td>43</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9.763213</td>\n",
       "      <td>9.646309</td>\n",
       "      <td>0.730155</td>\n",
       "      <td>9.416841</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.078446</td>\n",
       "      <td>0.754180</td>\n",
       "      <td>5.384260</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>268.0</td>\n",
       "      <td>130.510496</td>\n",
       "      <td>462.0</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>87</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9.550677</td>\n",
       "      <td>9.494390</td>\n",
       "      <td>0.833292</td>\n",
       "      <td>9.474737</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>0.110181</td>\n",
       "      <td>0.909695</td>\n",
       "      <td>8.702027</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>187.0</td>\n",
       "      <td>108.397417</td>\n",
       "      <td>374.0</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9.948639</td>\n",
       "      <td>9.877962</td>\n",
       "      <td>0.750480</td>\n",
       "      <td>5.686104</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>-0.003111</td>\n",
       "      <td>0.151980</td>\n",
       "      <td>0.988519</td>\n",
       "      <td>6.659024</td>\n",
       "      <td>5.192059</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>93.043769</td>\n",
       "      <td>299.0</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9.873517</td>\n",
       "      <td>9.823053</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>5.916028</td>\n",
       "      <td>-0.002192</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.082987</td>\n",
       "      <td>0.767631</td>\n",
       "      <td>4.152211</td>\n",
       "      <td>3.702154</td>\n",
       "      <td>...</td>\n",
       "      <td>238.0</td>\n",
       "      <td>177.047431</td>\n",
       "      <td>555.0</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acceleration_mean  acceleration_median  acceleration_std  \\\n",
       "0           9.883337             9.852269          0.619492   \n",
       "1           9.865608             9.847932          0.522142   \n",
       "2           9.929590             9.877755          0.515173   \n",
       "3           9.813434             9.791035          0.620066   \n",
       "4           9.918090             9.904142          0.585346   \n",
       "5           9.826470             9.789800          0.916836   \n",
       "6           9.763213             9.646309          0.730155   \n",
       "7           9.550677             9.494390          0.833292   \n",
       "8           9.948639             9.877962          0.750480   \n",
       "9           9.873517             9.823053          0.425662   \n",
       "\n",
       "   acceleration_spread  gyro_pc_mean  gyro_pc_median  gyro_pc_std  \\\n",
       "0             6.530989     -0.006583       -0.002863     0.099002   \n",
       "1             5.819621     -0.006855       -0.003612     0.090770   \n",
       "2             5.168422     -0.012751        0.001369     0.117109   \n",
       "3            13.349284      0.022429        0.024239     0.112628   \n",
       "4             7.280114      0.000480        0.004189     0.106469   \n",
       "5             8.572037      0.002651       -0.002687     0.072664   \n",
       "6             9.416841     -0.000840        0.000250     0.078446   \n",
       "7             9.474737      0.001922       -0.000612     0.110181   \n",
       "8             5.686104     -0.004018       -0.003111     0.151980   \n",
       "9             5.916028     -0.002192        0.000388     0.082987   \n",
       "\n",
       "   gyro_pc_spread  speed_mean  speed_median  ...  second_median  second_std  \\\n",
       "0        1.101352    9.003204      8.503366  ...         1086.5  534.113894   \n",
       "1        1.123587    8.019369      7.206634  ...          607.5  289.129088   \n",
       "2        0.896289    3.157213      2.998761  ...           97.0  356.319445   \n",
       "3        1.166471    6.150996      3.310000  ...          547.5  315.962793   \n",
       "4        1.161481    4.628921      1.936962  ...          547.0  316.243577   \n",
       "5        0.903745   12.176386     13.017325  ...          481.0  276.761488   \n",
       "6        0.754180    5.384260      3.540000  ...          268.0  130.510496   \n",
       "7        0.909695    8.702027      9.580000  ...          187.0  108.397417   \n",
       "8        0.988519    6.659024      5.192059  ...          112.0   93.043769   \n",
       "9        0.767631    4.152211      3.702154  ...          238.0  177.047431   \n",
       "\n",
       "   second_spread  num_non_speed_outlier  num_speed_outlier  \\\n",
       "0         1589.0                    243                  6   \n",
       "1         1034.0                    192                 16   \n",
       "2          825.0                     47                  0   \n",
       "3         1094.0                    259                 13   \n",
       "4         1094.0                    259                 13   \n",
       "5          959.0                    205                 30   \n",
       "6          462.0                     92                  3   \n",
       "7          374.0                     87                  5   \n",
       "8          299.0                     48                  6   \n",
       "9          555.0                    100                  9   \n",
       "\n",
       "   num_non_accel_outlier  num_accel_outlier  num_non_gyro_outlier  \\\n",
       "0                    235                 14                   237   \n",
       "1                    206                  2                   197   \n",
       "2                     47                  0                    41   \n",
       "3                    262                 10                   247   \n",
       "4                    262                 10                   248   \n",
       "5                    192                 43                   235   \n",
       "6                     89                  6                    87   \n",
       "7                     77                 15                    83   \n",
       "8                     49                  5                    45   \n",
       "9                    106                  3                   104   \n",
       "\n",
       "   num_gyro_outlier  label  \n",
       "0                12      0  \n",
       "1                11      1  \n",
       "2                 6      1  \n",
       "3                25      1  \n",
       "4                24      0  \n",
       "5                 0      0  \n",
       "6                 8      0  \n",
       "7                 9      0  \n",
       "8                 9      0  \n",
       "9                 5      0  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), '../data/safety/total_df.csv')\n",
    "\n",
    "# Without 'over' and 'outlier'\n",
    "cols = ['acceleration_mean', 'acceleration_median', 'acceleration_std',\n",
    "       'acceleration_spread', 'gyro_pc_mean', 'gyro_pc_median', 'gyro_pc_std',\n",
    "       'gyro_pc_spread', 'speed_mean', 'speed_median', 'speed_std',\n",
    "       'speed_spread', 'second_mean', 'second_median', 'second_std',\n",
    "       'second_spread', 'label']\n",
    "\n",
    "# Without 'outlier'\n",
    "cols2 = ['acceleration_mean', 'acceleration_median', 'acceleration_std',\n",
    "       'acceleration_spread', 'gyro_pc_mean', 'gyro_pc_median', 'gyro_pc_std',\n",
    "       'gyro_pc_spread', 'speed_mean', 'speed_median', 'speed_std',\n",
    "       'speed_spread', 'second_mean', 'second_median', 'second_std',\n",
    "       'second_spread', 'over_speed', 'over_second', 'over_acceleration_x',\n",
    "       'over_acceleration_y', 'over_acceleration_z', 'over_gyro_x',\n",
    "       'over_gyro_y', 'over_gyro_z', 'label']\n",
    "\n",
    "# Without 'over'\n",
    "cols3 = ['acceleration_mean', 'acceleration_median', 'acceleration_std',\n",
    "       'acceleration_spread', 'gyro_pc_mean', 'gyro_pc_median', 'gyro_pc_std',\n",
    "       'gyro_pc_spread', 'speed_mean', 'speed_median', 'speed_std',\n",
    "       'speed_spread', 'second_mean', 'second_median', 'second_std',\n",
    "       'second_spread', 'num_non_speed_outlier',\n",
    "       'num_speed_outlier', 'num_non_accel_outlier', 'num_accel_outlier',\n",
    "       'num_non_gyro_outlier', 'num_gyro_outlier', 'label']\n",
    "\n",
    "\n",
    "agg_diff_df = pd.read_csv(DATA_DIR)\n",
    "agg_diff_df = agg_diff_df.drop('bookingid', axis='columns')\n",
    "agg_diff_df = agg_diff_df[cols3]\n",
    "agg_diff_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "\n",
    "Downsample to ensure that the neural network learns to classify equally, and not focusing on one class etc \\\n",
    "Train set will have 50:50 distribution, test set will follow actual distribution of 75:25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = agg_diff_df['label'].value_counts()\n",
    "# actual_dist = dist[1] / (dist[0] + dist[1]) \n",
    "# actual_dist # About 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling training set to get equal class distribution\n",
    "seed = 199\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "count_0 = agg_diff_df['label'].value_counts()[0]\n",
    "count_1 = agg_diff_df['label'].value_counts()[1]\n",
    "\n",
    "idx0 = agg_diff_df[agg_diff_df['label'] == 0].index.values\n",
    "sample_0_idx = np.random.choice(idx0, count_1)\n",
    "\n",
    "df_0 = agg_diff_df.iloc[sample_0_idx, :]\n",
    "downsample_df = pd.concat([df_0, agg_diff_df[agg_diff_df['label'] == 1]]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = downsample_df.drop('label', axis=1)\n",
    "y = downsample_df['label']\n",
    "\n",
    "X_train, X_test2, y_train, y_test2 = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reforming test set to have class distribution of 75% class 0 : 25% class 1\n",
    "prop = count_1 / (count_0 + count_1)\n",
    "sample_0_idx2 = [idx for idx in idx0 if idx not in sample_0_idx]\n",
    "\n",
    "y_count = y_test2.value_counts()[1]\n",
    "sample_0_idx2 = np.random.choice(sample_0_idx2, size=np.int((y_count / 25) * 75))\n",
    "\n",
    "new_df0 = agg_diff_df.iloc[sample_0_idx2, :].sample(n=np.int((y_count / 25) * 75))\n",
    "test = pd.merge(X_test2, y_test2, left_index=True, right_index=True)\n",
    "test = test[test['label'] == 1]\n",
    "\n",
    "df_merge = pd.concat([new_df0, test], axis=0).reset_index(drop=True).sample(frac=1)\n",
    "\n",
    "X_test, y_test = df_merge.drop('label', axis=1), df_merge['label']\n",
    "\n",
    "del X_test2, y_test2, df_merge, test, new_df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class distribution : \n",
      "1    3999\n",
      "0    3940\n",
      "Name: label, dtype: int64\n",
      "Testing class distribution : \n",
      "0    2889\n",
      "1     963\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking distributions\n",
    "print(\"Training class distribution : \")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"Testing class distribution : \")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-downsampling approach\n",
    "\n",
    "Leaving distribution as is then see how it goes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 13\n",
    "\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# X = agg_diff_df.drop('label', axis=1)\n",
    "# y = agg_diff_df['label']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "#                                                     random_state=seed, shuffle=True)\n",
    "\n",
    "# print(y_train.value_counts())\n",
    "# print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising data to have mean = 0 and standard deviation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_mean</th>\n",
       "      <th>acceleration_median</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>acceleration_spread</th>\n",
       "      <th>gyro_pc_mean</th>\n",
       "      <th>gyro_pc_median</th>\n",
       "      <th>gyro_pc_std</th>\n",
       "      <th>gyro_pc_spread</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>...</th>\n",
       "      <th>second_mean</th>\n",
       "      <th>second_median</th>\n",
       "      <th>second_std</th>\n",
       "      <th>second_spread</th>\n",
       "      <th>num_non_speed_outlier</th>\n",
       "      <th>num_speed_outlier</th>\n",
       "      <th>num_non_accel_outlier</th>\n",
       "      <th>num_accel_outlier</th>\n",
       "      <th>num_non_gyro_outlier</th>\n",
       "      <th>num_gyro_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-1.117997e-15</td>\n",
       "      <td>-3.582131e-16</td>\n",
       "      <td>-5.544822e-17</td>\n",
       "      <td>-1.301040e-16</td>\n",
       "      <td>2.805362e-17</td>\n",
       "      <td>-5.848874e-18</td>\n",
       "      <td>-5.993023e-17</td>\n",
       "      <td>-6.174121e-18</td>\n",
       "      <td>3.027906e-16</td>\n",
       "      <td>6.368504e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.164902e-17</td>\n",
       "      <td>-1.552271e-17</td>\n",
       "      <td>6.267817e-17</td>\n",
       "      <td>3.945005e-17</td>\n",
       "      <td>9.817062e-18</td>\n",
       "      <td>-1.298034e-16</td>\n",
       "      <td>-3.865293e-17</td>\n",
       "      <td>9.133224e-17</td>\n",
       "      <td>7.141843e-17</td>\n",
       "      <td>-2.261455e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.403143e+01</td>\n",
       "      <td>-1.487927e+01</td>\n",
       "      <td>-1.263256e+00</td>\n",
       "      <td>-1.265030e+00</td>\n",
       "      <td>-7.505363e+01</td>\n",
       "      <td>-7.457329e+01</td>\n",
       "      <td>-6.390963e-01</td>\n",
       "      <td>-4.769338e-01</td>\n",
       "      <td>-1.987609e+00</td>\n",
       "      <td>-1.409070e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.755744e+00</td>\n",
       "      <td>-1.718727e+00</td>\n",
       "      <td>-1.882765e+00</td>\n",
       "      <td>-1.878490e+00</td>\n",
       "      <td>-1.775224e+00</td>\n",
       "      <td>-8.030272e-01</td>\n",
       "      <td>-1.709059e+00</td>\n",
       "      <td>-5.800865e-01</td>\n",
       "      <td>-1.716260e+00</td>\n",
       "      <td>-7.754690e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-1.389243e-01</td>\n",
       "      <td>-1.059107e-01</td>\n",
       "      <td>-4.052873e-01</td>\n",
       "      <td>-4.342546e-01</td>\n",
       "      <td>-2.422009e-02</td>\n",
       "      <td>-8.605665e-03</td>\n",
       "      <td>-2.943770e-01</td>\n",
       "      <td>-2.756335e-01</td>\n",
       "      <td>-7.383328e-01</td>\n",
       "      <td>-7.663352e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.264760e-01</td>\n",
       "      <td>-7.311748e-01</td>\n",
       "      <td>-7.227561e-01</td>\n",
       "      <td>-7.502336e-01</td>\n",
       "      <td>-7.481078e-01</td>\n",
       "      <td>-5.755529e-01</td>\n",
       "      <td>-7.528046e-01</td>\n",
       "      <td>-5.018448e-01</td>\n",
       "      <td>-7.760707e-01</td>\n",
       "      <td>-4.570796e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-1.701149e-02</td>\n",
       "      <td>1.429840e-02</td>\n",
       "      <td>-1.874991e-01</td>\n",
       "      <td>-1.923706e-01</td>\n",
       "      <td>9.958785e-04</td>\n",
       "      <td>-1.561686e-03</td>\n",
       "      <td>-1.994687e-01</td>\n",
       "      <td>-2.314391e-01</td>\n",
       "      <td>-2.150629e-01</td>\n",
       "      <td>-2.388728e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.396704e-01</td>\n",
       "      <td>-1.343923e-01</td>\n",
       "      <td>-1.233851e-01</td>\n",
       "      <td>-1.365864e-01</td>\n",
       "      <td>-1.625555e-01</td>\n",
       "      <td>-3.101662e-01</td>\n",
       "      <td>-1.459509e-01</td>\n",
       "      <td>-3.453614e-01</td>\n",
       "      <td>-1.584955e-01</td>\n",
       "      <td>-2.448200e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.127595e-01</td>\n",
       "      <td>1.334502e-01</td>\n",
       "      <td>9.040556e-02</td>\n",
       "      <td>1.231454e-01</td>\n",
       "      <td>2.565321e-02</td>\n",
       "      <td>7.447437e-03</td>\n",
       "      <td>-7.748910e-02</td>\n",
       "      <td>-1.606479e-01</td>\n",
       "      <td>6.101081e-01</td>\n",
       "      <td>6.079683e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.685832e-01</td>\n",
       "      <td>5.514987e-01</td>\n",
       "      <td>6.032076e-01</td>\n",
       "      <td>6.188211e-01</td>\n",
       "      <td>6.149811e-01</td>\n",
       "      <td>1.447824e-01</td>\n",
       "      <td>6.080188e-01</td>\n",
       "      <td>4.584714e-02</td>\n",
       "      <td>6.342130e-01</td>\n",
       "      <td>7.356943e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.721768e+01</td>\n",
       "      <td>4.991402e+01</td>\n",
       "      <td>1.586540e+01</td>\n",
       "      <td>1.694057e+01</td>\n",
       "      <td>3.429427e+01</td>\n",
       "      <td>3.467825e+01</td>\n",
       "      <td>2.857527e+01</td>\n",
       "      <td>1.822551e+01</td>\n",
       "      <td>4.312907e+00</td>\n",
       "      <td>3.527370e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.518335e+01</td>\n",
       "      <td>1.361776e+01</td>\n",
       "      <td>1.412638e+01</td>\n",
       "      <td>1.407828e+01</td>\n",
       "      <td>1.571455e+01</td>\n",
       "      <td>8.030558e+00</td>\n",
       "      <td>1.391283e+01</td>\n",
       "      <td>1.269492e+01</td>\n",
       "      <td>1.147404e+01</td>\n",
       "      <td>1.507325e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acceleration_mean  acceleration_median  acceleration_std  \\\n",
       "count       7.939000e+03         7.939000e+03      7.939000e+03   \n",
       "mean       -1.117997e-15        -3.582131e-16     -5.544822e-17   \n",
       "std         1.000063e+00         1.000063e+00      1.000063e+00   \n",
       "min        -1.403143e+01        -1.487927e+01     -1.263256e+00   \n",
       "25%        -1.389243e-01        -1.059107e-01     -4.052873e-01   \n",
       "50%        -1.701149e-02         1.429840e-02     -1.874991e-01   \n",
       "75%         1.127595e-01         1.334502e-01      9.040556e-02   \n",
       "max         4.721768e+01         4.991402e+01      1.586540e+01   \n",
       "\n",
       "       acceleration_spread  gyro_pc_mean  gyro_pc_median   gyro_pc_std  \\\n",
       "count         7.939000e+03  7.939000e+03    7.939000e+03  7.939000e+03   \n",
       "mean         -1.301040e-16  2.805362e-17   -5.848874e-18 -5.993023e-17   \n",
       "std           1.000063e+00  1.000063e+00    1.000063e+00  1.000063e+00   \n",
       "min          -1.265030e+00 -7.505363e+01   -7.457329e+01 -6.390963e-01   \n",
       "25%          -4.342546e-01 -2.422009e-02   -8.605665e-03 -2.943770e-01   \n",
       "50%          -1.923706e-01  9.958785e-04   -1.561686e-03 -1.994687e-01   \n",
       "75%           1.231454e-01  2.565321e-02    7.447437e-03 -7.748910e-02   \n",
       "max           1.694057e+01  3.429427e+01    3.467825e+01  2.857527e+01   \n",
       "\n",
       "       gyro_pc_spread    speed_mean  speed_median  ...   second_mean  \\\n",
       "count    7.939000e+03  7.939000e+03  7.939000e+03  ...  7.939000e+03   \n",
       "mean    -6.174121e-18  3.027906e-16  6.368504e-17  ...  1.164902e-17   \n",
       "std      1.000063e+00  1.000063e+00  1.000063e+00  ...  1.000063e+00   \n",
       "min     -4.769338e-01 -1.987609e+00 -1.409070e+00  ... -1.755744e+00   \n",
       "25%     -2.756335e-01 -7.383328e-01 -7.663352e-01  ... -7.264760e-01   \n",
       "50%     -2.314391e-01 -2.150629e-01 -2.388728e-01  ... -1.396704e-01   \n",
       "75%     -1.606479e-01  6.101081e-01  6.079683e-01  ...  5.685832e-01   \n",
       "max      1.822551e+01  4.312907e+00  3.527370e+00  ...  1.518335e+01   \n",
       "\n",
       "       second_median    second_std  second_spread  num_non_speed_outlier  \\\n",
       "count   7.939000e+03  7.939000e+03   7.939000e+03           7.939000e+03   \n",
       "mean   -1.552271e-17  6.267817e-17   3.945005e-17           9.817062e-18   \n",
       "std     1.000063e+00  1.000063e+00   1.000063e+00           1.000063e+00   \n",
       "min    -1.718727e+00 -1.882765e+00  -1.878490e+00          -1.775224e+00   \n",
       "25%    -7.311748e-01 -7.227561e-01  -7.502336e-01          -7.481078e-01   \n",
       "50%    -1.343923e-01 -1.233851e-01  -1.365864e-01          -1.625555e-01   \n",
       "75%     5.514987e-01  6.032076e-01   6.188211e-01           6.149811e-01   \n",
       "max     1.361776e+01  1.412638e+01   1.407828e+01           1.571455e+01   \n",
       "\n",
       "       num_speed_outlier  num_non_accel_outlier  num_accel_outlier  \\\n",
       "count       7.939000e+03           7.939000e+03       7.939000e+03   \n",
       "mean       -1.298034e-16          -3.865293e-17       9.133224e-17   \n",
       "std         1.000063e+00           1.000063e+00       1.000063e+00   \n",
       "min        -8.030272e-01          -1.709059e+00      -5.800865e-01   \n",
       "25%        -5.755529e-01          -7.528046e-01      -5.018448e-01   \n",
       "50%        -3.101662e-01          -1.459509e-01      -3.453614e-01   \n",
       "75%         1.447824e-01           6.080188e-01       4.584714e-02   \n",
       "max         8.030558e+00           1.391283e+01       1.269492e+01   \n",
       "\n",
       "       num_non_gyro_outlier  num_gyro_outlier  \n",
       "count          7.939000e+03      7.939000e+03  \n",
       "mean           7.141843e-17     -2.261455e-16  \n",
       "std            1.000063e+00      1.000063e+00  \n",
       "min           -1.716260e+00     -7.754690e-01  \n",
       "25%           -7.760707e-01     -4.570796e-01  \n",
       "50%           -1.584955e-01     -2.448200e-01  \n",
       "75%            6.342130e-01      7.356943e-02  \n",
       "max            1.147404e+01      1.507325e+01  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_mean</th>\n",
       "      <th>acceleration_median</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>acceleration_spread</th>\n",
       "      <th>gyro_pc_mean</th>\n",
       "      <th>gyro_pc_median</th>\n",
       "      <th>gyro_pc_std</th>\n",
       "      <th>gyro_pc_spread</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>...</th>\n",
       "      <th>second_mean</th>\n",
       "      <th>second_median</th>\n",
       "      <th>second_std</th>\n",
       "      <th>second_spread</th>\n",
       "      <th>num_non_speed_outlier</th>\n",
       "      <th>num_speed_outlier</th>\n",
       "      <th>num_non_accel_outlier</th>\n",
       "      <th>num_accel_outlier</th>\n",
       "      <th>num_non_gyro_outlier</th>\n",
       "      <th>num_gyro_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-5.931926e-17</td>\n",
       "      <td>-9.702851e-16</td>\n",
       "      <td>2.048127e-16</td>\n",
       "      <td>-1.195032e-17</td>\n",
       "      <td>-1.862621e-17</td>\n",
       "      <td>1.458393e-17</td>\n",
       "      <td>-1.572663e-16</td>\n",
       "      <td>6.953305e-18</td>\n",
       "      <td>-2.386893e-16</td>\n",
       "      <td>-1.102081e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.325812e-17</td>\n",
       "      <td>-4.052372e-17</td>\n",
       "      <td>-2.556510e-17</td>\n",
       "      <td>-1.317165e-16</td>\n",
       "      <td>1.972001e-16</td>\n",
       "      <td>1.158644e-17</td>\n",
       "      <td>3.585455e-17</td>\n",
       "      <td>-4.340592e-17</td>\n",
       "      <td>1.339070e-16</td>\n",
       "      <td>-3.594823e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-9.517856e+00</td>\n",
       "      <td>-9.678875e+00</td>\n",
       "      <td>-1.406150e+00</td>\n",
       "      <td>-1.379592e+00</td>\n",
       "      <td>-1.043166e+01</td>\n",
       "      <td>-9.735176e+00</td>\n",
       "      <td>-7.270629e-01</td>\n",
       "      <td>-4.629994e-01</td>\n",
       "      <td>-1.865650e+00</td>\n",
       "      <td>-1.395112e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.602576e+00</td>\n",
       "      <td>-1.568730e+00</td>\n",
       "      <td>-1.854968e+00</td>\n",
       "      <td>-1.842653e+00</td>\n",
       "      <td>-1.761975e+00</td>\n",
       "      <td>-7.863839e-01</td>\n",
       "      <td>-1.724276e+00</td>\n",
       "      <td>-5.614917e-01</td>\n",
       "      <td>-1.710210e+00</td>\n",
       "      <td>-7.886986e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-9.932039e-02</td>\n",
       "      <td>-7.957876e-02</td>\n",
       "      <td>-4.246305e-01</td>\n",
       "      <td>-4.625899e-01</td>\n",
       "      <td>-3.243065e-01</td>\n",
       "      <td>-1.786610e-01</td>\n",
       "      <td>-3.213616e-01</td>\n",
       "      <td>-2.587445e-01</td>\n",
       "      <td>-7.470991e-01</td>\n",
       "      <td>-7.792574e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.799369e-01</td>\n",
       "      <td>-6.968992e-01</td>\n",
       "      <td>-7.427452e-01</td>\n",
       "      <td>-7.444038e-01</td>\n",
       "      <td>-7.706154e-01</td>\n",
       "      <td>-5.618027e-01</td>\n",
       "      <td>-7.563422e-01</td>\n",
       "      <td>-4.780220e-01</td>\n",
       "      <td>-7.737081e-01</td>\n",
       "      <td>-4.612986e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-1.508900e-02</td>\n",
       "      <td>-2.272165e-03</td>\n",
       "      <td>-1.587854e-01</td>\n",
       "      <td>-1.717348e-01</td>\n",
       "      <td>-1.138947e-02</td>\n",
       "      <td>-5.136919e-02</td>\n",
       "      <td>-1.958964e-01</td>\n",
       "      <td>-2.089942e-01</td>\n",
       "      <td>-2.424808e-01</td>\n",
       "      <td>-2.662417e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.474542e-01</td>\n",
       "      <td>-1.492960e-01</td>\n",
       "      <td>-1.370580e-01</td>\n",
       "      <td>-1.459317e-01</td>\n",
       "      <td>-1.716688e-01</td>\n",
       "      <td>-3.176928e-01</td>\n",
       "      <td>-1.637299e-01</td>\n",
       "      <td>-3.110827e-01</td>\n",
       "      <td>-1.723753e-01</td>\n",
       "      <td>-2.157487e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.830606e-02</td>\n",
       "      <td>7.102765e-02</td>\n",
       "      <td>1.681711e-01</td>\n",
       "      <td>1.762076e-01</td>\n",
       "      <td>2.882491e-01</td>\n",
       "      <td>1.208569e-01</td>\n",
       "      <td>-2.988886e-02</td>\n",
       "      <td>-1.315703e-01</td>\n",
       "      <td>5.971829e-01</td>\n",
       "      <td>6.360827e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.535852e-01</td>\n",
       "      <td>5.266646e-01</td>\n",
       "      <td>6.472530e-01</td>\n",
       "      <td>6.609556e-01</td>\n",
       "      <td>6.234845e-01</td>\n",
       "      <td>1.509984e-01</td>\n",
       "      <td>6.190121e-01</td>\n",
       "      <td>5.061919e-02</td>\n",
       "      <td>6.359736e-01</td>\n",
       "      <td>1.116513e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.184967e+01</td>\n",
       "      <td>3.233498e+01</td>\n",
       "      <td>1.769901e+01</td>\n",
       "      <td>1.528644e+01</td>\n",
       "      <td>1.382471e+01</td>\n",
       "      <td>1.179318e+01</td>\n",
       "      <td>1.604057e+01</td>\n",
       "      <td>2.192246e+01</td>\n",
       "      <td>3.946116e+00</td>\n",
       "      <td>3.199149e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.370491e+01</td>\n",
       "      <td>2.264750e+01</td>\n",
       "      <td>6.607630e+00</td>\n",
       "      <td>6.626252e+00</td>\n",
       "      <td>7.748884e+00</td>\n",
       "      <td>1.085278e+01</td>\n",
       "      <td>7.678506e+00</td>\n",
       "      <td>1.051215e+01</td>\n",
       "      <td>7.704098e+00</td>\n",
       "      <td>1.652257e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acceleration_mean  acceleration_median  acceleration_std  \\\n",
       "count       3.852000e+03         3.852000e+03      3.852000e+03   \n",
       "mean       -5.931926e-17        -9.702851e-16      2.048127e-16   \n",
       "std         1.000130e+00         1.000130e+00      1.000130e+00   \n",
       "min        -9.517856e+00        -9.678875e+00     -1.406150e+00   \n",
       "25%        -9.932039e-02        -7.957876e-02     -4.246305e-01   \n",
       "50%        -1.508900e-02        -2.272165e-03     -1.587854e-01   \n",
       "75%         6.830606e-02         7.102765e-02      1.681711e-01   \n",
       "max         3.184967e+01         3.233498e+01      1.769901e+01   \n",
       "\n",
       "       acceleration_spread  gyro_pc_mean  gyro_pc_median   gyro_pc_std  \\\n",
       "count         3.852000e+03  3.852000e+03    3.852000e+03  3.852000e+03   \n",
       "mean         -1.195032e-17 -1.862621e-17    1.458393e-17 -1.572663e-16   \n",
       "std           1.000130e+00  1.000130e+00    1.000130e+00  1.000130e+00   \n",
       "min          -1.379592e+00 -1.043166e+01   -9.735176e+00 -7.270629e-01   \n",
       "25%          -4.625899e-01 -3.243065e-01   -1.786610e-01 -3.213616e-01   \n",
       "50%          -1.717348e-01 -1.138947e-02   -5.136919e-02 -1.958964e-01   \n",
       "75%           1.762076e-01  2.882491e-01    1.208569e-01 -2.988886e-02   \n",
       "max           1.528644e+01  1.382471e+01    1.179318e+01  1.604057e+01   \n",
       "\n",
       "       gyro_pc_spread    speed_mean  speed_median  ...   second_mean  \\\n",
       "count    3.852000e+03  3.852000e+03  3.852000e+03  ...  3.852000e+03   \n",
       "mean     6.953305e-18 -2.386893e-16 -1.102081e-16  ... -1.325812e-17   \n",
       "std      1.000130e+00  1.000130e+00  1.000130e+00  ...  1.000130e+00   \n",
       "min     -4.629994e-01 -1.865650e+00 -1.395112e+00  ... -1.602576e+00   \n",
       "25%     -2.587445e-01 -7.470991e-01 -7.792574e-01  ... -6.799369e-01   \n",
       "50%     -2.089942e-01 -2.424808e-01 -2.662417e-01  ... -1.474542e-01   \n",
       "75%     -1.315703e-01  5.971829e-01  6.360827e-01  ...  5.535852e-01   \n",
       "max      2.192246e+01  3.946116e+00  3.199149e+00  ...  2.370491e+01   \n",
       "\n",
       "       second_median    second_std  second_spread  num_non_speed_outlier  \\\n",
       "count   3.852000e+03  3.852000e+03   3.852000e+03           3.852000e+03   \n",
       "mean   -4.052372e-17 -2.556510e-17  -1.317165e-16           1.972001e-16   \n",
       "std     1.000130e+00  1.000130e+00   1.000130e+00           1.000130e+00   \n",
       "min    -1.568730e+00 -1.854968e+00  -1.842653e+00          -1.761975e+00   \n",
       "25%    -6.968992e-01 -7.427452e-01  -7.444038e-01          -7.706154e-01   \n",
       "50%    -1.492960e-01 -1.370580e-01  -1.459317e-01          -1.716688e-01   \n",
       "75%     5.266646e-01  6.472530e-01   6.609556e-01           6.234845e-01   \n",
       "max     2.264750e+01  6.607630e+00   6.626252e+00           7.748884e+00   \n",
       "\n",
       "       num_speed_outlier  num_non_accel_outlier  num_accel_outlier  \\\n",
       "count       3.852000e+03           3.852000e+03       3.852000e+03   \n",
       "mean        1.158644e-17           3.585455e-17      -4.340592e-17   \n",
       "std         1.000130e+00           1.000130e+00       1.000130e+00   \n",
       "min        -7.863839e-01          -1.724276e+00      -5.614917e-01   \n",
       "25%        -5.618027e-01          -7.563422e-01      -4.780220e-01   \n",
       "50%        -3.176928e-01          -1.637299e-01      -3.110827e-01   \n",
       "75%         1.509984e-01           6.190121e-01       5.061919e-02   \n",
       "max         1.085278e+01           7.678506e+00       1.051215e+01   \n",
       "\n",
       "       num_non_gyro_outlier  num_gyro_outlier  \n",
       "count          3.852000e+03      3.852000e+03  \n",
       "mean           1.339070e-16     -3.594823e-16  \n",
       "std            1.000130e+00      1.000130e+00  \n",
       "min           -1.710210e+00     -7.886986e-01  \n",
       "25%           -7.737081e-01     -4.612986e-01  \n",
       "50%           -1.723753e-01     -2.157487e-01  \n",
       "75%            6.359736e-01      1.116513e-01  \n",
       "max            7.704098e+00      1.652257e+01  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = pd.DataFrame(scaler.fit_transform(X_test), columns = X_test.columns)\n",
    "X_test_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to build model\n",
    "\n",
    "Writing a function here so that the Keras sklearn wrapper can be used for the GridSearchCV (last section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_layers=1, num_nodes=32, lr=0.001, dropout=False, opt=\"SGD\", input_shape=(24,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_nodes, activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    if dropout:\n",
    "        model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    if num_layers > 1:\n",
    "        for i in range(num_layers - 1):\n",
    "            model.add(Dense(num_nodes, activation='relu'))\n",
    "            if dropout:\n",
    "                model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if opt == \"SGD\":\n",
    "        optimiser = optimizers.SGD(lr=lr)\n",
    "    elif opt == \"RMSprop\":\n",
    "        optimiser = optimizers.RMSprop(lr=lr)\n",
    "    elif opt == \"Adam\":\n",
    "        optimiser = optimizers.Adam(lr=lr)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", \n",
    "               optimizer=optimiser,\n",
    "               metrics=[\"accuracy\"])\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomised grid search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params)\n",
    "\n",
    "params = {'num_nodes' : [32, 64, 128, 256, 512],\n",
    "         'num_layers' : [1, 2], \n",
    "         'lr' : [0.0001, 0.001, 0.01, 0.1],\n",
    "         'dropout' : [True, False],\n",
    "         'opt' : [\"Adam\"]}\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=60, batch_size=32)\n",
    "# grid = GridSearchCV(model, param_grid=params, n_jobs=4, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "seed = 199\n",
    "num_iter = 5\n",
    "\n",
    "random_grid = RandomizedSearchCV(estimator=model, \n",
    "                                 param_distributions=params, \n",
    "                                 scoring='roc_auc', n_iter=num_iter, cv=5, n_jobs=-1,\n",
    "                                 random_state=seed)\n",
    "random_grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(random_grid.best_score_)\n",
    "print(random_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1 of 5\n",
      "Total time taken: 69 seconds\n",
      "Processing fold 2 of 5\n",
      "Total time taken: 139 seconds\n",
      "Processing fold 3 of 5\n",
      "Total time taken: 210 seconds\n",
      "Processing fold 4 of 5\n",
      "Total time taken: 286 seconds\n",
      "Processing fold 5 of 5\n",
      "Total time taken: 365 seconds\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "k = 5\n",
    "num_val_samples = X_train_scaled.shape[0] // k\n",
    "num_epochs = 60\n",
    "batch_size = 32\n",
    "all_val_loss = []\n",
    "all_train_loss = []\n",
    "all_val_acc = []\n",
    "all_train_acc = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('Processing fold {} of {}'.format(i + 1, k))\n",
    "\n",
    "    val_data = X_train_scaled[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    partial_train_data = np.concatenate([X_train_scaled[:i * num_val_samples], \n",
    "                                         X_train_scaled[(i + 1) * num_val_samples:]], axis=0)\n",
    "    partial_train_targets = np.concatenate([y_train[:i * num_val_samples], \n",
    "                                            y_train[(i + 1) * num_val_samples:]], axis=0)\n",
    "    \n",
    "    model = build_model(num_layers=2, num_nodes=128, lr=0.0001, opt=\"Adam\", dropout=True, input_shape=((22,)))\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, verbose=0,\n",
    "                        validation_data=((val_data, val_targets)), batch_size=batch_size)\n",
    "\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "    all_val_loss.append(val_loss)\n",
    "    all_train_loss.append(loss)\n",
    "    all_val_acc.append(val_acc)\n",
    "    all_train_acc.append(acc)\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"Total time taken: {} seconds\".format((end_time - start_time).seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.592877481446158, train acc: 0.6627203822135925\n",
      "Val loss: 0.5974381052253376, val acc: 0.659735357761383\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0YAAAHgCAYAAACB/n3CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeXhV1b3/8fdijDJDghMiqGgFZDIiFhVIrYrUCRlEkVqnVts6Va+0j63W6v1Z67XUOtXaa2udiijqdaJqEYfWASdUUEFBxREQUGQMrN8fK4HIGCAn+yR5v55nPztnZ59zvkdNm0/Wd60VYoxIkiRJUl1WL+sCJEmSJClrBiNJkiRJdZ7BSJIkSVKdZzCSJEmSVOcZjCRJkiTVeQYjSZIkSXVeg6wLqCqFhYWxQ4cOWZchSZIkKY+99NJLc2OMRWtfrzXBqEOHDkyePDnrMiRJkiTlsRDC++u7biudJEmSpDrPYCRJkiSpzjMYSZIkSarzas0cI0mSJCmXVqxYwezZs1m6dGnWpagSCgoKaNeuHQ0bNqzU/QYjSZIkqRJmz55Ns2bN6NChAyGErMvRRsQYmTdvHrNnz6Zjx46Veo6tdJIkSVIlLF26lDZt2hiKaoAQAm3atNms0T2DkSRJklRJhqKaY3P/XRmMJEmSpBpg3rx59OjRgx49erD99tuz0047rX68fPnySr3GD37wA95+++2N3nPddddx++23V0XJHHDAAbz66qtV8lq55hwjSZIkqQZo06bN6pBxySWX0LRpU84///xv3BNjJMZIvXrrH/+45ZZbNvk+P/7xj7e+2BrIESNJkiSpBpsxYwZdu3blRz/6Eb169eKTTz7h9NNPp7i4mC5dunDppZeuvrd8BKe0tJSWLVsyevRounfvzv7778/nn38OwEUXXcSYMWNW3z969Gh69+7Nnnvuyb///W8Avv76a4499li6d+/OiBEjKC4u3uTI0G233cbee+9N165d+cUvfgFAaWkpJ5544urr11xzDQC///3v6dy5M927d2fkyJFV/s9sfRwxkiRJkjbXOedAVbeI9egBZYFkc02dOpVbbrmFG2+8EYArrriC1q1bU1payoABAxgyZAidO3f+xnMWLlxIv379uOKKKzjvvPP43//9X0aPHr3Oa8cYeeGFF3jggQe49NJLefTRR/njH//I9ttvzz333MNrr71Gr169Nlrf7Nmzueiii5g8eTItWrTg4IMP5sEHH6SoqIi5c+fy+uuvA7BgwQIArrzySt5//30aNWq0+lquOWIkSZIk1XC77bYb++677+rHd955J7169aJXr15MmzaNqVOnrvOcbbbZhoEDBwKwzz77MGvWrPW+9uDBg9e555lnnuG4444DoHv37nTp0mWj9T3//POUlJRQWFhIw4YNOf7443nqqafYfffdefvttzn77LOZMGECLVq0AKBLly6MHDmS22+/vdL7EG0tR4wkSZKkzbWFIzu50qRJk9VfT58+nT/84Q+88MILtGzZkpEjR6532epGjRqt/rp+/fqUlpau97UbN268zj0xxs2qb0P3t2nThilTpvDII49wzTXXcM8993DTTTcxYcIEJk2axP33389ll13GG2+8Qf369TfrPTeXI0aSJElSLfLll1/SrFkzmjdvzieffMKECROq/D0OOOAAxo4dC8Drr7++3hGpivr06cPEiROZN28epaWl3HXXXfTr1485c+YQY2To0KH8+te/5uWXX2blypXMnj2bkpISfve73zFnzhwWL15c5Z9hbY4YSZIkSbVIr1696Ny5M127dmXXXXelb9++Vf4eP/3pTxk1ahTdunWjV69edO3adXUb3Pq0a9eOSy+9lP79+xNj5IgjjmDQoEG8/PLLnHLKKcQYCSHw29/+ltLSUo4//ni++uorVq1axYUXXkizZs2q/DOsLWzuMFi+Ki4ujpMnT866DEmSJNVS06ZNY6+99sq6jLxQWlpKaWkpBQUFTJ8+nUMOOYTp06fToEF+jbus799ZCOGlGGPx2vfmV+W1xdKl6WjZMutKJEmSpCq3aNEivvOd71BaWkqMkT/96U95F4o2V82uPl/tvz/svDM88EDWlUiSJElVrmXLlrz00ktZl1GlXHwhFwoLYe7crKuQJEmSVEkGo1woKoI5c7KuQpIkSVIlGYxywWAkSZIk1SgGo1woLISFC2H58qwrkSRJklQJBqNcKCpK53nzsq1DkiRJtUb//v3X2ax1zJgxnHnmmRt9XtOmTQH4+OOPGTJkyAZfe1Nb34wZM+YbG60efvjhLFiwoDKlb9Qll1zCVVddtdWvs7UMRrlQHoxsp5MkSVIVGTFiBHfdddc3rt11112MGDGiUs/fcccdGTdu3Ba//9rB6OGHH6ZlLdqexmCUCwYjSZIkVbEhQ4bw4IMPsmzZMgBmzZrFxx9/zAEHHLB6X6FevXqx9957c//996/z/FmzZtG1a1cAlixZwnHHHUe3bt0YPnw4S5YsWX3fGWecQXFxMV26dOHiiy8G4JprruHjjz9mwIABDBgwAIAOHTowt2wl5quvvpquXbvStWtXxowZs/r99tprL0477TS6dOnCIYcc8o33WZ9XX32VPn360K1bN4455hjmz5+/+v07d+5Mt27dOO644wCYNGkSPXr0oEePHvTs2ZOvvvpqi//ZgvsY5UZhYTobjCRJkmqlc86BV1+t2tfs0QPKMsV6tWnTht69e/Poo49y1FFHcddddzF8+HBCCBQUFDB+/HiaN2/O3Llz6dOnD0ceeSQhhPW+1g033MC2227LlClTmDJlCr169Vr9vcsvv5zWrVuzcuVKvvOd7zBlyhTOOussrr76aiZOnEhh+e+6ZV566SVuueUWnn/+eWKM7LfffvTr149WrVoxffp07rzzTv785z8zbNgw7rnnHkaOHLnBzzhq1Cj++Mc/0q9fP371q1/x61//mjFjxnDFFVcwc+ZMGjduvLp976qrruK6666jb9++LFq0iIKCgs34p70uR4xyoXzEyL2MJEmSVIUqttNVbKOLMfKLX/yCbt26cfDBB/PRRx/x2WefbfB1nnrqqdUBpVu3bnTr1m3198aOHUuvXr3o2bMnb775JlOnTt1oTc888wzHHHMMTZo0oWnTpgwePJinn34agI4dO9KjRw8A9tlnH2bNmrXB11m4cCELFiygX79+AHz/+9/nqaeeWl3jCSecwG233UaDBmlsp2/fvpx33nlcc801LFiwYPX1LeWIUS60bg0hOGIkSZJUS21sZCeXjj76aM477zxefvlllixZsnqk5/bbb2fOnDm89NJLNGzYkA4dOrB06dKNvtb6RpNmzpzJVVddxYsvvkirVq046aSTNvk6McYNfq9x48arv65fv/4mW+k25KGHHuKpp57igQce4De/+Q1vvvkmo0ePZtCgQTz88MP06dOHxx9/nG9961tb9PrgiFFu1K+fwpHBSJIkSVWoadOm9O/fn5NPPvkbiy4sXLiQtm3b0rBhQyZOnMj777+/0dc56KCDuP322wF44403mDJlCgBffvklTZo0oUWLFnz22Wc88sgjq5/TrFmz9c7jOeigg7jvvvtYvHgxX3/9NePHj+fAAw/c7M/WokULWrVqtXq06e9//zv9+vVj1apVfPjhhwwYMIArr7ySBQsWsGjRIt5991323ntvLrzwQoqLi3nrrbc2+z0rcsQoV4qKbKWTJElSlRsxYgSDBw/+xgp1J5xwAkcccQTFxcX06NFjkyMnZ5xxBj/4wQ/o1q0bPXr0oHfv3gB0796dnj170qVLF3bddVf69u27+jmnn346AwcOZIcddmDixImrr/fq1YuTTjpp9Wuceuqp9OzZc6Ntcxvyt7/9jR/96EcsXryYXXfdlVtuuYWVK1cycuRIFi5cSIyRc889l5YtW/LLX/6SiRMnUr9+fTp37szAgQM3+/0qChsb+qpJiouL46bWXq9WBx2URo4q/EcjSZKkmmvatGnstddeWZehzbC+f2chhJdijMVr32srXa4UFdlKJ0mSJNUQBqNcKSw0GEmSJEk1hMEoV4qKYN48WLUq60okSZIkbYLBKFeKimDlSijbgEqSJEk1X22Zn18XbO6/K4NRrpTvCGw7nSRJUq1QUFDAvHnzDEc1QIyRefPmUVBQUOnnuFx3rhQVpfOcObDnntnWIkmSpK3Wrl07Zs+ezRz/8F0jFBQU0K5du0rfbzDKlfJg5F5GkiRJtULDhg3p2LFj1mUoR2yly5WKI0aSJEmS8prBKFecYyRJkiTVGAajXCkogKZNbaWTJEmSagCDUS4VFTliJEmSJNUABqNcMhhJkiRJNYLBKJcKCw1GkiRJUg1gMMqloiLnGEmSJEk1gMEol2ylkyRJkmoEg1EuFRbCkiXw9ddZVyJJkiRpIwxGueQmr5IkSVKNYDDKpfJg5DwjSZIkKa/lNBiFEA4LIbwdQpgRQhi9gXuGhRCmhhDeDCHcUeH6lWXXpoUQrgkhhFzWmhOOGEmSJEk1QoNcvXAIoT5wHfBdYDbwYgjhgRjj1Ar3dAJ+DvSNMc4PIbQtu/5toC/QrezWZ4B+wJO5qjcnCgvT2WAkSZIk5bVcjhj1BmbEGN+LMS4H7gKOWuue04DrYozzAWKMn5ddj0AB0AhoDDQEPsthrblhK50kSZJUI+QyGO0EfFjh8eyyaxXtAewRQng2hPBcCOEwgBjjf4CJwCdlx4QY47Qc1pobzZtDw4aOGEmSJEl5LmetdMD65gTF9bx/J6A/0A54OoTQFSgE9iq7BvBYCOGgGONT33iDEE4HTgdo37591VVeVUJI7XQGI0mSJCmv5XLEaDawc4XH7YCP13PP/THGFTHGmcDbpKB0DPBcjHFRjHER8AjQZ+03iDHeFGMsjjEWF5W3reUbN3mVJEmS8l4ug9GLQKcQQscQQiPgOOCBte65DxgAEEIoJLXWvQd8APQLITQIITQkLbxQ81rpIAUj5xhJkiRJeS1nwSjGWAr8BJhACjVjY4xvhhAuDSEcWXbbBGBeCGEqaU7RBTHGecA44F3gdeA14LUY4//lqtaccsRIkiRJynu5nGNEjPFh4OG1rv2qwtcROK/sqHjPSuCHuayt2jjHSJIkScp7Od3gVaQRowULYMWKrCuRJEmStAEGo1wrXxRi3rxs65AkSZK0QQajXCssTGfb6SRJkqS8ZTDKtfIRI4ORJEmSlLcMRrlWHoxcsluSJEnKWwajXHPESJIkScp7BqNca906nQ1GkiRJUt4yGOVagwYpHBmMJEmSpLxlMKoORUXOMZIkSZLymMGoOhQVOWIkSZIk5TGDUXUoLDQYSZIkSXnMYFQdbKWTJEmS8prBqDqUB6MYs65EkiRJ0noYjKpDYSGUlsKCBVlXIkmSJGk9DEbVwU1eJUmSpLxmMKoO5cHIeUaSJElSXjIYVQdHjCRJkqS8ZjCqDoWF6WwwkiRJkvKSwag6OGIkSZIk5TWDUXXYZhto0sQ5RpIkSVKeMhhVl8JCR4wkSZKkPGUwqi5FRQYjSZIkKU8ZjKpLUZGtdJIkSVKeMhhVF0eMJEmSpLxlMKouzjGSJEmS8pbBqLoUFcHixemQJEmSlFcMRtWlfC8j5xlJkiRJecdgVF0KC9PZdjpJkiQp7xiMqkv5iJHBSJIkSco7BqPqYjCSJEmS8pbBqLo4x0iSJEnKWwaj6tKiBTRo4IiRJEmSlIcMRtUlBPcykiRJkvKUwag6FRXZSidJkiTlIYNRdSoqcsRIkiRJykMGo+pkK50kSZKUlwxG1ckRI0mSJCkvGYyqU1ERzJ8PpaVZVyJJkiSpAoNRdSosTOd587KtQ5IkSdI3GIyqU/kmr7bTSZIkSXnFYFSdDEaSJElSXjIYVafyYOReRpIkSVJeMRhVp/I5Ro4YSZIkSXnFYFSd2rRJZ4ORJEmSlFcMRtWpYUNo1cpWOkmSJCnPGIyqW2GhI0aSJElSnjEYVbeiIoORJEmSlGcMRtXNYCRJkiTlHYNRdSsqco6RJEmSlGcMRtWtsDAFoxizrkSSJElSGYNRdSsqghUrYOHCrCuRJEmSVMZgVN2KitLZeUaSJElS3jAYVbfCwnR2npEkSZKUNwxG1c0RI0mSJCnvGIyqm8FIkiRJyjsGo+pWHoxspZMkSZLyhsGoum27LWyzjSNGkiRJUh4xGGWhqMhgJEmSJOURg1EWDEaSJElSXjEYZaGoyDlGkiRJUh4xGGWhsNARI0mSJCmPGIyyYCudJEmSlFcMRlkoKoKvv4YlS7KuRJIkSRIGo2wUFqaz84wkSZKkvGAwykL5Jq+200mSJEl5wWCUBYORJEmSlFcMRlkoD0a20kmSJEl5wWCUhfI5Ro4YSZIkSXnBYJSFli2hfn2DkSRJkpQnDEZZqFfPTV4lSZKkPGIwykphoXOMJEmSpDxhMMpKUZEjRpIkSVKeMBhlxWAkSZIk5Q2DUVaKimylkyRJkvJEToNRCOGwEMLbIYQZIYTRG7hnWAhhagjhzRDCHRWutw8h/DOEMK3s+x1yWWu1KyyEL76AlSuzrkSSJEmq8xrk6oVDCPWB64DvArOBF0MID8QYp1a4pxPwc6BvjHF+CKFthZe4Fbg8xvhYCKEpsCpXtWaiqAhihHnzoG3bTd8vSZIkKWdyOWLUG5gRY3wvxrgcuAs4aq17TgOuizHOB4gxfg4QQugMNIgxPlZ2fVGMcXEOa61+RUXp7DwjSZIkKXO5DEY7AR9WeDy77FpFewB7hBCeDSE8F0I4rML1BSGEe0MIr4QQflc2AlV7FBams/OMJEmSpMzlMhiF9VyLaz1uAHQC+gMjgJtDCC3Lrh8InA/sC+wKnLTOG4Rweghhcghh8pyaNvLiiJEkSZKUN3IZjGYDO1d43A74eD333B9jXBFjnAm8TQpKs4FXytrwSoH7gF5rv0GM8aYYY3GMsbioPGjUFAYjSZIkKW/kMhi9CHQKIXQMITQCjgMeWOue+4ABACGEQlIL3Xtlz20VQihPOyXAVGqT8lY6g5EkSZKUuZwFo7KRnp8AE4BpwNgY45shhEtDCEeW3TYBmBdCmApMBC6IMc6LMa4ktdE9EUJ4ndSW9+dc1ZqJhg2hRQvnGEmSJEl5IGfLdQPEGB8GHl7r2q8qfB2B88qOtZ/7GNAtl/VlrqjIESNJkiQpD+R0g1dtgsFIkiRJygsGoywVFdlKJ0mSJOUBg1GWCgsdMZIkSZLygMEoS+WtdHHt7Z0kSZIkVSeDUZaKimDFCvjyy6wrkSRJkuo0g1GWyvcycp6RJEmSlCmDUZaKyvavdZ6RJEmSlCmDUZYMRpIkSVJeMBhlyWAkSZIk5QWDUZacYyRJkiTlBYNRlpo0gYICR4wkSZKkjBmMshTCmr2MJEmSJGXGYJS1wkJb6SRJkqSMGYyy5oiRJEmSlDmDUdYMRpIkSVLmDEZZMxhJkiRJmTMYZa2wEBYtgqVLs65EkiRJqrMMRlkr3+TVBRgkSZKkzBiMslYejGynkyRJkjJjMMpaYWE6G4wkSZKkzBiMsmYrnSRJkpQ5g1HWbKWTJEmSMmcwylqrVlCvnsFIkiRJypDBKGv16kGbNrbSSZIkSRkyGOUDN3mVJEmSMmUwygc77QRvv511FZIkSVKdZTDKB4MGwZtvwjvvZF2JJEmSVCcZjPLBscem8913Z1uHJEmSVEcZjPJBu3aw//4wblzWlUiSJEl1ksEoXwwZAq++CjNmZF2JJEmSVOcYjPLFkCHp7KiRJEmSVO0MRvmifXvYbz/nGUmSJEkZMBjlkyFD4OWX4b33sq5EkiRJqlMMRvnEdjpJkiQpEwajfNKhA+y7r+10kiRJUjUzGOWbIUNg8mSYOTPrSiRJkqQ6w2CUb8rb6e65J9s6JEmSpDrEYJRvdt0VevWynU6SJEmqRgajfDR0KLzwArz/ftaVSJIkSXWCwSgf2U4nSZIkVSuDUT7afXfo0cN2OkmSJKmaGIzy1dCh8Nxz8OGHWVciSZIk1XoGo3xlO50kSZJUbQxG+WqPPaBbN9vpJEmSpGpgMMpnQ4fCv/8NH32UdSWSJElSrWYwymdDh6az7XSSJElSThmM8tmee0LXrrbTSZIkSTlmMMp3Q4fCs8/Cxx9nXYkkSZJUaxmM8t2QIRAj3Htv1pVIkiRJtZbBKN917pwO2+kkSZKknDEY1QRDh8LTT8Onn2ZdiSRJklQrGYxqAtvpJEmSpJwyGNUEXbrAt74F48ZlXYkkSZJUKxmMaoIQUjvdpEnw+edZVyNJkiTVOgajmmLIEFi1ynY6SZIkKQcMRjXF3nvDHnvYTidJkiTlgMGopgghjRpNnAhz5mRdjSRJklSrGIxqkqFDUzvd+PFZVyJJkiTVKgajmqR7d9h9d9vpJEmSpCpmMKpJytvp/vUvmDs362okSZKkWsNgVNMMHQorV8J992VdiSRJklRrGIxqmp49YdddYezYrCuRJEmSag2DUU0TAowYAU88AZ98knU1kiRJUq1gMKqJTjwxrU53xx1ZVyJJkiTVCgajmmjPPaF3b7j11qwrkSRJkmoFg1FNNWoUTJkCr72WdSWSJElSjVepYBRC2C2E0Ljs6/4hhLNCCC1zW5o2avhwaNjQUSNJkiSpClR2xOgeYGUIYXfgL0BHwAkuWSoshEGD4PbbobQ062okSZKkGq2ywWhVjLEUOAYYE2M8F9ghd2WpUkaNgs8+g8cfz7oSSZIkqUarbDBaEUIYAXwfeLDsWsPclKRKO/xwaN3adjpJkiRpK1U2GP0A2B+4PMY4M4TQEbgtd2WpUho3huOOg/Hj4csvs65GkiRJqrEqFYxijFNjjGfFGO8MIbQCmsUYr8hxbaqMUaNg6VIYNy7rSiRJkqQaq7Kr0j0ZQmgeQmgNvAbcEkK4OrelqVJ694ZOnWynkyRJkrZCZVvpWsQYvwQGA7fEGPcBDs5dWaq0ENKo0aRJMGtW1tVIkiRJNVJlg1GDEMIOwDDWLL6wSSGEw0IIb4cQZoQQRm/gnmEhhKkhhDdDCHes9b3mIYSPQgjXVvY966SRI9P5Nqd9SZIkSVuissHoUmAC8G6M8cUQwq7A9I09IYRQH7gOGAh0BkaEEDqvdU8n4OdA3xhjF+CctV7mN8CkStZYd3XoAP36pXa6GLOuRpIkSapxKrv4wt0xxm4xxjPKHr8XYzx2E0/rDcwou3c5cBdw1Fr3nAZcF2OcX/a6n5d/I4SwD7Ad8M/KfZQ6btQomD4dXngh60okSZKkGqeyiy+0CyGMDyF8HkL4LIRwTwih3SaethPwYYXHs8uuVbQHsEcI4dkQwnMhhMPK3q8e8D/ABZuo6/QQwuQQwuQ5c+ZU5qPUXkOGQEGBizBIkiRJW6CyrXS3AA8AO5LCzf+VXduYsJ5ra/d5NQA6Af2BEcDNIYSWwJnAwzHGD9mIGONNMcbiGGNxUVHRJj9Erda8ORxzDNx1FyxblnU1kiRJUo1S2WBUFGO8JcZYWnb8FdhUEpkN7FzhcTvg4/Xcc3+McUWMcSbwNiko7Q/8JIQwC7gKGBVCcN+kTRk1Cr74Ah5+OOtKJEmSpBqlssFobghhZAihftkxEpi3iee8CHQKIXQMITQCjiONOlV0HzAAIIRQSGqtey/GeEKMsX2MsQNwPnBrjHG9q9qpgoMPhu23t51OkiRJ2kyVDUYnk5bq/hT4BBgC/GBjT4gxlgI/Ia1mNw0YG2N8M4RwaQjhyLLbJgDzQghTgYnABTHGTQUubUiDBnD88fDQQzB3btbVSJIkSTVGiFu4vHMI4ZwY45gqrmeLFRcXx8mTJ2ddRvZeew169IBrr4Uf/zjraiRJkqS8EkJ4KcZYvPb1yo4Yrc95W/Fc5Ur37tCtm+10kiRJ0mbYmmC0vlXnlA9GjUr7Gb39dtaVSJIkSTXC1gSjLevBU+4dfzzUqwd//3vWlUiSJEk1wkaDUQjhqxDCl+s5viLtaaR8tMMOcMghKRitWpV1NZIkSVLe22gwijE2izE2X8/RLMbYoLqK1BYYNQo++ACeeirrSiRJkqS8tzWtdMpnRx0FzZq5CIMkSZJUCQaj2mrbbWHoULj7bli8OOtqJEmSpLxmMKrNTjwRFi2C++7LuhJJkiQprxmMarODDoL27W2nkyRJkjbBYFSb1auXRo0eeww++STraiRJkqS8ZTCq7U48MS3ZfccdWVciSZIk5S2DUW23556w335w1VXw2mtZVyNJkiTlJYNRXXDTTVC/PhxwADz4YNbVSJIkSXnHYFQXdOsGL7yQRo+OOgrGjIEYs65KkiRJyhsGo7pixx1h0qQUjM49F848E1asyLoqSZIkKS8YjOqSJk1g3Di48EK48UYYNAgWLMi6KkmSJClzBqO6pl49uOIK+MtfYOJE+Pa34b33sq5KkiRJypTBqK46+WT45z/h00/TqnXPPpt1RZIkSVJmDEZ12YAB8Nxz0LIllJTA7bdnXZEkSZKUCYNRXbfHHikc9ekDI0fCxRe7Yp0kSZLqHIORoE0beOwxOOkkuPRSOP54WLo066okSZKkatMg6wKUJxo1gv/937TX0c9/Dl995WawkiRJqjMMRlojBBg9Oo0W/frXMGsWdOiQdVWSJElSztlKp3WNGpXOd9+dbR2SJElSNTEYaV277gr77gtjx2ZdiSRJklQtDEZav+HDYfJkePfdrCuRJEmScs5gpPUbOjSdHTWSJElSHWAw0vq1bw/7728wkiRJUp1gMNKGDRsGr74K77yTdSWSJElSThmMtGG200mSJKmOMBhpw3baCQ44AP7xj6wrkSRJknLKYKSNGz4c3ngDpk7NuhJJkiQpZwxG2rghQyAE2+kkSZJUqxmMtHHbbw/9+qV2uhizrkaSJEnKCYORNm34cHjrrdRSJ0mSJNVCBiNt2uDBUK+eizBIkiSp1jIYadPatoWSEtvpJEmSVGsZjFQ5w4bBjBlpw1dJkiSpljEYqXIGD4YGDWynkyRJUq1kMFLltGkDBx+clu22nU6SJEm1jMFIlTdsGMycCZMnZ12JJEmSVKUMRqq8o4+Ghg1tp5MkSVKtYzBS5bVqBYccYjudJEmSah2DUQ7ceCP89a9ZV5Ejw31NLMMAACAASURBVIfDhx/Cc89lXYkkSZJUZQxGOfCPf8A112RdRY4ceSQ0apRGjSRJkqRawmCUAyUlabufefOyriQHWrSAgQPh7rth1aqsq5EkSZKqhMEoB0pK0hScSZOyriRHhg+Hjz6CZ5/NuhJJkiSpShiMcmDffaFJE/jXv7KuJEe+9z0oKLCdTpIkSbWGwSgHGjWCAw+EiROzriRHmjWDQYNg3DhYuTLraiRJkqStZjDKkQEDYOpU+PTTrCvJkWHD0od7+umsK5EkSZK2msEoR0pK0rnWjhoNGgTbbutmr5IkSaoVDEY50rNnWsCt1s4zatIEjjgC7rkHSkuzrkaSJEnaKgajHKlfH/r3r8XBCFI73Zw58OSTWVciSZIkbRWDUQ6VlMB778GsWVlXkiMDB0LTprbTSZIkqcYzGOVQrZ9ntM02cOSRcO+9sGJF1tVIkiRJW8xglENdukBRUS1vpxs+HL74Ap54IutKJEmSpC3WIOsCarMQ0qjRv/4FMabHtc6hh0Lz5nDDDencujW0apWORo2yrk6SJEmqFINRjpWUpCk477wDe+6ZdTU50LgxDB0Kf/kLPPDAN7/XpMmaoLT2ef/9YfDgbGqWJEmS1mIwyrGK84xqZTACuPZaOP10mD8/tdVt6Dx9ejp/8QVcdRXccQeMGJF19ZIkSZLBKNd22w3atUvtdD/6UdbV5EhBAfTuXfn7ly+Hgw+Gk0+GPfaAffbJXW2SJElSJbj4Qo6VzzOaOBFWrcq6mjzRqBGMGwdt28LRR8Nnn2VdkSRJkuo4g1E1KCmBuXPhjTeyriSPtG0L990H8+bBscemUSRJkiQpIwajajBgQDrX6mW7t0TPnnDLLfDss/CTn6Sl+yRJkqQMGIyqQfv2sPvuBqP1Gj4cfvEL+POf05LfkiRJUgYMRtWkpAQmTYLS0qwryUO/+Q1873tw9tnw5JNZVyNJkqQ6yGBUTUpK4Msv4eWXs64kD9WrB7fdlobVhg6FWbOyrkiSJEl1jMGomvTvn862021AixZpg9jSUjjqKPj666wrkiRJUh1iMKom220HXbsajDaqUye46660fN9JJ7kYgyRJkqqNwagaDRgAzzzjytQbdeihcOWVaZ+jyy/PuhpJkiTVEQajalRSAkuWwPPPZ11JnjvvPBg5En75S7j//s17bmkpvPYaTJmSm9okSZJUKxmMqlG/fhCC7XSbFALcdBPsu28KSG++ueF7P/kkbRQ7enQakmvZEnr0gO7d0xLgkiRJUiWEWEvmcRQXF8fJkydnXcYmFRdDkyZp6W5twkcfrfkH9sILsO22aVm/55+H555LxwcfpHsbNEiBqE+fdNxxBzz8cApYp52W7eeQJElS3gghvBRjLF77eoMsiqnLSkpgzBhYvDj9nq+N2GknuPfetKRf587wxRewYkX63i67pAB0zjmw337Qsydss82a5x57bDpOPz09NhxJkiRpI3LaShdCOCyE8HYIYUYIYfQG7hkWQpgaQngzhHBH2bUeIYT/lF2bEkIYnss6q1NJSfrd/tlns66khth/f/jb36BbN/jZz2D8ePj447TX0T/+AeeeC9/+9jdDEUBBAdxzDxx+eApHttVJkiRpI3I2YhRCqA9cB3wXmA28GEJ4IMY4tcI9nYCfA31jjPNDCG3LvrUYGBVjnB5C2BF4KYQwIca4IFf1VpcDDkhdX//6F3z3u1lXU0Mcd1w6Nld5OCofOQoBTj216uuTJElSjZfLEaPewIwY43sxxuXAXcBRa91zGnBdjHE+QIzx87LzOzHG6WVffwx8DhTlsNZq07Rp6vxyAYZqUnHk6LTT4Oabs65IkiRJeSiXwWgn4MMKj2eXXatoD2CPEMKzIYTnQgiHrf0iIYTeQCPg3ZxVWs1KSmDyZFi4MOtK6gjDkSRJkjYhl8EorOfa2kvgNQA6Af2BEcDNIYSWq18ghB2AvwM/iDGuWucNQjg9hDA5hDB5zpw5VVZ4rpWUwKpV8PTTWVdSh5SHo4EDDUeSJElaRy6D0Wxg5wqP2wEfr+ee+2OMK2KMM4G3SUGJEEJz4CHgohjjc+t7gxjjTTHG4hhjcVFRzem069MHGje2na7aFRSkVe7Kw9Ff/pJ1RZIkScoTuQxGLwKdQggdQwiNgOOAB9a65z5gAEAIoZDUWvde2f3jgVtjjHfnsMZMFBRA374Go0xUDEennmo4kiRJEpDDYBRjLAV+AkwApgFjY4xvhhAuDSEcWXbbBGBeCGEqMBG4IMY4DxgGHAScFEJ4tezokatas1BSAq+9BnPnZl1JHWQ4kiRJ0lpCjGtP+6mZiouL4+TJk7Muo9L+85+0/c7dd8OQIVlXU0ctXQqDB8Mjj6RddwcPTpvK1svp9l6SJEnKUAjhpRhj8TrXDUbZWLECWreGE0+E66/Pupo6rGI4gjSatNtusPvu0KnTmnOnToYmSZKkWmBDwShnG7xq4xo2hIMOcp5R5goK4IEH0hKB77wDM2bA9OnpePRRWLbsm/eWh6biYrjggrSKhiRJkmo8g1GGSkrg4Yfho4/SYIQy0qABDBiQjopWrYLZs78Zlsq/vv9+ePJJGD8emjXLpGxJkiRVHYNRhkpK0nniRBg5MttatB716kH79uko/5dV7tZb4eSToX//1IbXtm0mJUqSJKlqOGEiQ927Q6tWttPVSKNGpRa8adPS2uvvvZd1RZIkSdoKBqMM1auXBhwmTsy6Em2Rww9PqfaLL1I4evXVrCuSJEnSFjIYZaykBGbNgpkzs65EW6RPH3jmmbSaRr9+ad6RJEmSahyDUcbKp67YTleD7bUX/Pvf0K4dHHoojBuXdUWSJEnaTAajjO21F2y3HUyYkHUl2irt2qUlv4uLYdgwuPHGrCuSJEnSZjAYZSwEOOGENMjw4otZV6Ot0ro1PPYYDBoEZ5wBl1wCtWQDZUmSpNrOYJQHLr4Ytt8efvhDKC3NuhptlW23TXsb/eAH8Otfw5lnwsqVWVclSZKkTTAY5YHmzeEPf4BXXoHrr8+6Gm21Bg3gL3+B0aNTS92wYbB0adZVSZIkaSNCrCWtPsXFxXHy5MlZl7HFYkyrPz/7bNoaZ6edsq5IVWLMGDj3XOjZE3bfHZYvh2XL0nntrys+btMm7ZO0++5ZfwJJkqRaJYTwUoyxeJ3rBqP88e670LUrHHEEjB2bdTWqMnfeCb/5TUq/jRtDo0ZrjoqPK379j3/AnnumpcAbNMj6E0iSJNUaGwpG/saVR3bbDS66KB2PPAIDB2ZdkarEiBHp2Bz9+6fn/Pd/w69+lZOyJEmStIYjRnlm2TLo0SOd33wTttkm64qUmRNOSCNH//439O6ddTWSJEm1woZGjFx8Ic80bgw33AAzZ8Lll2ddjTJ13XWwww4wciR8/XXW1UiSJNVqBqM81L8/jBoFV16ZFmJQHdWyJfztbzB9OlxwQdbVSJIk1WoGozz1u99B06Zpn9Ba0u2oLVFSAuedl4YRH34462okSZJqLYNRnmrbFn77W5g0CW69NetqlKnLL4e994aTT4a5c7OuRpIkqVYyGOWxU06B/feH88+HefOyrkaZKSiA226D+fPh9NMdQpQkScoBg1Eeq1cPbrwx/T48enTW1ShT3brBZZfB+PHw179mXY0kSVKtYzDKc926wbnnws03w7PPZl2NMnXeedCvH5x1Frz3XtbVSJIk1SoGoxrg4oth553hRz+CFSuyrkaZqV8/rVJXr15atnDlyqwrkiRJqjUMRjVA06Zw7bXwxhswZkzW1ShTu+yS9jd69tm0nrskSZKqhMGohjjySDjqKLjkEnj//ayrUaZOOAGGDoVf/QpefjnraiRJkmoFg1ENcs016XzWWdnWoYyFkFblaNsWRo6EJUuyrkiSJKnGMxjVIO3bw69/DQ88APfdl3U1ylTr1ml1umnTXLJQkiSpChiMapizz04r1Z10EjzzTNbVKFPf/W4aPrzmGnjssayrkSRJqtEMRjVMw4ZpxGi77dLvxQ8+mHVFytQVV8Bee8H3vw9//zt89VXWFUmSJNVIBqMaaJdd0mhR165w9NFw661ZV6TMbLMN3HknFBSkJbzbtk0LM4wfD0uXZl2dJElSjWEwqqGKiuBf/4L+/dNgwdVXZ12RMtO9O7z7blrC+5RTYNIkGDw4DSuefHJqsystzbpKSZKkvGYwqsGaNYOHHoIhQ+BnP4Of/xxizLoqZSIE+Pa304ZXH38MEybAMcfAuHFwyCHQrl2aj/Tcc/5HIkmStB4h1pJfkoqLi+PkyZOzLiMTK1fCj38Mf/oTnHoq3HADNGiQdVXKC0uWwMMPp3a7Bx+EZcugY0cYPhy+8x3o0yftIFwV5s2DiRPh8cfhlVfgiCPgzDPTCnqSJEl5IoTwUoyxeJ3rBqPaIca03+dll6WBgjvuSNNOpNUWLkzrvN9xBzzxRErU9etDz55wwAFw4IHQt29qwauMJUtS+97jj6fj5ZfTf4jNm8Oee8KLL8K226a0fu650KFDTj+eJElSZRiM6ohrrklLeg8YkH4Hbt4864qUl778Ev7zn7SKxzPPpBa78sUaOnVKQak8LO2+e2rVW7kyjQSVB6FnnkkjUA0bpja+gw9OR3FxGrJ880246iq4/XZYtQqGDYMLLkhBTJIkKSMGozrk9tvTPkfdusEjj6SFyqSNWr48jfg88ww8/XQ6f/FF+l7btmkJxFdegfnz07Xu3dcEoQMPhCZNNvzas2fDH/6Qej2/+iqtM3/BBem5IeT+s0mSJFVgMKpjHnkEjj0WdtopLUpmF5M2y6pV8Pbba0LSG2+kkZ6DD4aSksq321W0YEEKR3/4A3zyCfToAf/1X2l5cSfFSZKkamIwqoP+/W8YNChtdTNhAuy9d9YVSaT2u9tvh9/9Dt56K6X2c85J/Z977OHkOEmSlFMGozrqjTfg0ENhzpw0B/6ii2DHHbOuSiKNSj34IFx5ZVrEAVJrXceOsNde8K1vffPs6naSJKkKGIzqsE8+gd/8Bv7859SxdOaZMHp02iRWygtTp8Lrr8O0aWkUadq01Mq3bNmae4qK1gSlzp3TJrY775xdzZIkqUYyGImZM+HSS+HWW1N73TnnpI1hW7XKujJpPVauhPffXxOUys/TpqWFIerXT/OTzj0XevfOulpJklRDGIy02ttvw8UXwz/+AS1bwvnnw1lnQbNmWVcmVdLMmXDddWkY9Msv03Lh554LRx/tQg6SJGmjNhSM6mVRjLK1555w113w2mtw0EFp3tGuu8L//E/as1PKex07pj2SypcC//TTNHq0++5w9dVpM9vqUFqa5kddeWXa0FaSJNVYBqM6rFs3uP9+eP556NUrjRztthtcf33a1kbKe82apeHOd96B8eNhl11Sf+jOO6de0ffeq/r3/PBDuPnmFMQKC9NGuBdeCPvtBz/5SfWFMkmSVKUMRqJ377Sc96RJKRj9+Mfp/D//k7qUpLxXv35qo5s0CSZPhqOOSq12nTqlRRqeemrLh0OXLk2bgZ1/ftrotn17OO00+M9/0mZhY8fCrFnw05+mvyrstRfcfTfUkjZlSZLqCucY6RtihH/+E664Ap58Epo3h9NPT3+UdwEw1Sgff5zC0Y03psUaALbdFtq0SSM9hYVrvl77WrNmqTXu0Udh4sQUqho1Sr2nhx4Khx0GXbqk5cUrmjwZfvhDePllGDgwvX/HjtX/2SVJ0ga5+II22+TJadTo7rvT73/Dh6cupZ49s65M2gyLF8N998EHH8DcuemYN++bX8+fv/7nduqUQtChh0L//tCkyabfr7QUrr0WfvnLtLLexRfDeedBw4ZV+rEkSdKWMRhpi73/fprf/uc/w6JF8J3vpIB02GHr/sFcqpFKS9OoUsWg1KVL6indUh9+mIZa77svteD96U9p9bzKiDHNm3r66XQ8/3zau+m886BvX3/wJEnaCgYjbbUFC+Cmm+Caa+Cjj9LvjT/7GRx/PDRunHV1Up66//40/+jDD1Nf6hVXrLt5WGlpWiayPAg98wx8/nn6XlFRmgj4n/+k8Lbvvmlp8iFDHIWSJGkLGIxUZZYvT3sgXXUVTJkC228PZ54JJ58MO+2UdXVSHlq0KLXUjRmT5jFdfXWatPf002lhiP/8B776Kt3boQMceOCaY8890wjR4sVpd+bf/z6NJrVrl0akTjstbUgmSZIqxWCkKhcjPP54Ckj//CfUq5emYpxyChxxRJqrLqmCl19OizNU/N+qrl2/GYTatdv4a6xaBQ8/nMLVxIlp3tMpp8DZZ6cNySRJ0kYZjJRTM2bAX/+ajo8+Sn8UP/HE9Ptaly5ZVyflkZUr4d57oaAgzRdq3XrLX+uVV9II0p13psB09NFpHtK3v+08JEmSNsBgpGqxcmUaPfrLX+CBB2DFijQ94pRT4Ljj0vLfkqrYRx+tWZp8/vz0Q/ezn6V9lurXz7o6SZLyyoaCkRu8qkrVr5+2bxk3Lv2udvXV8PXXqXto++3h+99PUypqSR6X8sNOO8F//3da4OH661M4Gj4c9tgDbrhhyze3lSSpDjEYKWeKitLiWa+/nlYbPvFEGD8e+vWD3XeH//qvdN2QJFWRJk3gjDNg2jS4557U03rmmbDLLnDZZWs2upUkSeuwlU7VavHiNJp0553wxBOp1a5dOxg8OHX99O1r549UZWJMQ7S//S088kgKTqedlv5i0b591tVJkpQJ5xgp7yxYAP/3f+kP248+CsuWQdu2cMwxKST17+82LVKVmTIlLSF5553p8YgRadi2a9ds65IkqZoZjJTXFi1KKxDfcw889FCal9SqFRx1VBpN+u530yJekrbSBx+klez+/Of0g3b44XDhhWmpcFeykyTVAQYj1RhLlqSV7e65J61st3Bhut6qVZq3VFi45tjQ4x12gG23zfZzSHntiy/SQg3XXANz5sC++6alvo891qFaSVKtZjBSjbR8OfzrX/DcczB37ppjzpw15xUr1n1evXqwzz6pHa9/fzjgAJcKl9ZryZK0Adnvfw/Tp6dJfz/9aZqL1KrV1r12aWnahHbcOHj//XW/v7H//9l1Vxg6FA46CBo02Lo6JEmqwGCkWilG+OqrdQPT9OkwaVJa9W7Fim8GpX79UlBq0SLr6qU8smpV6me9+uoUZpo0gZNOgrPPhk6dKv86paVpwYd//CNtZDt3LjRtCp07r79Vb33XYoQ33kitfm3bplGsYcNSu5+rs0iStpLBSHXS4sVptOnJJ9Px3HNrglKvXt8cUTIoSWVefRXGjIE77khB54gj0kp2/fqtP8isXAlPPw1jx6Ye2M8/T8HqiCNSoDnsMNhmm82rYfHitJLe2LHw4IPp8fbbw5Ah6TX79k0/yJtr1Sr49NP0A9+kyeY/X5JU4xmMJNYEpUmT1gSl5cvTH6H33z9tTjtwIPTo4Tx0iU8/TfOQrr8e5s1LPxjnngvHHZfa2555JgWXcePgs8/SxL7vfS8Fl4EDq26i39dfp1VZxo5N56VLYccdU6vdsGHQp8+akLRyJXzySWrdmzVr3eODD9IPfWFher0BA6qmRklSjWEwktZjyZIUjp54Iv1x+uWX0/Xtt09/5B44MK2It7VTLaQabckSuO22NA9p2rT0AxJCCiAFBTBoUAoogwblfhRm0aK0zv/YsemHdtmyNC9qjz1SGPrgg3UnHm63HXTokI5ddoGdd4brrks9t1demcKefwmRpDrDYCRVwqefwoQJ6fetf/4T5s9Po0l9+nxzNGlLOnikGi/G9ANy/fVpxGjYsDRC1LRpNvV8+eWakPTZZ2vCT8Wjffv1j1x9+WWaQzV+fNrT6eabXcpSkuoIg5G0mUpL4YUXUkh65BF46aV0fbvt0ihScXEKSd27Q8uW2dYqaQusWgVXXAEXXQTduqWQ1LHj1r/u0qVpJMuJi5KUlwxG0lb67LM1o0kTJ6bH5Tp0gJ49U1AqP3be2e4cqUZ45BE4/vg0FHznnXDIIVv2OvPmwbXXwh//mJbLPPVU+PnPU6ufJClvGIykKvbpp2nxrorHO++s2Zqldes1Ialr1zQto3wD2qIiF8SS8sqMGXDMMTB1Kvz3f8N//Vfl/7Lx/vtpmfObb04rvHzve+kH/q9/TWHr9NNTQNpxx5x+BElS5RiMpGqwaBG8/vqaoPTKK+nx0qXr3rvNNikgVTzKQ1NhYWrPa948deOUn8tXGHYkSsqBRYvglFPSnKUhQ+CWWzY+f2rKlLR4w113pR/K44+HCy5IfwmBtAre5ZengFS/PvzwhzB6NOywQ3V8GknSBhiMpIyUlqY/KH/+edqAtnwT2vKvKx5z56aViTemXr11A1ObNmlfpj59YL/9nNogbbEY4aqrUoDZa68076jiBrcxpg1sf/vb1ILXpEkaETrnnLTQw/q8914KSH/7GzRsCD/6EVx4YRpVkiRVO4ORVEMsWZIC0sKFaeGsiucNXfv0U3jrrfQ7Wwjp97k+fdKx//7pcf36WX8yqQZ5/HEYPjzti3T77Wn9/vvvT4HohRfS0O5ZZ8GZZ6a+2cqYMQMuuwz+/ndo3BjOOCO17G23Xe4+x7JlaaPe996Dn/4U2rbN3XtJUg1hMJJquS+/TL+vPffcmmPevPS9Zs2gd+81Qam4OP1e57Lj0kbMmpXmHb32WhoNev992HVXOP/8tNT3Ntts2etOnw6/+U0KXAUF8OMfp9esytAyZw7ceGPar6l8pZgWLdL7nnFGWm5dkuoog5FUx8SY/kBdMSi99lr6AzikUNSyZfpjd+vWaRPbDX3dpk2aFrHjjun3OKnOWLw4jbRMnZra5Y49tupCxdtvp6Byxx1pSLekJAWxo47a8nlIb72VNuK99dY0ufHww+G882CnndII12OPpaXJr70WDjywaj6HJNUwmQSjEMJhwB+A+sDNMcYr1nPPMOASIAKvxRiPL7v+feCistsuizH+bWPvZTCSNu3rr9N+TK+8ktr15s+HL75Yc5Q/nj9/zep6ayssTL9jlR/t2q37uGVLF4iQKu2tt9ICDffem0aTQkhDu4MHp6C0664bf36MaQ+Bq6+Ghx5Kf70YNSoFub32+uZ948fDuefCBx/AyJFp8YjqXgxi8eLU2teli/9DISkT1R6MQgj1gXeA7wKzgReBETHGqRXu6QSMBUpijPNDCG1jjJ+HEFoDk4FiUmB6Cdgnxjh/Q+9nMJKqzqpVqTWvPDDNnQsffwwffbTmmD07nefMWff5226bfh/r2nXNsffeacTJ34OkDYgxjUzde28KMK+8kq53754C0uDB6Yep/Ido+fK0It7VV6fh4LZtU1veGWekXtkNWbwY/t//S6GocWO45JI0KtawYW4/31tvpfa+v/0NFiyAffaBX/wCjj7avl5J1SqLYLQ/cEmM8dCyxz8HiDH+vwr3XAm8E2O8ea3njgD6xxh/WPb4T8CTMcY7N/R+BiMpG8uWwSefrAlKH32U/hg9dWpaqvzTT9fc27LlN4NS+deVnbsu1SkzZ8J996Wg9OyzKTjttlsKSM2bw/XXpx++Ll1Su9zxx29er+uMGXD22fDww9C5c2qvGzCgaj/D8uXpM9xwAzz5ZApfxx6bls+87rpUQ+fOaZ+n445z7pOkapFFMBoCHBZjPLXs8YnAfjHGn1S45z7SqFJfUrvdJTHGR0MI5wMFMcbLyu77JbAkxnjVht7PYCTlp7lz4c034Y030vH66+m8cOGae7bbLs0Lb9wYGjVK5/JjQ4/r1Vvzh/MQ1j0qXq9XL62M3LFjOjp02PJ581ImPvssrYo3fjw88QSsWAGHHJIC0SGHbPlQbIzw4IMpIM2cmVbiu+qq1BO7NT74AG66KW16+9ln6Yfuhz+Ek09es8hEaSncfXfaUPeNN1LL4IUXwve/n37IJSlHsghGQ4FD1wpGvWOMP61wz4PACmAY0A54GugKnAY0XisYLY4x/s9a73E6cDpA+/bt93n//fdz8lkkVa0Y08hSeViaNi3Nf1q2LB3Ll6//64qPV61a81rlx4Yer1q15v5y22+fflcrD0vlgaljx7QAWa67iqQttmBB+svCLrtU3WsuWZJa6664Ii0EcfbZaSRn++3XHK1bbzyArVwJEyakdrmHHko/fIMGpda+Qw/d8J4Bq1bB//1f2uvpxRfTZMXzz4fTTkv7RFXWqlXw4Yfpf1A++wz696/af0aSao18baW7EXguxvjXssdPAKOB3bGVTlIVWbUq/Z40c+aaY9asNV9/8MGa1fogjTBtt12aE1V+lK/KV/HIxZLnMaZaSku/eawdENd3LF26Jjw2a7ZmQYwdd0zzvqRNmjkzLc5w//3rfq9hw/SDUTEslR8LFqTRoVmz0j2nnpqCzeYEkxjT/lGXXw6TJqWVXs49N82bqrhrdWkpvPtu6tedNu2bx+LF33zNffZJrYeDB8O3vrVF/0j0/9u78zgry7qP498fs8Bsyr4oBiqImAuQGypGaE+4vMxyJTRts9TSFrXMbNGwLEs0bbFc0yczMI0yQ9FHzcQVNHFJQRkUBCYYhpk5s57r+eN3H8+ZYRZgZjjb5/163a/7PvecOec+cw2H853run4XkHvSEYwK5cPkjpL0rrz4wqdCCMtS7jNTXpDhLDMbKmmJpElKFlyYEt31BXnxhQ2dPR/BCMD2amnxOVKpgWn16rZbR0UmCgv9M+GoUf6ZsbV127b24aelZcuerd4ycKAHpERQSuwTxxUVHvIKCpL71OP2+9JSFg3OaYmVo7vb1q1L/tJOn+69Qyee6GNee+LJJ32I3QMP+HyqWbN8XO6rr3rlvubm5H1Hj/ZqL/vs4/uJE32dgQcf9PlZixf7/SZOTIakyZOpBAPksXSV6z5W0lz5/KFbQghzzOwKSc+FEP5iZibpZ5JmSmqVNCeEcHf0vZ+V9O3ooeaEEG7t6rkIRgD6UlOTfw5cs2bL3P8bHAAAE/1JREFU0LRmjYeaRJjYmq2wsO3W0bnE+YKCtvOsOtoGDGg7D2vTpraVBBPHif2aNW17ybZVv37+B/3hw7duKy/fMZ9DQ0j2sCV62To6Li5OXhvDJnugtdUDS0uLJ+zetmSJB6QFC3yMa2r4mTjRe4EqKrp+jHffTRaxeOwxv+YxY5IhaepUUj6QZ1jgFQDwvtZW7wVLBKX6ej8Xj2/dvqbGOwsS29q1vk8tqtGeWdsQmBoS2++ltvPDUo87up0ahrb1v7VBg3z01/Dhne8rKjrv+Uv8TFK3EDoPxF0F5c4CcurX87KydQi9k6yrqjxk3XuvtHCh/8KMGOHl0C+6yKv+Ach5BCMAQJ9rbPTA1T401dUlhw+mDiXs6FxLiz9Wv37J6oOJ485uFxYme8sSlQu7Om5o2DLUpe43drpqXvqZ+VDGxDDOrrYhQzrOEyF4W9XXe9u035qbvZdvp508FCa2srLMDmaNjdLmzb4fMaKb6t81NdLf/+4hacEC/8U77zzp8sv9BwcgZxGMAADYSk1NyYC3dq1UW9v10MjUeVkFBR5GOptX1tX5RDDsbA5aYqutTQ7tTGybN2/5OoqKPEANHLhlCNqe+WxmHo4qKtqGprKyznvDuvqZJUJud/sQ/PXV1CT3iS31dlNT8loLCnzE3B57dLwNGpTywlav9oVub77ZX9Cll0oXXNDzuv6xmDR/vgevXXbxBdz228+HBG5Lxb3etnGj/1Iwz6qNeNznm775pv+IYrHk1tDQ+e2GBv99mjDBt733lsaN27ZlxbBjEYwAAMhhdXVtg1LqtmmT9zKVlXW/lZZ6oKqt9dCRuiWCSPutrq7z0NfZlhgO2dm+vZISD2OJLRHOOrpdVOTVJlesSG5VVW0fb+DAZEgaM8a/v7TmPZX84z6VLntGJYNLVXLGSSqdeaRKygtUWurXUFrqH3jN2g7bTF0iQK++Kt11l8L8e6WaTbLhwzVoc6VKYlENKTN/4kRQSqx4PX587y9y29wsvfSS9K9/JbfKSn/+M87wbfz43n3ODNbc7EV2li/3APTmm8njFSvahuuOFBf778GAAb5PHFdVebX4BDNf/iE1LCWOR45sm0njcQ9Y9fWdb4WFXjE/sQ0a1PMaJ/mMYAQAALJG+zXJelofoabGK06mhqXEtnKlD7/ra2WlcQ0ti2lYUbWGxddqaP0qDatZrmFap6Gq0rDCag0dW64hE4crPnIXNQwepcaBI9W40zA1lA9VY+kgNcaL3i/NnyjT39SUHFJa2Fingsq3VLhyuQreXq7Ct99QQVNMhWpR4aCdVLD3eBXuvpv6v7JEJUufUonqVbLvOJV8YqZKPnmMSkYPef/DfrbWpGho8HZNBJ/UALRyZdvCM2VlPrVs3Li2+2HD2gafrfmZ1NVJ//mP9Npr0uuvJ/evv+7BJyER4BOhp6Fh+15nWVnboJQanEaO9Oy7554e0NLZQZmJCEYAAACdaG1NDo2qr5didXHV3/+QYr/4nWJrNqp+0uGKzfqsYsPHJD/khiCrXCn985/Sc8/KGhukUaNkRxwhHXqoVF7+/rDKjRt9eGZVVft9UF1dZg5pKypKhoPiYr9dVOQBLHHc2bn2cwK725eW+nJVqb2AHW0VFf5ctbUedFJ7fhLbO++07c0bONA7xdqHn3HjfC5aX48oTAzRSw1L9fX+mrdmKynxHtkNG/z3aMOGLY/b324f9EeM8Nec6CVNPR45suO5g/F4sqhNU5P3tqVW+UwdUth+3/5caamPVs0UBCMAAIBt1dgo/fKX0pVX+kK2Z54pXXyxl/7+7W+lF1/0T66nneaL2k6dus2ftGOxtmFpwwapwOLq31ij/purNGDzevWvWa/+G9/TgI1r1P+/q9V//TsasK5S/detUnE8pjB4qFoPOUwtBx+m1gMPUcu+k9Tav3SLIieJeWrt58zE/rNKsceeUWzxUsWqG9VQvLNiEyYpNn4/xYaMVlNzPzU3Sy3NcTXXNam5rlnN9c1qjrWouaFFLY2tam6Mq7kpqLlZihcNUCgrU3xAqYIVdDlsMh73oLB589ZVlSwpadsDI3n1yNTA8/42YrMGX3WRj2H76lczu3pILwnBQ9Ly5cle0dTjVavaDlcdMMB7mdoHoJ4s6ZBqwABp7FgfYZopCEYAAADba+NG6cc/lq67Lvnn+MmTPQx96lPe3ZEOra0e2AYP7p2uj3jcQ9+dd0rz5vkYxFGjvKumqsp/Dp19dqyo8DFoO+/sXSOxmF/TlCnSjBnSRz4iHXFEp2tPxeM+HG3TprYFNhJb6vmhQ5PhZ889vTdpC2+9JZ1wgvTyy377Yx+T7rjDU1Qea2ryIYWpoam62qt2FhUlq3imbh2d72iuVft9//6ZWeODYAQAANBTlZXSn/4kTZ8ufehD6b6avhWLJdd9CsFDz9ChvrU/HjLEPwUnNDZKTz8tPfqo9Mgj0uLF/om8sFA66KBkUDrssJ5X/+vI449LJ53k3WP33ONj7L72NQ+Qd93lz428RTACAABAetTXe0W8RFB69lnv7Sou9uGH55wjzZrVO90LN98snXuuVx1YsEDaay8//+KL0qmnSm+84etVffe72VthAj3SWTDK/YGWAAAASK/SUunoo6U5c6SnnvIheX/7m68XtW6dNHu29x4tXrz9z9HS4r1Cn/+89wgtXpwMRZJ0wAHS88/7PLErrpCOOkp6992ev7ZMsmyZNG2adOCBXhQE24RgBAAAgB2rokI69ljppz/1OUC33uoLDE2d6msrpS4KtDWqq6Xjj5fmzpUuvNBDV5tVfCPl5dLtt0u33ea9VpMmSQ88sH2voalJevBB6ctflm66aesqR/SVpiYPe5Mne5WDtWs9IJ15pi9mhq1CMAIAAED69OsnnX22D3G77DIv+jBhgtd3rqvr/vvfeMPLoy9a5AFl7tzuF8o96yzvPdplF+m447zSYHeru0peJ3zePO/hGjZMOuYYf84vflE6/XT/+o72zDM+3+173/N5Va+84sUvLrvM51dNmCD97Gdebg5dIhgBAAAg/crLpR/+0Bf6OeEE6Qc/8A/1d97Ztr50qocflg45xCvmPfywVwncWnvv7cPtvvQl6ZprvIflrbe2vN+GDd7LdOKJHoZOOUX6xz+kk0+W/vpXL5d39dUemA4+2EPJjlBfL33jG97LtmGDdP/90h/+4FX3ysr8Z5kYWnfRRT6UcNGiHXNtWYpgBAAAgMwxZox0993SE094qfAzz/QP/0891fZ+N94ozZzpvT7PPit9+MPb/lwlJdKvfuU9K6+95kPR5s+XVq/29as++lEPGmef7T1MX/iCF5B47z0v8nDccf4Yl1wiPfSQB7SDDvLH6EuPPCLtt5/085/7Nb3yiofJ9saN82GFCxZ4pcCjj/YCFJWVfXt9WYpgBAAAgMxzxBFe8vu223zO0WGH+ZpRK1ZI553nc3uOOcar3e2+e8+e65RTpCVLvFjDySdLu+4qnX++B4iLL/bhapWV0vXXe6n2jobqzZghvfCC9MEP+mNcfLEXhOhN1dUehI46yocgPvqo9Otfd7+O1vHHe+/RlVd6L9fEidJVVyXX5IIkynUDAAAg09XW+nC1a66RGhr83De/6VXuerPkdlNTchHfT37SA8S2lhBvbJS+/nXvcZo+3Xu/Rozo+bXdf7+XIV+71ofQff/7Xu1vW61c6d8/f773KF13nRfCyCOsYwQAAIDstnKl9KMfSUce6b1Hmez3v/eiDIMG+fyjqVO373FWrfI5QvfcI+2/vw/hO3CLz/TbbuFCL5f++usekIqK/HwiG6Tu25/bay8Pqvvu2/PrSAOCEQAAALAjvfSS9zxVVvp8oPPP77oHKgQvAPH44z7H6oknvOpecbEvSHvJJckA0xuamnyu1pNP+nUlri113/6c5GXKa2qkr3zFe666G8qXYQhGAAAAwI5WXS19+tNeAGH2bOk3v/GqcZJX21u2zANQIgytXu1fGzTI51lNmyZ94hPeq5Mpqqqk73zHS5UPGyb95CdeJKNfdpQvIBgBAAAA6RCP+xDAyy/34gyzZ3svzZNPShs3+n123dWHCE6b5ts++2R+0Hj+eS+CsXixDxW84QZpypR0X1W3CEYAAABAOi1c6HOj/vtfX6MpEYKmTZPGjt32Qg+ZIB6X7rjDi2GsXy+dc44XxRgyJN1X1imCEQAAAJButbVSLOZD0HLJpk0+3+gXv/A5R3PmeGnx3qwa2Es6C0YZ3j8HAAAA5JDy8twLRZKHoWuvlZYulQ44wEuLH3SQrzOVJQhGAAAAAHrHvvtKixZJf/yjtG6ddPjh0llnJdefymAEIwAAAAC9x0w69VTptdekSy/1OVX9+6f7qrpVmO4LAAAAAJCDysulq67y9ZmyoLAEPUYAAAAA+k4WhCKJYAQAAAAABCMAAAAAIBgBAAAAyHsEIwAAAAB5j2AEAAAAIO8RjAAAAADkPYIRAAAAgLxHMAIAAACQ9whGAAAAAPIewQgAAABA3iMYAQAAAMh7BCMAAAAAeY9gBAAAACDvEYwAAAAA5D2CEQAAAIC8RzACAAAAkPcIRgAAAADynoUQ0n0NvcLM1kta2YdPMVRSVR8+PtKL9s19tHFuo31zG+2b+2jj3JZp7TsmhDCs/cmcCUZ9zcyeCyEcmO7rQN+gfXMfbZzbaN/cRvvmPto4t2VL+zKUDgAAAEDeIxgBAAAAyHsEo613U7ovAH2K9s19tHFuo31zG+2b+2jj3JYV7cscIwAAAAB5jx4jAAAAAHmPYNQNM5tpZq+b2Ztm9q10Xw96zsxuMbN1ZvZyyrnBZvaQmb0R7Qel8xqx/cxsNzN71MxeNbNlZnZhdJ42zhFmNsDMnjGzF6M2/kF0fnczezpq4z+aWXG6rxXbz8wKzGyJmf01uk375ggze9vM/m1mS83suegc79E5xMwGmtk8M3st+v94aja0McGoC2ZWIOlGScdI2kfSLDPbJ71XhV5wm6SZ7c59S9KiEMJ4SYui28hOLZK+EUKYKOlQSedH/25p49zRKGlGCOEASZMkzTSzQyVdLenaqI03SvpcGq8RPXehpFdTbtO+ueUjIYRJKSWceY/OLddJejCEsLekA+T/ljO+jQlGXTtY0pshhBUhhCZJd0v6eJqvCT0UQnhc0oZ2pz8u6fbo+HZJJ+7Qi0KvCSGsCSG8EB1vlr8Z7yraOGcEVxvdLIq2IGmGpHnRedo4i5nZaEnHSfpddNtE++Y63qNzhJntJOlISTdLUgihKYRQrSxoY4JR13aVtCrl9jvROeSeESGENZJ/sJY0PM3Xg15gZmMlTZb0tGjjnBINs1oqaZ2khyQtl1QdQmiJ7sL7dXabK+kSSfHo9hDRvrkkSFpoZs+b2TnROd6jc8cektZLujUaDvs7MytTFrQxwahr1sE5yvgBWcDMyiXNl/TVEEJNuq8HvSuE0BpCmCRptLx3f2JHd9uxV4XeYGbHS1oXQng+9XQHd6V9s9fhIYQp8qkK55vZkem+IPSqQklTJP0qhDBZUp0ycNhcRwhGXXtH0m4pt0dLWp2ma0HfWmtmoyQp2q9L8/WgB8ysSB6K7goh3Budpo1zUDQ84//k88kGmllh9CXer7PX4ZJOMLO35UPYZ8h7kGjfHBFCWB3t10n6s/yPG7xH5453JL0TQng6uj1PHpQyvo0JRl17VtL4qBJOsaTTJf0lzdeEvvEXSWdFx2dJuj+N14IeiOYi3Czp1RDCz1O+RBvnCDMbZmYDo+MSSUfL55I9Kunk6G60cZYKIVwaQhgdQhgr/3/3kRDCbNG+OcHMysysInEs6X8kvSzeo3NGCOE9SavMbEJ06ihJrygL2pgFXrthZsfK/1JVIOmWEMKcNF8SesjM/iBpuqShktZK+p6k+yTdI+kDkiolnRJCaF+gAVnAzI6Q9ISkfys5P+Hb8nlGtHEOMLP95RN3C+R/4LsnhHCFme0h72EYLGmJpDNCCI3pu1L0lJlNl3RRCOF42jc3RO345+hmoaT/DSHMMbMh4j06Z5jZJHnxlGJJKyR9RtH7tTK4jQlGAAAAAPIeQ+kAAAAA5D2CEQAAAIC8RzACAAAAkPcIRgAAAADyHsEIAAAAQN4jGAEAMpKZtZrZ0pSt11ZON7OxZvZybz0eACD7FXZ/FwAA0iIWQpiU7osAAOQHeowAAFnFzN42s6vN7JloGxedH2Nmi8zspWj/gej8CDP7s5m9GG2HRQ9VYGa/NbNlZrbQzEqi+19gZq9Ej3N3ml4mAGAHIxgBADJVSbuhdKelfK0mhHCwpBskzY3O3SDpjhDC/pLuknR9dP56SY+FEA6QNEXSsuj8eEk3hhA+KKla0knR+W9Jmhw9zpf66sUBADKLhRDSfQ0AAGzBzGpDCOUdnH9b0owQwgozK5L0XghhiJlVSRoVQmiOzq8JIQw1s/WSRocQGlMeY6ykh0II46Pb35RUFEL4oZk9KKlW0n2S7gsh1PbxSwUAZAB6jAAA2Sh0ctzZfTrSmHLcquS82+Mk3SjpQ5KeNzPm4wJAHiAYAQCy0Wkp+6ei439JOj06ni3pn9HxIknnSpKZFZjZTp09qJn1k7RbCOFRSZdIGihpi14rAEDu4a9gAIBMVWJmS1NuPxhCSJTs7m9mT8v/wDcrOneBpFvM7GJJ6yV9Jjp/oaSbzOxz8p6hcyWt6eQ5CyTdaWY7SzJJ14YQqnvtFQEAMhZzjAAAWSWaY3RgCKEq3dcCAMgdDKUDAAAAkPfoMQIAAACQ9+gxAgAAAJD3CEYAAAAA8h7BCAAAAEDeIxgBAAAAyHsEIwAAAAB5j2AEAAAAIO/9P2trAdu1VFKdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_val_loss = [np.mean([x[i] for x in all_val_loss]) for i in range(num_epochs)]\n",
    "average_train_loss = [np.mean([x[i] for x in all_train_loss]) for i in range(num_epochs)]\n",
    "\n",
    "average_val_acc = [np.mean([x[i] for x in all_val_acc]) for i in range(num_epochs)]\n",
    "average_train_acc = [np.mean([x[i] for x in all_train_acc]) for i in range(num_epochs)]\n",
    "\n",
    "print(\"Train loss: {}, train acc: {}\".format(average_train_loss[-1], average_train_acc[-1]))\n",
    "print(\"Val loss: {}, val acc: {}\".format(average_val_loss[-1], average_val_acc[-1]))\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(range(1, len(average_train_loss) + 1), average_train_loss, color=\"r\", label=\"Training loss\")\n",
    "plt.plot(range(1, len(average_val_loss) + 1), average_val_loss, color=\"b\", label=\"Validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing predictions after getting a satisfactory model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC score : 0.681723779854621\n"
     ]
    }
   ],
   "source": [
    "model = build_model(num_layers=2, num_nodes=128, lr=0.0001, opt=\"Adam\", dropout=True, input_shape=((22,)))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=45, batch_size=batch_size, verbose=0)\n",
    "\n",
    "res = model.predict(X_test_scaled)\n",
    "res = [round(num[0]) for num in res]\n",
    "\n",
    "print(\"Test ROC score : {}\".format(roc_auc_score(y_test, res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/ann_weights.h5')\n",
    "\n",
    "with open('models/ann_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
