{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_mean</th>\n",
       "      <th>acceleration_median</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>acceleration_spread</th>\n",
       "      <th>gyro_pc_mean</th>\n",
       "      <th>gyro_pc_median</th>\n",
       "      <th>gyro_pc_std</th>\n",
       "      <th>gyro_pc_spread</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>...</th>\n",
       "      <th>second_spread</th>\n",
       "      <th>over_speed</th>\n",
       "      <th>over_second</th>\n",
       "      <th>over_acceleration_x</th>\n",
       "      <th>over_acceleration_y</th>\n",
       "      <th>over_acceleration_z</th>\n",
       "      <th>over_gyro_x</th>\n",
       "      <th>over_gyro_y</th>\n",
       "      <th>over_gyro_z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.883337</td>\n",
       "      <td>9.852269</td>\n",
       "      <td>0.619492</td>\n",
       "      <td>6.530989</td>\n",
       "      <td>-0.006583</td>\n",
       "      <td>-0.002863</td>\n",
       "      <td>0.099002</td>\n",
       "      <td>1.101352</td>\n",
       "      <td>9.003204</td>\n",
       "      <td>8.503366</td>\n",
       "      <td>...</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>247</td>\n",
       "      <td>687</td>\n",
       "      <td>709</td>\n",
       "      <td>1002</td>\n",
       "      <td>801</td>\n",
       "      <td>570</td>\n",
       "      <td>581</td>\n",
       "      <td>614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.865608</td>\n",
       "      <td>9.847932</td>\n",
       "      <td>0.522142</td>\n",
       "      <td>5.819621</td>\n",
       "      <td>-0.006855</td>\n",
       "      <td>-0.003612</td>\n",
       "      <td>0.090770</td>\n",
       "      <td>1.123587</td>\n",
       "      <td>8.019369</td>\n",
       "      <td>7.206634</td>\n",
       "      <td>...</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>157</td>\n",
       "      <td>168</td>\n",
       "      <td>483</td>\n",
       "      <td>270</td>\n",
       "      <td>790</td>\n",
       "      <td>230</td>\n",
       "      <td>404</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.929590</td>\n",
       "      <td>9.877755</td>\n",
       "      <td>0.515173</td>\n",
       "      <td>5.168422</td>\n",
       "      <td>-0.012751</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.117109</td>\n",
       "      <td>0.896289</td>\n",
       "      <td>3.157213</td>\n",
       "      <td>2.998761</td>\n",
       "      <td>...</td>\n",
       "      <td>825.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>143</td>\n",
       "      <td>34</td>\n",
       "      <td>67</td>\n",
       "      <td>103</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.813434</td>\n",
       "      <td>9.791035</td>\n",
       "      <td>0.620066</td>\n",
       "      <td>13.349284</td>\n",
       "      <td>0.022429</td>\n",
       "      <td>0.024239</td>\n",
       "      <td>0.112628</td>\n",
       "      <td>1.166471</td>\n",
       "      <td>6.150996</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>...</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>122</td>\n",
       "      <td>232</td>\n",
       "      <td>389</td>\n",
       "      <td>1094</td>\n",
       "      <td>1072</td>\n",
       "      <td>531</td>\n",
       "      <td>735</td>\n",
       "      <td>753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.918090</td>\n",
       "      <td>9.904142</td>\n",
       "      <td>0.585346</td>\n",
       "      <td>7.280114</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.106469</td>\n",
       "      <td>1.161481</td>\n",
       "      <td>4.628921</td>\n",
       "      <td>1.936962</td>\n",
       "      <td>...</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>18</td>\n",
       "      <td>232</td>\n",
       "      <td>463</td>\n",
       "      <td>407</td>\n",
       "      <td>257</td>\n",
       "      <td>533</td>\n",
       "      <td>450</td>\n",
       "      <td>561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9.826470</td>\n",
       "      <td>9.789800</td>\n",
       "      <td>0.916836</td>\n",
       "      <td>8.572037</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>-0.002687</td>\n",
       "      <td>0.072664</td>\n",
       "      <td>0.903745</td>\n",
       "      <td>12.176386</td>\n",
       "      <td>13.017325</td>\n",
       "      <td>...</td>\n",
       "      <td>959.0</td>\n",
       "      <td>365</td>\n",
       "      <td>97</td>\n",
       "      <td>809</td>\n",
       "      <td>262</td>\n",
       "      <td>219</td>\n",
       "      <td>561</td>\n",
       "      <td>490</td>\n",
       "      <td>687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9.763213</td>\n",
       "      <td>9.646309</td>\n",
       "      <td>0.730155</td>\n",
       "      <td>9.416841</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.078446</td>\n",
       "      <td>0.754180</td>\n",
       "      <td>5.384260</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>94</td>\n",
       "      <td>36</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9.550677</td>\n",
       "      <td>9.494390</td>\n",
       "      <td>0.833292</td>\n",
       "      <td>9.474737</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>0.110181</td>\n",
       "      <td>0.909695</td>\n",
       "      <td>8.702027</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>71</td>\n",
       "      <td>307</td>\n",
       "      <td>90</td>\n",
       "      <td>111</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9.948639</td>\n",
       "      <td>9.877962</td>\n",
       "      <td>0.750480</td>\n",
       "      <td>5.686104</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>-0.003111</td>\n",
       "      <td>0.151980</td>\n",
       "      <td>0.988519</td>\n",
       "      <td>6.659024</td>\n",
       "      <td>5.192059</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>120</td>\n",
       "      <td>44</td>\n",
       "      <td>147</td>\n",
       "      <td>154</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9.873517</td>\n",
       "      <td>9.823053</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>5.916028</td>\n",
       "      <td>-0.002192</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.082987</td>\n",
       "      <td>0.767631</td>\n",
       "      <td>4.152211</td>\n",
       "      <td>3.702154</td>\n",
       "      <td>...</td>\n",
       "      <td>555.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>349</td>\n",
       "      <td>207</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acceleration_mean  acceleration_median  acceleration_std  \\\n",
       "0           9.883337             9.852269          0.619492   \n",
       "1           9.865608             9.847932          0.522142   \n",
       "2           9.929590             9.877755          0.515173   \n",
       "3           9.813434             9.791035          0.620066   \n",
       "4           9.918090             9.904142          0.585346   \n",
       "5           9.826470             9.789800          0.916836   \n",
       "6           9.763213             9.646309          0.730155   \n",
       "7           9.550677             9.494390          0.833292   \n",
       "8           9.948639             9.877962          0.750480   \n",
       "9           9.873517             9.823053          0.425662   \n",
       "\n",
       "   acceleration_spread  gyro_pc_mean  gyro_pc_median  gyro_pc_std  \\\n",
       "0             6.530989     -0.006583       -0.002863     0.099002   \n",
       "1             5.819621     -0.006855       -0.003612     0.090770   \n",
       "2             5.168422     -0.012751        0.001369     0.117109   \n",
       "3            13.349284      0.022429        0.024239     0.112628   \n",
       "4             7.280114      0.000480        0.004189     0.106469   \n",
       "5             8.572037      0.002651       -0.002687     0.072664   \n",
       "6             9.416841     -0.000840        0.000250     0.078446   \n",
       "7             9.474737      0.001922       -0.000612     0.110181   \n",
       "8             5.686104     -0.004018       -0.003111     0.151980   \n",
       "9             5.916028     -0.002192        0.000388     0.082987   \n",
       "\n",
       "   gyro_pc_spread  speed_mean  speed_median  ...  second_spread  over_speed  \\\n",
       "0        1.101352    9.003204      8.503366  ...         1589.0         247   \n",
       "1        1.123587    8.019369      7.206634  ...         1034.0         157   \n",
       "2        0.896289    3.157213      2.998761  ...          825.0           0   \n",
       "3        1.166471    6.150996      3.310000  ...         1094.0         122   \n",
       "4        1.161481    4.628921      1.936962  ...         1094.0          18   \n",
       "5        0.903745   12.176386     13.017325  ...          959.0         365   \n",
       "6        0.754180    5.384260      3.540000  ...          462.0          25   \n",
       "7        0.909695    8.702027      9.580000  ...          374.0          90   \n",
       "8        0.988519    6.659024      5.192059  ...          299.0          14   \n",
       "9        0.767631    4.152211      3.702154  ...          555.0           1   \n",
       "\n",
       "   over_second  over_acceleration_x  over_acceleration_y  over_acceleration_z  \\\n",
       "0          687                  709                 1002                  801   \n",
       "1          168                  483                  270                  790   \n",
       "2            0                  102                  143                   34   \n",
       "3          232                  389                 1094                 1072   \n",
       "4          232                  463                  407                  257   \n",
       "5           97                  809                  262                  219   \n",
       "6            0                  357                   94                   36   \n",
       "7            0                  300                   71                  307   \n",
       "8            0                  129                  120                   44   \n",
       "9            0                  155                  441                   10   \n",
       "\n",
       "   over_gyro_x  over_gyro_y  over_gyro_z  label  \n",
       "0          570          581          614      0  \n",
       "1          230          404          347      1  \n",
       "2           67          103           71      1  \n",
       "3          531          735          753      1  \n",
       "4          533          450          561      0  \n",
       "5          561          490          687      0  \n",
       "6          157          159           82      0  \n",
       "7           90          111          149      0  \n",
       "8          147          154          141      0  \n",
       "9          349          207          374      0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), '../data/safety/total_df.csv')\n",
    "\n",
    "# Not using the columns formed by IsolationForest\n",
    "cols = ['acceleration_mean', 'acceleration_median', 'acceleration_std',\n",
    "       'acceleration_spread', 'gyro_pc_mean', 'gyro_pc_median', 'gyro_pc_std',\n",
    "       'gyro_pc_spread', 'speed_mean', 'speed_median', 'speed_std',\n",
    "       'speed_spread', 'second_mean', 'second_median', 'second_std',\n",
    "       'second_spread', 'over_speed', 'over_second', 'over_acceleration_x',\n",
    "       'over_acceleration_y', 'over_acceleration_z', 'over_gyro_x',\n",
    "       'over_gyro_y', 'over_gyro_z', 'label']\n",
    "\n",
    "\n",
    "agg_diff_df = pd.read_csv(DATA_DIR)\n",
    "agg_diff_df = agg_diff_df.drop('bookingid', axis='columns')\n",
    "agg_diff_df = agg_diff_df[cols]\n",
    "agg_diff_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "\n",
    "Downsample to ensure that the neural network learns to classify equally, and not focusing on one class etc \\\n",
    "Train set will have 50:50 distribution, test set will follow actual distribution of 75:25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = agg_diff_df['label'].value_counts()\n",
    "# actual_dist = dist[1] / (dist[0] + dist[1]) \n",
    "# actual_dist # About 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling training set to get equal class distribution\n",
    "seed = 199\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "count_0 = agg_diff_df['label'].value_counts()[0]\n",
    "count_1 = agg_diff_df['label'].value_counts()[1]\n",
    "\n",
    "idx0 = agg_diff_df[agg_diff_df['label'] == 0].index.values\n",
    "sample_0_idx = np.random.choice(idx0, count_1)\n",
    "\n",
    "df_0 = agg_diff_df.iloc[sample_0_idx, :]\n",
    "downsample_df = pd.concat([df_0, agg_diff_df[agg_diff_df['label'] == 1]]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X = downsample_df.drop('label', axis=1)\n",
    "y = downsample_df['label']\n",
    "\n",
    "X_train, X_test2, y_train, y_test2 = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reforming test set to have class distribution of 75% class 0 : 25% class 1\n",
    "prop = count_1 / (count_0 + count_1)\n",
    "sample_0_idx2 = [idx for idx in idx0 if idx not in sample_0_idx]\n",
    "\n",
    "y_count = y_test2.value_counts()[1]\n",
    "sample_0_idx2 = np.random.choice(sample_0_idx2, size=np.int((y_count / 25) * 75))\n",
    "\n",
    "new_df0 = agg_diff_df.iloc[sample_0_idx2, :].sample(n=np.int((y_count / 25) * 75))\n",
    "test = pd.merge(X_test2, y_test2, left_index=True, right_index=True)\n",
    "test = test[test['label'] == 1]\n",
    "\n",
    "df_merge = pd.concat([new_df0, test], axis=0).reset_index(drop=True).sample(frac=1)\n",
    "\n",
    "X_test, y_test = df_merge.drop('label', axis=1), df_merge['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class distribution : \n",
      "1    3999\n",
      "0    3940\n",
      "Name: label, dtype: int64\n",
      "Testing class distribution : \n",
      "0    2889\n",
      "1     963\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking distributions\n",
    "print(\"Training class distribution : \")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"Testing class distribution : \")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-downsampling approach\n",
    "\n",
    "Leaving distribution as is then see how it goes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 13\n",
    "\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# X = agg_diff_df.drop('label', axis=1)\n",
    "# y = agg_diff_df['label']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "#                                                     random_state=seed, shuffle=True)\n",
    "\n",
    "# print(y_train.value_counts())\n",
    "# print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising data to have mean = 0 and standard deviation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_mean</th>\n",
       "      <th>acceleration_median</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>acceleration_spread</th>\n",
       "      <th>gyro_pc_mean</th>\n",
       "      <th>gyro_pc_median</th>\n",
       "      <th>gyro_pc_std</th>\n",
       "      <th>gyro_pc_spread</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>...</th>\n",
       "      <th>second_std</th>\n",
       "      <th>second_spread</th>\n",
       "      <th>over_speed</th>\n",
       "      <th>over_second</th>\n",
       "      <th>over_acceleration_x</th>\n",
       "      <th>over_acceleration_y</th>\n",
       "      <th>over_acceleration_z</th>\n",
       "      <th>over_gyro_x</th>\n",
       "      <th>over_gyro_y</th>\n",
       "      <th>over_gyro_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "      <td>7.939000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-1.117997e-15</td>\n",
       "      <td>-3.582131e-16</td>\n",
       "      <td>-5.544822e-17</td>\n",
       "      <td>-1.301040e-16</td>\n",
       "      <td>2.805362e-17</td>\n",
       "      <td>-5.848874e-18</td>\n",
       "      <td>-5.993023e-17</td>\n",
       "      <td>-6.174121e-18</td>\n",
       "      <td>3.027906e-16</td>\n",
       "      <td>6.368504e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>6.267817e-17</td>\n",
       "      <td>3.945005e-17</td>\n",
       "      <td>3.052099e-16</td>\n",
       "      <td>-1.153295e-16</td>\n",
       "      <td>-7.215086e-17</td>\n",
       "      <td>-9.555554e-17</td>\n",
       "      <td>5.628729e-19</td>\n",
       "      <td>-2.121436e-17</td>\n",
       "      <td>-3.736637e-17</td>\n",
       "      <td>3.382831e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "      <td>1.000063e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.403143e+01</td>\n",
       "      <td>-1.487927e+01</td>\n",
       "      <td>-1.263256e+00</td>\n",
       "      <td>-1.265030e+00</td>\n",
       "      <td>-7.505363e+01</td>\n",
       "      <td>-7.457329e+01</td>\n",
       "      <td>-6.390963e-01</td>\n",
       "      <td>-4.769338e-01</td>\n",
       "      <td>-1.987609e+00</td>\n",
       "      <td>-1.409070e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.882765e+00</td>\n",
       "      <td>-1.878490e+00</td>\n",
       "      <td>-8.315435e-01</td>\n",
       "      <td>-6.904687e-01</td>\n",
       "      <td>-1.390601e+00</td>\n",
       "      <td>-1.040193e+00</td>\n",
       "      <td>-1.041998e+00</td>\n",
       "      <td>-1.375954e+00</td>\n",
       "      <td>-1.479895e+00</td>\n",
       "      <td>-1.468457e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-1.389243e-01</td>\n",
       "      <td>-1.059107e-01</td>\n",
       "      <td>-4.052873e-01</td>\n",
       "      <td>-4.342546e-01</td>\n",
       "      <td>-2.422009e-02</td>\n",
       "      <td>-8.605665e-03</td>\n",
       "      <td>-2.943770e-01</td>\n",
       "      <td>-2.756335e-01</td>\n",
       "      <td>-7.383328e-01</td>\n",
       "      <td>-7.663352e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.227561e-01</td>\n",
       "      <td>-7.502336e-01</td>\n",
       "      <td>-7.705905e-01</td>\n",
       "      <td>-6.904687e-01</td>\n",
       "      <td>-7.157829e-01</td>\n",
       "      <td>-7.651875e-01</td>\n",
       "      <td>-7.877953e-01</td>\n",
       "      <td>-7.601378e-01</td>\n",
       "      <td>-7.377072e-01</td>\n",
       "      <td>-7.365042e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-1.701149e-02</td>\n",
       "      <td>1.429840e-02</td>\n",
       "      <td>-1.874991e-01</td>\n",
       "      <td>-1.923706e-01</td>\n",
       "      <td>9.958785e-04</td>\n",
       "      <td>-1.561686e-03</td>\n",
       "      <td>-1.994687e-01</td>\n",
       "      <td>-2.314391e-01</td>\n",
       "      <td>-2.150629e-01</td>\n",
       "      <td>-2.388728e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.233851e-01</td>\n",
       "      <td>-1.365864e-01</td>\n",
       "      <td>-4.211267e-01</td>\n",
       "      <td>-5.378694e-01</td>\n",
       "      <td>-2.365645e-01</td>\n",
       "      <td>-2.858195e-01</td>\n",
       "      <td>-3.617028e-01</td>\n",
       "      <td>-2.458660e-01</td>\n",
       "      <td>-2.347075e-01</td>\n",
       "      <td>-2.380789e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.127595e-01</td>\n",
       "      <td>1.334502e-01</td>\n",
       "      <td>9.040556e-02</td>\n",
       "      <td>1.231454e-01</td>\n",
       "      <td>2.565321e-02</td>\n",
       "      <td>7.447437e-03</td>\n",
       "      <td>-7.748910e-02</td>\n",
       "      <td>-1.606479e-01</td>\n",
       "      <td>6.101081e-01</td>\n",
       "      <td>6.079683e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.032076e-01</td>\n",
       "      <td>6.188211e-01</td>\n",
       "      <td>4.687871e-01</td>\n",
       "      <td>4.709818e-01</td>\n",
       "      <td>4.578130e-01</td>\n",
       "      <td>4.761233e-01</td>\n",
       "      <td>5.631116e-01</td>\n",
       "      <td>5.239039e-01</td>\n",
       "      <td>5.145158e-01</td>\n",
       "      <td>4.834178e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.721768e+01</td>\n",
       "      <td>4.991402e+01</td>\n",
       "      <td>1.586540e+01</td>\n",
       "      <td>1.694057e+01</td>\n",
       "      <td>3.429427e+01</td>\n",
       "      <td>3.467825e+01</td>\n",
       "      <td>2.857527e+01</td>\n",
       "      <td>1.822551e+01</td>\n",
       "      <td>4.312907e+00</td>\n",
       "      <td>3.527370e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.412638e+01</td>\n",
       "      <td>1.407828e+01</td>\n",
       "      <td>7.584033e+00</td>\n",
       "      <td>1.840423e+01</td>\n",
       "      <td>1.095172e+01</td>\n",
       "      <td>9.059334e+00</td>\n",
       "      <td>7.392697e+00</td>\n",
       "      <td>9.544952e+00</td>\n",
       "      <td>1.041974e+01</td>\n",
       "      <td>1.077607e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acceleration_mean  acceleration_median  acceleration_std  \\\n",
       "count       7.939000e+03         7.939000e+03      7.939000e+03   \n",
       "mean       -1.117997e-15        -3.582131e-16     -5.544822e-17   \n",
       "std         1.000063e+00         1.000063e+00      1.000063e+00   \n",
       "min        -1.403143e+01        -1.487927e+01     -1.263256e+00   \n",
       "25%        -1.389243e-01        -1.059107e-01     -4.052873e-01   \n",
       "50%        -1.701149e-02         1.429840e-02     -1.874991e-01   \n",
       "75%         1.127595e-01         1.334502e-01      9.040556e-02   \n",
       "max         4.721768e+01         4.991402e+01      1.586540e+01   \n",
       "\n",
       "       acceleration_spread  gyro_pc_mean  gyro_pc_median   gyro_pc_std  \\\n",
       "count         7.939000e+03  7.939000e+03    7.939000e+03  7.939000e+03   \n",
       "mean         -1.301040e-16  2.805362e-17   -5.848874e-18 -5.993023e-17   \n",
       "std           1.000063e+00  1.000063e+00    1.000063e+00  1.000063e+00   \n",
       "min          -1.265030e+00 -7.505363e+01   -7.457329e+01 -6.390963e-01   \n",
       "25%          -4.342546e-01 -2.422009e-02   -8.605665e-03 -2.943770e-01   \n",
       "50%          -1.923706e-01  9.958785e-04   -1.561686e-03 -1.994687e-01   \n",
       "75%           1.231454e-01  2.565321e-02    7.447437e-03 -7.748910e-02   \n",
       "max           1.694057e+01  3.429427e+01    3.467825e+01  2.857527e+01   \n",
       "\n",
       "       gyro_pc_spread    speed_mean  speed_median  ...    second_std  \\\n",
       "count    7.939000e+03  7.939000e+03  7.939000e+03  ...  7.939000e+03   \n",
       "mean    -6.174121e-18  3.027906e-16  6.368504e-17  ...  6.267817e-17   \n",
       "std      1.000063e+00  1.000063e+00  1.000063e+00  ...  1.000063e+00   \n",
       "min     -4.769338e-01 -1.987609e+00 -1.409070e+00  ... -1.882765e+00   \n",
       "25%     -2.756335e-01 -7.383328e-01 -7.663352e-01  ... -7.227561e-01   \n",
       "50%     -2.314391e-01 -2.150629e-01 -2.388728e-01  ... -1.233851e-01   \n",
       "75%     -1.606479e-01  6.101081e-01  6.079683e-01  ...  6.032076e-01   \n",
       "max      1.822551e+01  4.312907e+00  3.527370e+00  ...  1.412638e+01   \n",
       "\n",
       "       second_spread    over_speed   over_second  over_acceleration_x  \\\n",
       "count   7.939000e+03  7.939000e+03  7.939000e+03         7.939000e+03   \n",
       "mean    3.945005e-17  3.052099e-16 -1.153295e-16        -7.215086e-17   \n",
       "std     1.000063e+00  1.000063e+00  1.000063e+00         1.000063e+00   \n",
       "min    -1.878490e+00 -8.315435e-01 -6.904687e-01        -1.390601e+00   \n",
       "25%    -7.502336e-01 -7.705905e-01 -6.904687e-01        -7.157829e-01   \n",
       "50%    -1.365864e-01 -4.211267e-01 -5.378694e-01        -2.365645e-01   \n",
       "75%     6.188211e-01  4.687871e-01  4.709818e-01         4.578130e-01   \n",
       "max     1.407828e+01  7.584033e+00  1.840423e+01         1.095172e+01   \n",
       "\n",
       "       over_acceleration_y  over_acceleration_z   over_gyro_x   over_gyro_y  \\\n",
       "count         7.939000e+03         7.939000e+03  7.939000e+03  7.939000e+03   \n",
       "mean         -9.555554e-17         5.628729e-19 -2.121436e-17 -3.736637e-17   \n",
       "std           1.000063e+00         1.000063e+00  1.000063e+00  1.000063e+00   \n",
       "min          -1.040193e+00        -1.041998e+00 -1.375954e+00 -1.479895e+00   \n",
       "25%          -7.651875e-01        -7.877953e-01 -7.601378e-01 -7.377072e-01   \n",
       "50%          -2.858195e-01        -3.617028e-01 -2.458660e-01 -2.347075e-01   \n",
       "75%           4.761233e-01         5.631116e-01  5.239039e-01  5.145158e-01   \n",
       "max           9.059334e+00         7.392697e+00  9.544952e+00  1.041974e+01   \n",
       "\n",
       "        over_gyro_z  \n",
       "count  7.939000e+03  \n",
       "mean   3.382831e-17  \n",
       "std    1.000063e+00  \n",
       "min   -1.468457e+00  \n",
       "25%   -7.365042e-01  \n",
       "50%   -2.380789e-01  \n",
       "75%    4.834178e-01  \n",
       "max    1.077607e+01  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_mean</th>\n",
       "      <th>acceleration_median</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>acceleration_spread</th>\n",
       "      <th>gyro_pc_mean</th>\n",
       "      <th>gyro_pc_median</th>\n",
       "      <th>gyro_pc_std</th>\n",
       "      <th>gyro_pc_spread</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>...</th>\n",
       "      <th>second_std</th>\n",
       "      <th>second_spread</th>\n",
       "      <th>over_speed</th>\n",
       "      <th>over_second</th>\n",
       "      <th>over_acceleration_x</th>\n",
       "      <th>over_acceleration_y</th>\n",
       "      <th>over_acceleration_z</th>\n",
       "      <th>over_gyro_x</th>\n",
       "      <th>over_gyro_y</th>\n",
       "      <th>over_gyro_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "      <td>3.852000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-5.931926e-17</td>\n",
       "      <td>-9.702851e-16</td>\n",
       "      <td>2.048127e-16</td>\n",
       "      <td>-1.195032e-17</td>\n",
       "      <td>-1.862621e-17</td>\n",
       "      <td>1.458393e-17</td>\n",
       "      <td>-1.572663e-16</td>\n",
       "      <td>6.953305e-18</td>\n",
       "      <td>-2.386893e-16</td>\n",
       "      <td>-1.102081e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.556510e-17</td>\n",
       "      <td>-1.317165e-16</td>\n",
       "      <td>-3.620042e-17</td>\n",
       "      <td>4.621318e-16</td>\n",
       "      <td>-8.983814e-17</td>\n",
       "      <td>5.029437e-17</td>\n",
       "      <td>-8.473665e-18</td>\n",
       "      <td>3.686332e-17</td>\n",
       "      <td>-4.487584e-17</td>\n",
       "      <td>-1.354057e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "      <td>1.000130e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-9.517856e+00</td>\n",
       "      <td>-9.678875e+00</td>\n",
       "      <td>-1.406150e+00</td>\n",
       "      <td>-1.379592e+00</td>\n",
       "      <td>-1.043166e+01</td>\n",
       "      <td>-9.735176e+00</td>\n",
       "      <td>-7.270629e-01</td>\n",
       "      <td>-4.629994e-01</td>\n",
       "      <td>-1.865650e+00</td>\n",
       "      <td>-1.395112e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.854968e+00</td>\n",
       "      <td>-1.842653e+00</td>\n",
       "      <td>-8.195180e-01</td>\n",
       "      <td>-6.477713e-01</td>\n",
       "      <td>-1.372258e+00</td>\n",
       "      <td>-1.045952e+00</td>\n",
       "      <td>-1.009899e+00</td>\n",
       "      <td>-1.359921e+00</td>\n",
       "      <td>-1.443346e+00</td>\n",
       "      <td>-1.455797e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-9.932039e-02</td>\n",
       "      <td>-7.957876e-02</td>\n",
       "      <td>-4.246305e-01</td>\n",
       "      <td>-4.625899e-01</td>\n",
       "      <td>-3.243065e-01</td>\n",
       "      <td>-1.786610e-01</td>\n",
       "      <td>-3.213616e-01</td>\n",
       "      <td>-2.587445e-01</td>\n",
       "      <td>-7.470991e-01</td>\n",
       "      <td>-7.792574e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.427452e-01</td>\n",
       "      <td>-7.444038e-01</td>\n",
       "      <td>-7.628744e-01</td>\n",
       "      <td>-6.477713e-01</td>\n",
       "      <td>-7.187891e-01</td>\n",
       "      <td>-7.627491e-01</td>\n",
       "      <td>-7.761838e-01</td>\n",
       "      <td>-7.824426e-01</td>\n",
       "      <td>-7.551285e-01</td>\n",
       "      <td>-7.572613e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-1.508900e-02</td>\n",
       "      <td>-2.272165e-03</td>\n",
       "      <td>-1.587854e-01</td>\n",
       "      <td>-1.717348e-01</td>\n",
       "      <td>-1.138947e-02</td>\n",
       "      <td>-5.136919e-02</td>\n",
       "      <td>-1.958964e-01</td>\n",
       "      <td>-2.089942e-01</td>\n",
       "      <td>-2.424808e-01</td>\n",
       "      <td>-2.662417e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.370580e-01</td>\n",
       "      <td>-1.459317e-01</td>\n",
       "      <td>-4.230129e-01</td>\n",
       "      <td>-6.477713e-01</td>\n",
       "      <td>-2.435390e-01</td>\n",
       "      <td>-2.986110e-01</td>\n",
       "      <td>-3.519392e-01</td>\n",
       "      <td>-2.501882e-01</td>\n",
       "      <td>-2.501863e-01</td>\n",
       "      <td>-2.467564e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.830606e-02</td>\n",
       "      <td>7.102765e-02</td>\n",
       "      <td>1.681711e-01</td>\n",
       "      <td>1.762076e-01</td>\n",
       "      <td>2.882491e-01</td>\n",
       "      <td>1.208569e-01</td>\n",
       "      <td>-2.988886e-02</td>\n",
       "      <td>-1.315703e-01</td>\n",
       "      <td>5.971829e-01</td>\n",
       "      <td>6.360827e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.472530e-01</td>\n",
       "      <td>6.609556e-01</td>\n",
       "      <td>4.428247e-01</td>\n",
       "      <td>4.364485e-01</td>\n",
       "      <td>4.527373e-01</td>\n",
       "      <td>4.775747e-01</td>\n",
       "      <td>5.022658e-01</td>\n",
       "      <td>5.473237e-01</td>\n",
       "      <td>5.427599e-01</td>\n",
       "      <td>5.410946e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.184967e+01</td>\n",
       "      <td>3.233498e+01</td>\n",
       "      <td>1.769901e+01</td>\n",
       "      <td>1.528644e+01</td>\n",
       "      <td>1.382471e+01</td>\n",
       "      <td>1.179318e+01</td>\n",
       "      <td>1.604057e+01</td>\n",
       "      <td>2.192246e+01</td>\n",
       "      <td>3.946116e+00</td>\n",
       "      <td>3.199149e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.607630e+00</td>\n",
       "      <td>6.626252e+00</td>\n",
       "      <td>5.548839e+00</td>\n",
       "      <td>9.282254e+00</td>\n",
       "      <td>9.722735e+00</td>\n",
       "      <td>6.631993e+00</td>\n",
       "      <td>6.382626e+00</td>\n",
       "      <td>5.392404e+00</td>\n",
       "      <td>5.764236e+00</td>\n",
       "      <td>6.291091e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acceleration_mean  acceleration_median  acceleration_std  \\\n",
       "count       3.852000e+03         3.852000e+03      3.852000e+03   \n",
       "mean       -5.931926e-17        -9.702851e-16      2.048127e-16   \n",
       "std         1.000130e+00         1.000130e+00      1.000130e+00   \n",
       "min        -9.517856e+00        -9.678875e+00     -1.406150e+00   \n",
       "25%        -9.932039e-02        -7.957876e-02     -4.246305e-01   \n",
       "50%        -1.508900e-02        -2.272165e-03     -1.587854e-01   \n",
       "75%         6.830606e-02         7.102765e-02      1.681711e-01   \n",
       "max         3.184967e+01         3.233498e+01      1.769901e+01   \n",
       "\n",
       "       acceleration_spread  gyro_pc_mean  gyro_pc_median   gyro_pc_std  \\\n",
       "count         3.852000e+03  3.852000e+03    3.852000e+03  3.852000e+03   \n",
       "mean         -1.195032e-17 -1.862621e-17    1.458393e-17 -1.572663e-16   \n",
       "std           1.000130e+00  1.000130e+00    1.000130e+00  1.000130e+00   \n",
       "min          -1.379592e+00 -1.043166e+01   -9.735176e+00 -7.270629e-01   \n",
       "25%          -4.625899e-01 -3.243065e-01   -1.786610e-01 -3.213616e-01   \n",
       "50%          -1.717348e-01 -1.138947e-02   -5.136919e-02 -1.958964e-01   \n",
       "75%           1.762076e-01  2.882491e-01    1.208569e-01 -2.988886e-02   \n",
       "max           1.528644e+01  1.382471e+01    1.179318e+01  1.604057e+01   \n",
       "\n",
       "       gyro_pc_spread    speed_mean  speed_median  ...    second_std  \\\n",
       "count    3.852000e+03  3.852000e+03  3.852000e+03  ...  3.852000e+03   \n",
       "mean     6.953305e-18 -2.386893e-16 -1.102081e-16  ... -2.556510e-17   \n",
       "std      1.000130e+00  1.000130e+00  1.000130e+00  ...  1.000130e+00   \n",
       "min     -4.629994e-01 -1.865650e+00 -1.395112e+00  ... -1.854968e+00   \n",
       "25%     -2.587445e-01 -7.470991e-01 -7.792574e-01  ... -7.427452e-01   \n",
       "50%     -2.089942e-01 -2.424808e-01 -2.662417e-01  ... -1.370580e-01   \n",
       "75%     -1.315703e-01  5.971829e-01  6.360827e-01  ...  6.472530e-01   \n",
       "max      2.192246e+01  3.946116e+00  3.199149e+00  ...  6.607630e+00   \n",
       "\n",
       "       second_spread    over_speed   over_second  over_acceleration_x  \\\n",
       "count   3.852000e+03  3.852000e+03  3.852000e+03         3.852000e+03   \n",
       "mean   -1.317165e-16 -3.620042e-17  4.621318e-16        -8.983814e-17   \n",
       "std     1.000130e+00  1.000130e+00  1.000130e+00         1.000130e+00   \n",
       "min    -1.842653e+00 -8.195180e-01 -6.477713e-01        -1.372258e+00   \n",
       "25%    -7.444038e-01 -7.628744e-01 -6.477713e-01        -7.187891e-01   \n",
       "50%    -1.459317e-01 -4.230129e-01 -6.477713e-01        -2.435390e-01   \n",
       "75%     6.609556e-01  4.428247e-01  4.364485e-01         4.527373e-01   \n",
       "max     6.626252e+00  5.548839e+00  9.282254e+00         9.722735e+00   \n",
       "\n",
       "       over_acceleration_y  over_acceleration_z   over_gyro_x   over_gyro_y  \\\n",
       "count         3.852000e+03         3.852000e+03  3.852000e+03  3.852000e+03   \n",
       "mean          5.029437e-17        -8.473665e-18  3.686332e-17 -4.487584e-17   \n",
       "std           1.000130e+00         1.000130e+00  1.000130e+00  1.000130e+00   \n",
       "min          -1.045952e+00        -1.009899e+00 -1.359921e+00 -1.443346e+00   \n",
       "25%          -7.627491e-01        -7.761838e-01 -7.824426e-01 -7.551285e-01   \n",
       "50%          -2.986110e-01        -3.519392e-01 -2.501882e-01 -2.501863e-01   \n",
       "75%           4.775747e-01         5.022658e-01  5.473237e-01  5.427599e-01   \n",
       "max           6.631993e+00         6.382626e+00  5.392404e+00  5.764236e+00   \n",
       "\n",
       "        over_gyro_z  \n",
       "count  3.852000e+03  \n",
       "mean  -1.354057e-16  \n",
       "std    1.000130e+00  \n",
       "min   -1.455797e+00  \n",
       "25%   -7.572613e-01  \n",
       "50%   -2.467564e-01  \n",
       "75%    5.410946e-01  \n",
       "max    6.291091e+00  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = pd.DataFrame(scaler.fit_transform(X_test), columns = X_test.columns)\n",
    "X_test_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to build model\n",
    "\n",
    "Writing a function here so that the Keras sklearn wrapper can be used for the GridSearchCV (last section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_layers=1, num_nodes=32, lr=0.001, dropout=False, opt=\"SGD\", input_shape=(24,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_nodes, activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    if dropout:\n",
    "        model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    if num_layers > 1:\n",
    "        for i in range(num_layers - 1):\n",
    "            model.add(Dense(num_nodes, activation='relu'))\n",
    "            if dropout:\n",
    "                model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if opt == \"SGD\":\n",
    "        optimiser = optimizers.SGD(lr=lr)\n",
    "    elif opt == \"RMSprop\":\n",
    "        optimiser = optimizers.RMSprop(lr=lr)\n",
    "    elif opt == \"Adam\":\n",
    "        optimiser = optimizers.Adam(lr=lr)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", \n",
    "               optimizer=optimiser,\n",
    "               metrics=[\"accuracy\"])\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1 of 5\n",
      "Total time taken: 51 seconds\n",
      "Processing fold 2 of 5\n",
      "Total time taken: 106 seconds\n",
      "Processing fold 3 of 5\n",
      "Total time taken: 164 seconds\n",
      "Processing fold 4 of 5\n",
      "Total time taken: 221 seconds\n",
      "Processing fold 5 of 5\n",
      "Total time taken: 280 seconds\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "k = 5\n",
    "num_val_samples = X_train_scaled.shape[0] // k\n",
    "num_epochs = 60\n",
    "batch_size = 32\n",
    "all_val_loss = []\n",
    "all_train_loss = []\n",
    "all_val_acc = []\n",
    "all_train_acc = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('Processing fold {} of {}'.format(i + 1, k))\n",
    "\n",
    "    val_data = X_train_scaled[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    partial_train_data = np.concatenate([X_train_scaled[:i * num_val_samples], \n",
    "                                         X_train_scaled[(i + 1) * num_val_samples:]], axis=0)\n",
    "    partial_train_targets = np.concatenate([y_train[:i * num_val_samples], \n",
    "                                            y_train[(i + 1) * num_val_samples:]], axis=0)\n",
    "    \n",
    "    model = build_model(num_layers=2, num_nodes=64, lr=0.001, opt=\"SGD\", dropout=True, input_shape=((24,)))\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, verbose=0,\n",
    "                        validation_data=((val_data, val_targets)), batch_size=batch_size)\n",
    "\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "    all_val_loss.append(val_loss)\n",
    "    all_train_loss.append(loss)\n",
    "    all_val_acc.append(val_acc)\n",
    "    all_train_acc.append(acc)\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"Total time taken: {} seconds\".format((end_time - start_time).seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6389220841585539, train acc: 0.6245906949043274\n",
      "Val loss: 0.6165098827818165, val acc: 0.6482671618461608\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_val_loss = [np.mean([x[i] for x in all_val_loss]) for i in range(num_epochs)]\n",
    "average_train_loss = [np.mean([x[i] for x in all_train_loss]) for i in range(num_epochs)]\n",
    "\n",
    "average_val_acc = [np.mean([x[i] for x in all_val_acc]) for i in range(num_epochs)]\n",
    "average_train_acc = [np.mean([x[i] for x in all_train_acc]) for i in range(num_epochs)]\n",
    "\n",
    "print(\"Train loss: {}, train acc: {}\".format(average_train_loss[-1], average_train_acc[-1]))\n",
    "print(\"Val loss: {}, val acc: {}\".format(average_val_loss[-1], average_val_acc[-1]))\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(range(1, len(average_train_loss) + 1), average_train_loss, color=\"r\", label=\"Training loss\")\n",
    "plt.plot(range(1, len(average_val_loss) + 1), average_val_loss, color=\"b\", label=\"Validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing predictions after getting a satisfactory model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7939/7939 [==============================] - 2s 192us/step - loss: 0.7502 - accuracy: 0.5216\n",
      "Epoch 2/60\n",
      "7939/7939 [==============================] - 1s 117us/step - loss: 0.7325 - accuracy: 0.5300\n",
      "Epoch 3/60\n",
      "7939/7939 [==============================] - 1s 119us/step - loss: 0.7226 - accuracy: 0.5414\n",
      "Epoch 4/60\n",
      "7939/7939 [==============================] - 1s 117us/step - loss: 0.7221 - accuracy: 0.5405\n",
      "Epoch 5/60\n",
      "7939/7939 [==============================] - 1s 119us/step - loss: 0.7028 - accuracy: 0.5570\n",
      "Epoch 6/60\n",
      "7939/7939 [==============================] - 1s 116us/step - loss: 0.6982 - accuracy: 0.5572\n",
      "Epoch 7/60\n",
      "7939/7939 [==============================] - 1s 117us/step - loss: 0.6922 - accuracy: 0.5732\n",
      "Epoch 8/60\n",
      "7939/7939 [==============================] - 1s 117us/step - loss: 0.6849 - accuracy: 0.5770\n",
      "Epoch 9/60\n",
      "7939/7939 [==============================] - 1s 117us/step - loss: 0.6824 - accuracy: 0.5808\n",
      "Epoch 10/60\n",
      "7939/7939 [==============================] - 1s 118us/step - loss: 0.6793 - accuracy: 0.5870\n",
      "Epoch 11/60\n",
      "7939/7939 [==============================] - 1s 118us/step - loss: 0.6784 - accuracy: 0.5899\n",
      "Epoch 12/60\n",
      "7939/7939 [==============================] - 1s 117us/step - loss: 0.6689 - accuracy: 0.5925\n",
      "Epoch 13/60\n",
      "7939/7939 [==============================] - 1s 116us/step - loss: 0.6649 - accuracy: 0.5903\n",
      "Epoch 14/60\n",
      "7939/7939 [==============================] - 1s 117us/step - loss: 0.6673 - accuracy: 0.5952\n",
      "Epoch 15/60\n",
      "7939/7939 [==============================] - 1s 117us/step - loss: 0.6665 - accuracy: 0.5924\n",
      "Epoch 16/60\n",
      "7939/7939 [==============================] - 1s 120us/step - loss: 0.6617 - accuracy: 0.6045\n",
      "Epoch 17/60\n",
      "7939/7939 [==============================] - 1s 127us/step - loss: 0.6646 - accuracy: 0.6030\n",
      "Epoch 18/60\n",
      "7939/7939 [==============================] - 1s 124us/step - loss: 0.6663 - accuracy: 0.5971\n",
      "Epoch 19/60\n",
      "7939/7939 [==============================] - 1s 125us/step - loss: 0.6600 - accuracy: 0.6078\n",
      "Epoch 20/60\n",
      "7939/7939 [==============================] - 1s 125us/step - loss: 0.6642 - accuracy: 0.6012\n",
      "Epoch 21/60\n",
      "7939/7939 [==============================] - 1s 124us/step - loss: 0.6587 - accuracy: 0.6066\n",
      "Epoch 22/60\n",
      "7939/7939 [==============================] - 1s 126us/step - loss: 0.6550 - accuracy: 0.6040\n",
      "Epoch 23/60\n",
      "7939/7939 [==============================] - 1s 129us/step - loss: 0.6551 - accuracy: 0.6133\n",
      "Epoch 24/60\n",
      "7939/7939 [==============================] - 1s 128us/step - loss: 0.6546 - accuracy: 0.6114\n",
      "Epoch 25/60\n",
      "7939/7939 [==============================] - 1s 125us/step - loss: 0.6531 - accuracy: 0.6110\n",
      "Epoch 26/60\n",
      "7939/7939 [==============================] - 1s 124us/step - loss: 0.6577 - accuracy: 0.6081\n",
      "Epoch 27/60\n",
      "7939/7939 [==============================] - 1s 129us/step - loss: 0.6514 - accuracy: 0.6128\n",
      "Epoch 28/60\n",
      "7939/7939 [==============================] - 1s 129us/step - loss: 0.6508 - accuracy: 0.6138\n",
      "Epoch 29/60\n",
      "7939/7939 [==============================] - 1s 128us/step - loss: 0.6493 - accuracy: 0.6055\n",
      "Epoch 30/60\n",
      "7939/7939 [==============================] - 1s 129us/step - loss: 0.6532 - accuracy: 0.6193\n",
      "Epoch 31/60\n",
      "7939/7939 [==============================] - 1s 128us/step - loss: 0.6539 - accuracy: 0.6173\n",
      "Epoch 32/60\n",
      "7939/7939 [==============================] - 1s 128us/step - loss: 0.6444 - accuracy: 0.6201\n",
      "Epoch 33/60\n",
      "7939/7939 [==============================] - 1s 129us/step - loss: 0.6480 - accuracy: 0.6220\n",
      "Epoch 34/60\n",
      "7939/7939 [==============================] - 1s 130us/step - loss: 0.6485 - accuracy: 0.6142\n",
      "Epoch 35/60\n",
      "7939/7939 [==============================] - 1s 135us/step - loss: 0.6447 - accuracy: 0.6151\n",
      "Epoch 36/60\n",
      "7939/7939 [==============================] - 1s 130us/step - loss: 0.6438 - accuracy: 0.6211\n",
      "Epoch 37/60\n",
      "7939/7939 [==============================] - 1s 130us/step - loss: 0.6421 - accuracy: 0.6229\n",
      "Epoch 38/60\n",
      "7939/7939 [==============================] - 1s 131us/step - loss: 0.6439 - accuracy: 0.6233\n",
      "Epoch 39/60\n",
      "7939/7939 [==============================] - 1s 131us/step - loss: 0.6480 - accuracy: 0.6165\n",
      "Epoch 40/60\n",
      "7939/7939 [==============================] - 1s 133us/step - loss: 0.6434 - accuracy: 0.6201\n",
      "Epoch 41/60\n",
      "7939/7939 [==============================] - 1s 132us/step - loss: 0.6448 - accuracy: 0.6202\n",
      "Epoch 42/60\n",
      "7939/7939 [==============================] - 1s 133us/step - loss: 0.6462 - accuracy: 0.6183\n",
      "Epoch 43/60\n",
      "7939/7939 [==============================] - 1s 132us/step - loss: 0.6386 - accuracy: 0.6197\n",
      "Epoch 44/60\n",
      "7939/7939 [==============================] - 1s 132us/step - loss: 0.6425 - accuracy: 0.6214\n",
      "Epoch 45/60\n",
      "7939/7939 [==============================] - 1s 133us/step - loss: 0.6418 - accuracy: 0.6245\n",
      "Epoch 46/60\n",
      "7939/7939 [==============================] - 1s 134us/step - loss: 0.6384 - accuracy: 0.6233\n",
      "Epoch 47/60\n",
      "7939/7939 [==============================] - 1s 134us/step - loss: 0.6382 - accuracy: 0.6289\n",
      "Epoch 48/60\n",
      "7939/7939 [==============================] - 1s 133us/step - loss: 0.6417 - accuracy: 0.6299\n",
      "Epoch 49/60\n",
      "7939/7939 [==============================] - 1s 134us/step - loss: 0.6396 - accuracy: 0.6244\n",
      "Epoch 50/60\n",
      "7939/7939 [==============================] - 1s 133us/step - loss: 0.6431 - accuracy: 0.6185\n",
      "Epoch 51/60\n",
      "7939/7939 [==============================] - 1s 137us/step - loss: 0.6414 - accuracy: 0.6206\n",
      "Epoch 52/60\n",
      "7939/7939 [==============================] - 1s 144us/step - loss: 0.6423 - accuracy: 0.6326\n",
      "Epoch 53/60\n",
      "7939/7939 [==============================] - 1s 145us/step - loss: 0.6406 - accuracy: 0.6226\n",
      "Epoch 54/60\n",
      "7939/7939 [==============================] - 1s 139us/step - loss: 0.6381 - accuracy: 0.6313\n",
      "Epoch 55/60\n",
      "7939/7939 [==============================] - 1s 144us/step - loss: 0.6364 - accuracy: 0.6290\n",
      "Epoch 56/60\n",
      "7939/7939 [==============================] - 1s 143us/step - loss: 0.6384 - accuracy: 0.6278\n",
      "Epoch 57/60\n",
      "7939/7939 [==============================] - 1s 138us/step - loss: 0.6353 - accuracy: 0.6227\n",
      "Epoch 58/60\n",
      "7939/7939 [==============================] - 1s 141us/step - loss: 0.6409 - accuracy: 0.6287\n",
      "Epoch 59/60\n",
      "7939/7939 [==============================] - 1s 143us/step - loss: 0.6354 - accuracy: 0.6278\n",
      "Epoch 60/60\n",
      "7939/7939 [==============================] - 1s 143us/step - loss: 0.6359 - accuracy: 0.6279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6498788508134302"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(num_layers=2, num_nodes=64, lr=0.001, opt=\"SGD\", dropout=True, input_shape=((24,)))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "res = model.predict(X_test_scaled)\n",
    "res = [round(num[0]) for num in res]\n",
    "\n",
    "roc_auc_score(y_test, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomised grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7939/7939 [==============================] - 4s 469us/step - loss: 0.6427 - accuracy: 0.6274\n",
      "Epoch 2/20\n",
      "7939/7939 [==============================] - 3s 342us/step - loss: 0.6228 - accuracy: 0.6430\n",
      "Epoch 3/20\n",
      "7939/7939 [==============================] - 3s 354us/step - loss: 0.6144 - accuracy: 0.6487\n",
      "Epoch 4/20\n",
      "7939/7939 [==============================] - 3s 359us/step - loss: 0.6139 - accuracy: 0.6455\n",
      "Epoch 5/20\n",
      "7939/7939 [==============================] - 3s 362us/step - loss: 0.6107 - accuracy: 0.6507\n",
      "Epoch 6/20\n",
      "7939/7939 [==============================] - 3s 359us/step - loss: 0.6082 - accuracy: 0.6551\n",
      "Epoch 7/20\n",
      "7939/7939 [==============================] - 3s 402us/step - loss: 0.6050 - accuracy: 0.6556\n",
      "Epoch 8/20\n",
      "7939/7939 [==============================] - 3s 408us/step - loss: 0.6078 - accuracy: 0.6574\n",
      "Epoch 9/20\n",
      "7939/7939 [==============================] - 3s 401us/step - loss: 0.6055 - accuracy: 0.6618\n",
      "Epoch 10/20\n",
      "7939/7939 [==============================] - 3s 379us/step - loss: 0.6044 - accuracy: 0.6575\n",
      "Epoch 11/20\n",
      "7939/7939 [==============================] - 3s 371us/step - loss: 0.6026 - accuracy: 0.6604\n",
      "Epoch 12/20\n",
      "7939/7939 [==============================] - 3s 375us/step - loss: 0.6027 - accuracy: 0.6589\n",
      "Epoch 13/20\n",
      "7939/7939 [==============================] - 3s 376us/step - loss: 0.6001 - accuracy: 0.6592\n",
      "Epoch 14/20\n",
      "7939/7939 [==============================] - 3s 366us/step - loss: 0.5996 - accuracy: 0.6597\n",
      "Epoch 15/20\n",
      "7939/7939 [==============================] - 3s 368us/step - loss: 0.5987 - accuracy: 0.6613\n",
      "Epoch 16/20\n",
      "7939/7939 [==============================] - 3s 364us/step - loss: 0.6018 - accuracy: 0.6599\n",
      "Epoch 17/20\n",
      "7939/7939 [==============================] - 3s 360us/step - loss: 0.5974 - accuracy: 0.6639\n",
      "Epoch 18/20\n",
      "7939/7939 [==============================] - 3s 362us/step - loss: 0.6000 - accuracy: 0.6634\n",
      "Epoch 19/20\n",
      "7939/7939 [==============================] - 3s 361us/step - loss: 0.5999 - accuracy: 0.6643\n",
      "Epoch 20/20\n",
      "7939/7939 [==============================] - 3s 361us/step - loss: 0.5994 - accuracy: 0.6641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x1a430e7110>,\n",
       "                   iid='warn', n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'dropout': [True, False],\n",
       "                                        'lr': [0.0001, 0.001, 0.01, 0.1],\n",
       "                                        'num_layers': [1, 2],\n",
       "                                        'num_nodes': [32, 64, 128, 256],\n",
       "                                        'opt': ['SGD', 'RMSprop', 'Adam']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=299, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params)\n",
    "\n",
    "params = {'num_nodes' : [32, 64, 128, 256],\n",
    "         'num_layers' : [1, 2], \n",
    "         'lr' : [0.0001, 0.001, 0.01, 0.1],\n",
    "         'dropout' : [True, False],\n",
    "         'opt' : ['SGD', \"RMSprop\", \"Adam\"]}\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=20, batch_size=32)\n",
    "# grid = GridSearchCV(model, param_grid=params, n_jobs=4, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "seed = 299\n",
    "num_iter = 5\n",
    "\n",
    "random_grid = RandomizedSearchCV(estimator=model, \n",
    "                                 param_distributions=params, \n",
    "                                 scoring='roc_auc', n_iter=num_iter, cv=5, n_jobs=-1,\n",
    "                                 random_state=seed)\n",
    "random_grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7289189711320792\n",
      "{'opt': 'Adam', 'num_nodes': 128, 'num_layers': 2, 'lr': 0.001, 'dropout': True}\n"
     ]
    }
   ],
   "source": [
    "print(random_grid.best_score_)\n",
    "print(random_grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
