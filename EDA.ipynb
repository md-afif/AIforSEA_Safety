{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00001-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(1613558, 11)\n",
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00000-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(3227112, 11)\n",
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00003-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(4840665, 11)\n",
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00002-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(6454220, 11)\n",
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00005-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(8067771, 11)\n",
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00009-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(9681333, 11)\n",
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00004-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(11294892, 11)\n",
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00008-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(12908452, 11)\n",
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00007-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(14522008, 11)\n",
      "/Users/itn.muhammad.afif/Documents/notebooks/AIforSEA_Safety/../data/safety/features/part-00006-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "(16135561, 11)\n"
     ]
    }
   ],
   "source": [
    "# Reading and merging all csv files into one dataframe\n",
    "\n",
    "DATA_DIR = '../data/safety/features'\n",
    "\n",
    "colnames = ['bookingID', 'Accuracy', 'Bearing', 'acceleration_x',\n",
    "             'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y',\n",
    "             'gyro_z', 'second', 'Speed']\n",
    "raw_df = pd.DataFrame(columns=colnames)\n",
    "\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    if filename !=  '.DS_Store':\n",
    "        print(os.path.join(os.getcwd(), DATA_DIR, filename))\n",
    "        new_df = pd.read_csv(os.path.join(os.getcwd(), DATA_DIR, filename))\n",
    "        raw_df = pd.concat([raw_df, new_df], axis=0, ignore_index=True)\n",
    "        print(raw_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111669149733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>335007449205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>171798691856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1520418422900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>798863917116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bookingID  label\n",
       "0   111669149733      0\n",
       "1   335007449205      1\n",
       "2   171798691856      0\n",
       "3  1520418422900      0\n",
       "4   798863917116      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in labels csv\n",
    "\n",
    "LABEL_DIR = os.path.join(os.getcwd(), '../data/safety/labels', \n",
    "                         'part-00000-e9445087-aa0a-433b-a7f6-7f4c19d78ad6-c000.csv')\n",
    "\n",
    "label_df = pd.read_csv(LABEL_DIR)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking and dropping the 18 duplicate bookingIDs \n",
    "# These bookingIDs are labelled both 0 and 1\n",
    "\n",
    "label_counts = np.unique(label_df['bookingID'].values, return_counts=True)\n",
    "label_counts = pd.DataFrame({'bookingID' : label_counts[0], \n",
    "                             'counts' : label_counts[1]})\n",
    "\n",
    "dup = label_counts[label_counts['counts'] > 1]\n",
    "\n",
    "dup_id = dup['bookingID'].values\n",
    "\n",
    "# bookingIDs are labelled both 0 and 1, drop these IDs since we have sufficient data\n",
    "\n",
    "for b in dup_id:\n",
    "    idx1 = label_df[label_df['bookingID'] == b].index\n",
    "    idx2 = raw_df[raw_df['bookingID'] == b].index\n",
    "\n",
    "    label_df = label_df.drop(idx1, axis=0)\n",
    "    raw_df = raw_df.drop(idx2, axis=0)\n",
    "    \n",
    "df = pd.merge(raw_df, label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping inaccurate readings (rows with values that clearly dont make sense)\n",
    "# i.e. rows with accuracy > 30 and speed < 0\n",
    "\n",
    "df = df.loc[(df['Accuracy'] <= 30) & (df['Speed'] >= 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Adding additional columns \n",
    "1. Distance = 'Speed' * 'second' \n",
    "2. Acceleration = sqrt('acceleration_x' ** 2, 'acceleration_y' ** 2, 'acceleration_z' ** 2) (Euclidean distance)\n",
    "3. gyro_pc (magnitude) = PC1 of PCA applied on gyro_x, gyro_y, gyro_z\n",
    "4. Speed_diff = difference in speed per reading for each bookingID\n",
    "5. Bearing_diff = difference in bearing per reading for each bookingID\n",
    "\n",
    "Note that speed_diff and bearing_diff are not necessarily per second difference. This is because some readings may have been dropped as they are inaccurate, hence the gaps between some readings may be larger than a second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75386447, 0.12894376, 0.11719177])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a copy of the raw data\n",
    "df_add = df.copy(deep=True).sort_values(by=['bookingID', 'second']).reset_index(drop=True)\n",
    "\n",
    "# Applying PCA to gyro coordinates\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "gyro_cols = ['gyro_x', 'gyro_y', 'gyro_z']\n",
    "gyro_coord = df_add[gyro_cols]\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(gyro_coord)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Bearing</th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>acceleration_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>second</th>\n",
       "      <th>Speed</th>\n",
       "      <th>label</th>\n",
       "      <th>gyro_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>0.818112</td>\n",
       "      <td>-9.941461</td>\n",
       "      <td>-2.014999</td>\n",
       "      <td>-0.016245</td>\n",
       "      <td>-0.094040</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.442991</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.089042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>0.546405</td>\n",
       "      <td>-9.835590</td>\n",
       "      <td>-2.038925</td>\n",
       "      <td>-0.047092</td>\n",
       "      <td>-0.078874</td>\n",
       "      <td>0.043187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.076595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.706207</td>\n",
       "      <td>-9.270792</td>\n",
       "      <td>-1.209448</td>\n",
       "      <td>-0.028965</td>\n",
       "      <td>-0.032652</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.032230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.416705</td>\n",
       "      <td>-9.548032</td>\n",
       "      <td>-1.860977</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.025753</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.598145</td>\n",
       "      <td>-9.853534</td>\n",
       "      <td>-1.378574</td>\n",
       "      <td>-0.014297</td>\n",
       "      <td>-0.046206</td>\n",
       "      <td>0.021902</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bookingID  Accuracy     Bearing  acceleration_x  acceleration_y  \\\n",
       "0         0      12.0  143.298294        0.818112       -9.941461   \n",
       "1         0       8.0  143.298294        0.546405       -9.835590   \n",
       "2         0       8.0  143.298294       -1.706207       -9.270792   \n",
       "3         0       8.0  143.298294       -1.416705       -9.548032   \n",
       "4         0       8.0  143.298294       -0.598145       -9.853534   \n",
       "\n",
       "   acceleration_z    gyro_x    gyro_y    gyro_z  second     Speed  label  \\\n",
       "0       -2.014999 -0.016245 -0.094040  0.070732     0.0  3.442991      0   \n",
       "1       -2.038925 -0.047092 -0.078874  0.043187     1.0  0.228454      0   \n",
       "2       -1.209448 -0.028965 -0.032652  0.015390     2.0  0.228454      0   \n",
       "3       -1.860977 -0.022413  0.005049 -0.025753     3.0  0.228454      0   \n",
       "4       -1.378574 -0.014297 -0.046206  0.021902     4.0  0.228454      0   \n",
       "\n",
       "    gyro_pc  \n",
       "0 -0.089042  \n",
       "1 -0.076595  \n",
       "2 -0.032230  \n",
       "3  0.002411  \n",
       "4 -0.044964  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since first PC accounts for > 70% of variance, we only keep 1 PC to explain gyro\n",
    "\n",
    "df_add['gyro_pc'] = pca.transform(df_add[gyro_cols])[:, 0]\n",
    "df_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding distance and acceleration columns\n",
    "\n",
    "df_add['distance'] = df_add['Speed'] * df_add['second']\n",
    "df_add['acceleration'] = np.sqrt(np.power(df_add['acceleration_x'], 2) + \n",
    "                                 np.power(df_add['acceleration_y'], 2) + \n",
    "                                 np.power(df_add['acceleration_z'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate speed difference\n",
    "def calc_speed_diff(x):\n",
    "    return x['Speed'].diff()\n",
    "\n",
    "# Function to calculate bearing difference\n",
    "def calc_bearing_diff(x):\n",
    "    return x['Bearing'].diff()\n",
    "\n",
    "# Large change in speed == sudden speeding/braking\n",
    "# Large change in bearing == sudden change in direction/lane change\n",
    "# FURTHER ANALYSIS SHOWED THAT THIS IS APPARENTLY NOT TRUE\n",
    "\n",
    "df_add['speed_diff'] = df_add.groupby('bookingID').apply(calc_speed_diff).fillna(method=\"backfill\").values\n",
    "df_add['bearing_diff'] = df_add.groupby('bookingID').apply(calc_bearing_diff).fillna(method=\"backfill\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Bearing</th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>acceleration_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>second</th>\n",
       "      <th>Speed</th>\n",
       "      <th>label</th>\n",
       "      <th>gyro_pc</th>\n",
       "      <th>distance</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>speed_diff</th>\n",
       "      <th>bearing_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>0.818112</td>\n",
       "      <td>-9.941461</td>\n",
       "      <td>-2.014999</td>\n",
       "      <td>-0.016245</td>\n",
       "      <td>-0.094040</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.442991</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.089042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.176551</td>\n",
       "      <td>-3.214536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>0.546405</td>\n",
       "      <td>-9.835590</td>\n",
       "      <td>-2.038925</td>\n",
       "      <td>-0.047092</td>\n",
       "      <td>-0.078874</td>\n",
       "      <td>0.043187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.076595</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>10.059553</td>\n",
       "      <td>-3.214536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.706207</td>\n",
       "      <td>-9.270792</td>\n",
       "      <td>-1.209448</td>\n",
       "      <td>-0.028965</td>\n",
       "      <td>-0.032652</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.032230</td>\n",
       "      <td>0.456909</td>\n",
       "      <td>9.503762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.416705</td>\n",
       "      <td>-9.548032</td>\n",
       "      <td>-1.860977</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.025753</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.685363</td>\n",
       "      <td>9.830320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.598145</td>\n",
       "      <td>-9.853534</td>\n",
       "      <td>-1.378574</td>\n",
       "      <td>-0.014297</td>\n",
       "      <td>-0.046206</td>\n",
       "      <td>0.021902</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044964</td>\n",
       "      <td>0.913818</td>\n",
       "      <td>9.967466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.608313</td>\n",
       "      <td>-9.539658</td>\n",
       "      <td>-1.794583</td>\n",
       "      <td>-0.007538</td>\n",
       "      <td>-0.023838</td>\n",
       "      <td>0.018068</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022816</td>\n",
       "      <td>1.142272</td>\n",
       "      <td>9.726029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.867758</td>\n",
       "      <td>-9.698615</td>\n",
       "      <td>-1.615439</td>\n",
       "      <td>0.022728</td>\n",
       "      <td>-0.012178</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011493</td>\n",
       "      <td>1.370727</td>\n",
       "      <td>9.870449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.050790</td>\n",
       "      <td>-9.745270</td>\n",
       "      <td>-1.411771</td>\n",
       "      <td>0.027603</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>1.599181</td>\n",
       "      <td>9.902906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.721213</td>\n",
       "      <td>-9.960004</td>\n",
       "      <td>-1.202271</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>-0.007702</td>\n",
       "      <td>0.014018</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006844</td>\n",
       "      <td>1.827636</td>\n",
       "      <td>10.058194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.346924</td>\n",
       "      <td>-9.532629</td>\n",
       "      <td>-1.204663</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>-0.050033</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047958</td>\n",
       "      <td>2.056090</td>\n",
       "      <td>9.614707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bookingID  Accuracy     Bearing  acceleration_x  acceleration_y  \\\n",
       "0         0      12.0  143.298294        0.818112       -9.941461   \n",
       "1         0       8.0  143.298294        0.546405       -9.835590   \n",
       "2         0       8.0  143.298294       -1.706207       -9.270792   \n",
       "3         0       8.0  143.298294       -1.416705       -9.548032   \n",
       "4         0       8.0  143.298294       -0.598145       -9.853534   \n",
       "5         0       8.0  143.298294       -0.608313       -9.539658   \n",
       "6         0       8.0  143.298294       -0.867758       -9.698615   \n",
       "7         0       8.0  143.298294       -1.050790       -9.745270   \n",
       "8         0       8.0  143.298294       -0.721213       -9.960004   \n",
       "9         0       8.0  143.298294       -0.346924       -9.532629   \n",
       "\n",
       "   acceleration_z    gyro_x    gyro_y    gyro_z  second     Speed  label  \\\n",
       "0       -2.014999 -0.016245 -0.094040  0.070732     0.0  3.442991      0   \n",
       "1       -2.038925 -0.047092 -0.078874  0.043187     1.0  0.228454      0   \n",
       "2       -1.209448 -0.028965 -0.032652  0.015390     2.0  0.228454      0   \n",
       "3       -1.860977 -0.022413  0.005049 -0.025753     3.0  0.228454      0   \n",
       "4       -1.378574 -0.014297 -0.046206  0.021902     4.0  0.228454      0   \n",
       "5       -1.794583 -0.007538 -0.023838  0.018068     5.0  0.228454      0   \n",
       "6       -1.615439  0.022728 -0.012178  0.005982     6.0  0.228454      0   \n",
       "7       -1.411771  0.027603  0.001841  0.000904     7.0  0.228454      0   \n",
       "8       -1.202271  0.001864 -0.007702  0.014018     8.0  0.228454      0   \n",
       "9       -1.204663  0.014962 -0.050033  0.025118     9.0  0.228454      0   \n",
       "\n",
       "    gyro_pc  distance  acceleration  speed_diff  bearing_diff  \n",
       "0 -0.089042  0.000000     10.176551   -3.214536           0.0  \n",
       "1 -0.076595  0.228454     10.059553   -3.214536           0.0  \n",
       "2 -0.032230  0.456909      9.503762    0.000000           0.0  \n",
       "3  0.002411  0.685363      9.830320    0.000000           0.0  \n",
       "4 -0.044964  0.913818      9.967466    0.000000           0.0  \n",
       "5 -0.022816  1.142272      9.726029    0.000000           0.0  \n",
       "6 -0.011493  1.370727      9.870449    0.000000           0.0  \n",
       "7  0.002201  1.599181      9.902906    0.000000           0.0  \n",
       "8 -0.006844  1.827636     10.058194    0.000000           0.0  \n",
       "9 -0.047958  2.056090      9.614707    0.000000           0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_add.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating df_sub1: aggregation of variables \n",
    "Taking mean, median, standard deviation, spread of acceleration, gyro_pc, speed and second \\\n",
    "Spread is defined as the difference between the maximum and minimum value of the feature in the trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "df_sub1 = df_add.groupby('bookingID')['acceleration', 'gyro_pc', 'Speed', 'second'].aggregate([\n",
    "    'mean', 'median', 'std', spread\n",
    "])\n",
    "\n",
    "df_sub1.columns = [\"_\".join(x) for x in df_sub1.columns.ravel()]\n",
    "df_sub1.columns = [col.lower() for col in df_sub1.columns]\n",
    "df_sub1 = df_sub1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_mean</th>\n",
       "      <th>acceleration_median</th>\n",
       "      <th>acceleration_std</th>\n",
       "      <th>acceleration_spread</th>\n",
       "      <th>gyro_pc_mean</th>\n",
       "      <th>gyro_pc_median</th>\n",
       "      <th>gyro_pc_std</th>\n",
       "      <th>gyro_pc_spread</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_median</th>\n",
       "      <th>speed_std</th>\n",
       "      <th>speed_spread</th>\n",
       "      <th>second_mean</th>\n",
       "      <th>second_median</th>\n",
       "      <th>second_std</th>\n",
       "      <th>second_spread</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bookingID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.883337</td>\n",
       "      <td>9.852269</td>\n",
       "      <td>0.619492</td>\n",
       "      <td>6.530989</td>\n",
       "      <td>-0.006583</td>\n",
       "      <td>-0.002863</td>\n",
       "      <td>0.099002</td>\n",
       "      <td>1.101352</td>\n",
       "      <td>9.003204</td>\n",
       "      <td>8.503366</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>22.881775</td>\n",
       "      <td>902.936128</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>534.113894</td>\n",
       "      <td>1589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.865608</td>\n",
       "      <td>9.847932</td>\n",
       "      <td>0.522142</td>\n",
       "      <td>5.819621</td>\n",
       "      <td>-0.006855</td>\n",
       "      <td>-0.003612</td>\n",
       "      <td>0.090770</td>\n",
       "      <td>1.123587</td>\n",
       "      <td>8.019369</td>\n",
       "      <td>7.206634</td>\n",
       "      <td>7.025981</td>\n",
       "      <td>21.882141</td>\n",
       "      <td>581.681384</td>\n",
       "      <td>607.5</td>\n",
       "      <td>289.129088</td>\n",
       "      <td>1034.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.929590</td>\n",
       "      <td>9.877755</td>\n",
       "      <td>0.515173</td>\n",
       "      <td>5.168422</td>\n",
       "      <td>-0.012751</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.117109</td>\n",
       "      <td>0.896289</td>\n",
       "      <td>3.157213</td>\n",
       "      <td>2.998761</td>\n",
       "      <td>2.897762</td>\n",
       "      <td>9.360483</td>\n",
       "      <td>339.441026</td>\n",
       "      <td>97.0</td>\n",
       "      <td>356.319445</td>\n",
       "      <td>825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.813434</td>\n",
       "      <td>9.791035</td>\n",
       "      <td>0.620066</td>\n",
       "      <td>13.349284</td>\n",
       "      <td>0.022429</td>\n",
       "      <td>0.024239</td>\n",
       "      <td>0.112628</td>\n",
       "      <td>1.166471</td>\n",
       "      <td>6.150996</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>5.595901</td>\n",
       "      <td>19.780001</td>\n",
       "      <td>547.495430</td>\n",
       "      <td>547.5</td>\n",
       "      <td>315.962793</td>\n",
       "      <td>1094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9.918090</td>\n",
       "      <td>9.904142</td>\n",
       "      <td>0.585346</td>\n",
       "      <td>7.280114</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.106469</td>\n",
       "      <td>1.161481</td>\n",
       "      <td>4.628921</td>\n",
       "      <td>1.936962</td>\n",
       "      <td>5.314844</td>\n",
       "      <td>16.394695</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>547.0</td>\n",
       "      <td>316.243577</td>\n",
       "      <td>1094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9.826470</td>\n",
       "      <td>9.789800</td>\n",
       "      <td>0.916836</td>\n",
       "      <td>8.572037</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>-0.002687</td>\n",
       "      <td>0.072664</td>\n",
       "      <td>0.903745</td>\n",
       "      <td>12.176386</td>\n",
       "      <td>13.017325</td>\n",
       "      <td>8.680455</td>\n",
       "      <td>25.230654</td>\n",
       "      <td>480.947313</td>\n",
       "      <td>481.0</td>\n",
       "      <td>276.761488</td>\n",
       "      <td>959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9.763213</td>\n",
       "      <td>9.646309</td>\n",
       "      <td>0.730155</td>\n",
       "      <td>9.416841</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.078446</td>\n",
       "      <td>0.754180</td>\n",
       "      <td>5.384260</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>5.657824</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>257.176623</td>\n",
       "      <td>268.0</td>\n",
       "      <td>130.510496</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>9.550677</td>\n",
       "      <td>9.494390</td>\n",
       "      <td>0.833292</td>\n",
       "      <td>9.474737</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>0.110181</td>\n",
       "      <td>0.909695</td>\n",
       "      <td>8.702027</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>7.002632</td>\n",
       "      <td>20.050000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.0</td>\n",
       "      <td>108.397417</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>9.948639</td>\n",
       "      <td>9.877962</td>\n",
       "      <td>0.750480</td>\n",
       "      <td>5.686104</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>-0.003111</td>\n",
       "      <td>0.151980</td>\n",
       "      <td>0.988519</td>\n",
       "      <td>6.659024</td>\n",
       "      <td>5.192059</td>\n",
       "      <td>6.019429</td>\n",
       "      <td>17.876741</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>93.043769</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>9.873517</td>\n",
       "      <td>9.823053</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>5.916028</td>\n",
       "      <td>-0.002192</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.082987</td>\n",
       "      <td>0.767631</td>\n",
       "      <td>4.152211</td>\n",
       "      <td>3.702154</td>\n",
       "      <td>3.524323</td>\n",
       "      <td>15.669114</td>\n",
       "      <td>274.020408</td>\n",
       "      <td>238.0</td>\n",
       "      <td>177.047431</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           acceleration_mean  acceleration_median  acceleration_std  \\\n",
       "bookingID                                                             \n",
       "0                   9.883337             9.852269          0.619492   \n",
       "1                   9.865608             9.847932          0.522142   \n",
       "2                   9.929590             9.877755          0.515173   \n",
       "4                   9.813434             9.791035          0.620066   \n",
       "6                   9.918090             9.904142          0.585346   \n",
       "7                   9.826470             9.789800          0.916836   \n",
       "8                   9.763213             9.646309          0.730155   \n",
       "10                  9.550677             9.494390          0.833292   \n",
       "11                  9.948639             9.877962          0.750480   \n",
       "14                  9.873517             9.823053          0.425662   \n",
       "\n",
       "           acceleration_spread  gyro_pc_mean  gyro_pc_median  gyro_pc_std  \\\n",
       "bookingID                                                                   \n",
       "0                     6.530989     -0.006583       -0.002863     0.099002   \n",
       "1                     5.819621     -0.006855       -0.003612     0.090770   \n",
       "2                     5.168422     -0.012751        0.001369     0.117109   \n",
       "4                    13.349284      0.022429        0.024239     0.112628   \n",
       "6                     7.280114      0.000480        0.004189     0.106469   \n",
       "7                     8.572037      0.002651       -0.002687     0.072664   \n",
       "8                     9.416841     -0.000840        0.000250     0.078446   \n",
       "10                    9.474737      0.001922       -0.000612     0.110181   \n",
       "11                    5.686104     -0.004018       -0.003111     0.151980   \n",
       "14                    5.916028     -0.002192        0.000388     0.082987   \n",
       "\n",
       "           gyro_pc_spread  speed_mean  speed_median  speed_std  speed_spread  \\\n",
       "bookingID                                                                      \n",
       "0                1.101352    9.003204      8.503366   7.200000     22.881775   \n",
       "1                1.123587    8.019369      7.206634   7.025981     21.882141   \n",
       "2                0.896289    3.157213      2.998761   2.897762      9.360483   \n",
       "4                1.166471    6.150996      3.310000   5.595901     19.780001   \n",
       "6                1.161481    4.628921      1.936962   5.314844     16.394695   \n",
       "7                0.903745   12.176386     13.017325   8.680455     25.230654   \n",
       "8                0.754180    5.384260      3.540000   5.657824     18.270000   \n",
       "10               0.909695    8.702027      9.580000   7.002632     20.050000   \n",
       "11               0.988519    6.659024      5.192059   6.019429     17.876741   \n",
       "14               0.767631    4.152211      3.702154   3.524323     15.669114   \n",
       "\n",
       "           second_mean  second_median  second_std  second_spread  \n",
       "bookingID                                                         \n",
       "0           902.936128         1086.5  534.113894         1589.0  \n",
       "1           581.681384          607.5  289.129088         1034.0  \n",
       "2           339.441026           97.0  356.319445          825.0  \n",
       "4           547.495430          547.5  315.962793         1094.0  \n",
       "6           547.000000          547.0  316.243577         1094.0  \n",
       "7           480.947313          481.0  276.761488          959.0  \n",
       "8           257.176623          268.0  130.510496          462.0  \n",
       "10          187.000000          187.0  108.397417          374.0  \n",
       "11          132.000000          112.0   93.043769          299.0  \n",
       "14          274.020408          238.0  177.047431          555.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub1.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating df_sub2: detecting outlier values for speed, second, acceleration, gyro\n",
    "\n",
    "Outliers are defined as values that lie in the 25th/75th percentile of the particular feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Speed_75': 15.67,\n",
       " 'second_75': 862.0,\n",
       " 'acceleration_x_25': -0.506329345703125,\n",
       " 'acceleration_y_25': 0.2875244775,\n",
       " 'acceleration_z_25': -0.8680572509765626,\n",
       " 'acceleration_x_75': 0.6344828,\n",
       " 'acceleration_y_75': 9.718361999999999,\n",
       " 'acceleration_z_75': 2.7852156,\n",
       " 'gyro_x_25': -0.026582342420625914,\n",
       " 'gyro_y_25': -0.029722957,\n",
       " 'gyro_z_25': -0.018615723,\n",
       " 'gyro_x_75': 0.02321850364774683,\n",
       " 'gyro_y_75': 0.031136672999999997,\n",
       " 'gyro_z_75': 0.018109497}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking 75th percentile for speed and second\n",
    "# Checking 25th and 75th percentile for acceleration, gyro coordinates\n",
    "\n",
    "outlier_vals = {'Speed_75' : np.quantile(df_add['Speed'], 0.75),\n",
    "               'second_75' : np.quantile(df_add['second'], 0.75),\n",
    "               'acceleration_x_25' : np.quantile(df_add['acceleration_x'], 0.25), \n",
    "               'acceleration_y_25' : np.quantile(df_add['acceleration_y'], 0.25),\n",
    "               'acceleration_z_25' : np.quantile(df_add['acceleration_z'], 0.25),\n",
    "               'acceleration_x_75' : np.quantile(df_add['acceleration_x'], 0.75),\n",
    "               'acceleration_y_75' : np.quantile(df_add['acceleration_y'], 0.75),\n",
    "               'acceleration_z_75' : np.quantile(df_add['acceleration_z'], 0.75),\n",
    "               'gyro_x_25' : np.quantile(df_add['gyro_x'], 0.25),\n",
    "               'gyro_y_25' : np.quantile(df_add['gyro_y'], 0.25),\n",
    "               'gyro_z_25' : np.quantile(df_add['gyro_z'], 0.25),\n",
    "               'gyro_x_75' : np.quantile(df_add['gyro_x'], 0.75),\n",
    "               'gyro_y_75' : np.quantile(df_add['gyro_y'], 0.75),\n",
    "               'gyro_z_75' : np.quantile(df_add['gyro_z'], 0.75)}\n",
    "\n",
    "outlier_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_x\n",
      "acceleration_y\n",
      "acceleration_z\n",
      "gyro_x\n",
      "gyro_y\n",
      "gyro_z\n"
     ]
    }
   ],
   "source": [
    "def quantile_check(x, col, q):\n",
    "    val = outlier_vals['{}_{}'.format(col, q)]\n",
    "    \n",
    "    if q == 25:\n",
    "        return np.sum(x[col] < val)\n",
    "    elif q == 75:\n",
    "        return np.sum(x[col] > val)\n",
    "    \n",
    "\n",
    "df_sub2 = pd.DataFrame()\n",
    "    \n",
    "colnames = ['acceleration_x', 'acceleration_y', 'acceleration_z', \n",
    "           'gyro_x', 'gyro_y', 'gyro_z']\n",
    "\n",
    "df_sub2['over_Speed'] = df_add.groupby('bookingID').apply(quantile_check, col='Speed', q=75)\n",
    "df_sub2['over_second'] = df_add.groupby('bookingID').apply(quantile_check, col='second', q=75)\n",
    "\n",
    "for col in colnames:\n",
    "    print(col)\n",
    "    arr = df_add.groupby('bookingID').apply(quantile_check, col=col, \n",
    "                                             q=25).values + df_add.groupby('bookingID').apply(quantile_check, \n",
    "                                                                                              col=col, q=75).values\n",
    "    df_sub2['over_{}'.format(col)] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging df_sub1 and df_sub2\n",
    "\n",
    "df_add2 = pd.merge(df_sub1, df_sub2, on='bookingID')\n",
    "df_add2 = pd.merge(df_add2, label_df, on='bookingID')\n",
    "df_add2.columns = [col.lower() for col in df_add2.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating df_sub3: sliding window + IsolationForest\n",
    "\n",
    "Sliding window of 8 seconds with 4 seconds overlap on speed, acceleration and gyro readings \\\n",
    "Values per window are aggregated on mean, median and standard deviation \\\n",
    "The aggregated windows are then used to fit an IsolationForest for each bookingID, to get outlier values for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_features = df_add[['bookingID', 'Speed', 'acceleration', 'gyro_pc']].groupby('bookingID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2020-01-28 14:12:38.361423\n",
      "End time: 2020-01-28 14:16:56.002106\n",
      "Total time taken: 257 seconds\n"
     ]
    }
   ],
   "source": [
    "def sliding_window(df, step=8, overlap=4):\n",
    "    df = df.reset_index(drop=True)\n",
    "    start_idx = df.index.values[0]\n",
    "    end_idx = df.index.values[-1]\n",
    "        \n",
    "    booking_df = pd.DataFrame(columns=['Speed_mean', 'acceleration_mean', 'gyro_pc_mean', \n",
    "                                       'Speed_median', 'acceleration_median', 'gyro_pc_median', \n",
    "                                       'Speed_std', 'acceleration_std', 'gyro_pc_std'])    \n",
    "    \n",
    "    while start_idx <= (end_idx - step):\n",
    "        agg_vals = df.iloc[start_idx: start_idx + step, ].aggregate(['mean', 'median', 'std'])\n",
    "        agg_vals = agg_vals.unstack().to_frame().sort_index(level=1).T\n",
    "        agg_vals.columns = agg_vals.columns.map('_'.join)\n",
    "        \n",
    "        booking_df = pd.concat([booking_df, agg_vals], axis=0)\n",
    "        \n",
    "        start_idx += overlap\n",
    "\n",
    "    return booking_df\n",
    "    \n",
    "\n",
    "    \n",
    "import datetime\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: {}\".format(start_time))\n",
    "\n",
    "df_sub3 = window_features.rolling(8).agg(['mean', 'median', 'std']).dropna()[::4]\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: {}\".format(end_time))\n",
    "\n",
    "print(\"Total time taken: {} seconds\".format((end_time - start_time).seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 369367187568,  609885356187,  824633720857, 1108101562368,\n",
       "       1211180777622, 1314259992647])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we removed some rows earlier due to inaccuracy, some bookingIDs have less than\n",
    "# the required amount of readings for the sliding window, resulting in null values \n",
    "\n",
    "x = window_features.count()\n",
    "missing_ids = x['Speed'][x['Speed'] <= 10].index.values\n",
    "\n",
    "missing_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub3 = df_sub3.drop('bookingID', axis=1)\n",
    "df_sub3.columns = ['_'.join(col) for col in df_sub3.columns]\n",
    "df_sub3 = df_sub3.droplevel(1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fitting IsolationForest for each feature to detect outliers\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "speed_cols = ['Speed_mean', 'Speed_median', 'Speed_std']\n",
    "accel_cols = ['acceleration_mean', 'acceleration_median', 'acceleration_std']\n",
    "gyro_cols = ['gyro_pc_mean', 'gyro_pc_median', 'gyro_pc_std']\n",
    "\n",
    "iso1 = IsolationForest()\n",
    "iso_speed = iso1.fit_predict(df_sub3[speed_cols])\n",
    "\n",
    "iso2 = IsolationForest()\n",
    "iso_accel = iso2.fit_predict(df_sub3[accel_cols])\n",
    "\n",
    "iso3 = IsolationForest()\n",
    "iso_gyro = iso3.fit_predict(df_sub3[gyro_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bookingID\n",
       "0                 ((243, 6), (235, 14), (237, 12))\n",
       "1                 ((192, 16), (206, 2), (197, 11))\n",
       "2                      ((47, 0), (47, 0), (41, 6))\n",
       "4                ((259, 13), (262, 10), (247, 25))\n",
       "6                ((259, 13), (262, 10), (248, 24))\n",
       "                               ...                \n",
       "1709396983957     ((242, 0), (39, 203), (232, 10))\n",
       "1709396983960     ((157, 25), (177, 5), (169, 13))\n",
       "1709396983966     ((177, 16), (192, 1), (167, 26))\n",
       "1709396983971      ((254, 9), (254, 9), (236, 27))\n",
       "1709396983975          ((61, 5), (64, 2), (63, 3))\n",
       "Length: 19934, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub3['speed_outlier'] = iso_speed\n",
    "df_sub3['accel_outlier'] = iso_accel\n",
    "df_sub3['gyro_outlier'] = iso_gyro\n",
    "\n",
    "def count_outliers(x):\n",
    "    non_speed = np.sum(x['speed_outlier'] == 1)\n",
    "    speed = np.sum(x['speed_outlier'] == -1)\n",
    "    \n",
    "    non_accel = np.sum(x['accel_outlier'] == 1)\n",
    "    accel = np.sum(x['accel_outlier'] == -1)\n",
    "    \n",
    "    non_gyro = np.sum(x['gyro_outlier'] == 1)\n",
    "    gyro = np.sum(x['gyro_outlier'] == -1)\n",
    "    \n",
    "    return (non_speed, speed), (non_accel, accel), (non_gyro, gyro)\n",
    "\n",
    "outlier_df = df_sub3.groupby('bookingID').apply(count_outliers)\n",
    "outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df2 = pd.DataFrame({'num_non_speed_outlier' : [lst[0][0] for lst in outlier_df],\n",
    "                           'num_speed_outlier' : [lst[0][1] for lst in outlier_df],\n",
    "                           'num_non_accel_outlier' : [lst[1][0] for lst in outlier_df],\n",
    "                           'num_accel_outlier' : [lst[1][1] for lst in outlier_df],\n",
    "                           'num_non_gyro_outlier' : [lst[2][0] for lst in outlier_df],\n",
    "                           'num_gyro_outlier' : [lst[2][1] for lst in outlier_df]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bookingid                0\n",
       "acceleration_mean        0\n",
       "acceleration_median      0\n",
       "acceleration_std         0\n",
       "acceleration_spread      0\n",
       "gyro_pc_mean             0\n",
       "gyro_pc_median           0\n",
       "gyro_pc_std              0\n",
       "gyro_pc_spread           0\n",
       "speed_mean               0\n",
       "speed_median             0\n",
       "speed_std                0\n",
       "speed_spread             0\n",
       "second_mean              0\n",
       "second_median            0\n",
       "second_std               0\n",
       "second_spread            0\n",
       "over_speed               0\n",
       "over_second              0\n",
       "over_acceleration_x      0\n",
       "over_acceleration_y      0\n",
       "over_acceleration_z      0\n",
       "over_gyro_x              0\n",
       "over_gyro_y              0\n",
       "over_gyro_z              0\n",
       "label                    0\n",
       "num_non_speed_outlier    0\n",
       "num_speed_outlier        0\n",
       "num_non_accel_outlier    0\n",
       "num_accel_outlier        0\n",
       "num_non_gyro_outlier     0\n",
       "num_gyro_outlier         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping missing rows from df_add2, then merging with new outlier_df2\n",
    "df_add2 = df_add2[~df_add2['bookingid'].isin(missing_ids)].reset_index(drop=True)\n",
    "df_add3 = pd.concat([df_add2, outlier_df2], axis=1)\n",
    "\n",
    "# Double check for missing values\n",
    "df_add3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating df_sub4 (not dropping inaccurate rows and negative speeds)\n",
    "1. Calculate acceleration using Euclidean distance\n",
    "2. Sliding window of size 8 to aggregate on mean, median, std per bookingID\n",
    "3. IsolationForest to identify outliers per bookingID\n",
    "\n",
    "THIS TAKES FOREVER (~ 1.5 HOURS) TO RUN FOR ONE FEATURE, DONT USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_df = df_add[['bookingID', 'acceleration', 'second', 'label']]\n",
    "\n",
    "accel_agg = accel_df.groupby('bookingID')['acceleration'].rolling(8).aggregate(['mean', 'median', 'std'])\n",
    "accel_agg = accel_agg.dropna().droplevel(1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso = IsolationForest(behaviour='new', contamination='auto')\n",
    "\n",
    "def detect_outliers(x):\n",
    "    pred = iso.fit_predict(x)\n",
    "    x['outlier'] = pred\n",
    "    return x\n",
    "    \n",
    "accel_agg2 = accel_agg.groupby('bookingID').apply(detect_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_agg2.to_csv(SAVE_DIR + \"accel_agg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older (unused) pre-processing/aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# window_features5 = pd.DataFrame(scaler.fit_transform(window_features4), columns=window_features4.columns)\n",
    "# window_features5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans \n",
    "# from sklearn import metrics \n",
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# distortions = [] \n",
    "# inertias = [] \n",
    "# mapping1 = {} \n",
    "# mapping2 = {} \n",
    "# K = range(1,10) \n",
    "  \n",
    "# for k in K: \n",
    "#     print(k)\n",
    "    \n",
    "#     #Building and fitting the model \n",
    "#     kmeanModel = KMeans(n_clusters=k)\n",
    "#     kmeanModel.fit(window_features4)     \n",
    "      \n",
    "#     distortions.append(sum(np.min(cdist(window_features4, kmeanModel.cluster_centers_, \n",
    "#                       'euclidean'),axis=1)) / window_features4.shape[0]) \n",
    "#     inertias.append(kmeanModel.inertia_) \n",
    "  \n",
    "#     mapping1[k] = sum(np.min(cdist(window_features4, kmeanModel.cluster_centers_, \n",
    "#                  'euclidean'),axis=1)) / window_features4.shape[0] \n",
    "#     mapping2[k] = kmeanModel.inertia_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key,val in mapping1.items(): \n",
    "# \tprint(str(key)+' : '+str(val)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(K, distortions, 'bx-') \n",
    "# plt.xlabel('Values of K') \n",
    "# plt.ylabel('Distortion') \n",
    "# plt.title('The Elbow Method using Distortion') \n",
    "# plt.show() # Should keep 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(K, inertias, 'bx-') \n",
    "# plt.xlabel('Values of K') \n",
    "# plt.ylabel('Inertia') \n",
    "# plt.title('The Elbow Method using Inertia') \n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans = KMeans(n_clusters=5)\n",
    "# kmeans.fit(window_features5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_features5['cluster'] = kmeans.predict(window_features5)\n",
    "# window_features5['cluster'] += 1\n",
    "# window_features5['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_ids = []\n",
    "\n",
    "# for idx in window_features3.index:\n",
    "#     booking_ids.append(idx[0])\n",
    "    \n",
    "# len(booking_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_features5['bookingID'] = booking_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_add2 = df_add.groupby('bookingID').aggregate({'second' : ['min', 'mean', 'max', 'median', 'std', spread], \n",
    "#                                                  'Speed' : ['min', 'mean', 'max', 'median', 'std', spread], \n",
    "#                                                 'distance' : ['min', 'mean', 'max', 'median', 'std', spread],\n",
    "#                                                 'acceleration' : ['min', 'mean', 'max', 'median', 'std', spread],\n",
    "#                                                 'gyro_pc' : ['min', 'mean', 'max', 'median', 'std', spread],\n",
    "#                                                 'speed_diff' : ['min', 'mean', 'max', 'median', 'std', spread],\n",
    "#                                                 'bearing_diff' : ['min', 'mean', 'max', 'median', 'std', spread]})\n",
    "\n",
    "# df_add2.columns = [\"_\".join(x) for x in df_add2.columns.ravel()]\n",
    "# df_add2 = pd.merge(df_add2, label_df, on='bookingID').drop('bookingID', axis='columns')\n",
    "# df_add2.columns = [col.lower() for col in df_add2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking for correlations within aggregated data\n",
    "# # Particularly, check for correlations between different features \n",
    "# # e.g. strong correlation between accuracy and speed etc\n",
    "\n",
    "# corr_matrix = df_add2.corr()\n",
    "# corr_matrix.where((corr_matrix > 0.5) & (corr_matrix != 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_corr_heatmap(df, vmax=1.0):\n",
    "#     corr_matrix = df.corr()\n",
    "    \n",
    "#     mask = np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "#     mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "#     # Set up the matplotlib figure\n",
    "#     f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "#     # Generate a custom diverging colormap\n",
    "#     cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "#     # Draw the heatmap with the mask and correct aspect ratio\n",
    "#     sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=vmax, \n",
    "#                 square=True, center=0, linewidths=.5)\n",
    "    \n",
    "# plot_corr_heatmap(df, vmax=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df_add2, hue='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating CSV for use in modelling.ipynb and model_ANN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = os.path.join(os.getcwd(), '../data/safety/')\n",
    "\n",
    "df_add3.to_csv(SAVE_DIR + \"total_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
